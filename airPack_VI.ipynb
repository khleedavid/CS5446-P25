{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies for the project\n",
    "import gymnasium as gym\n",
    "import gym_BinPack3D\n",
    "from gym_BinPack3D.envs import Box, Rotate\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.path.join(os.getcwd(), 'Documents/GitHub/CS5446_AI_planning/CS5446-Project')\n",
    "DATA_DIR = os.path.join(CWD, 'data')\n",
    "GIF_DIR = os.path.join(CWD, 'gifs')\n",
    "TENSORBOARD_DIR = os.path.join(CWD, 'tensorboard')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(GIF_DIR, exist_ok=True)\n",
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (3, 3)\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (25, 4)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultiDiscrete([100   4]),\n",
       " Dict('coming_boxes': Box(0.0, 25.0, (3, 3), float32), 'height_map': Box(0.0, 4.0, (25, 4), float32), 'valid_placement_mask': MultiBinary((4, 25, 4))))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#register the environment\n",
    "gym.envs.register(\n",
    "    id='BinPack3D-v1',\n",
    "    entry_point='gym_BinPack3D.envs:PackingGame',\n",
    ")\n",
    "\n",
    "#define the environment.\n",
    "#container_size: size of the container in 3D\n",
    "#boxSeqGenerator: how the boxes are generated.\n",
    "#enabled_rotations: which rotations are allowed for the boxes\n",
    "#n_foreseeable_box: how many boxes are shown to the agent\n",
    "#box_set: the set of boxes that are used in the environment. \n",
    "\n",
    "env = gym.make('BinPack3D-v1', \n",
    "                container_size = (25, 4, 4),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP, Rotate.XY, Rotate.XZ, Rotate.YZ],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1,\n",
    "                maxSideLen = 2,\n",
    "            )\n",
    "\n",
    "\n",
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Baseline Agent\n",
    "Here we load an agent with perfect information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "(14, 2) (58, <Rotate.NOOP: 0>) 0.1\n",
      "(20, 2) (82, <Rotate.NOOP: 0>) 0.1\n",
      "(17, 2) (70, <Rotate.NOOP: 0>) 0.1\n",
      "(22, 0) (88, <Rotate.NOOP: 0>) 0.1\n",
      "(14, 3) (59, <Rotate.NOOP: 0>) 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:364: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 0) (72, <Rotate.NOOP: 0>) 0.05\n",
      "(10, 2) (42, <Rotate.NOOP: 0>) 0.05\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 0.05\n",
      "(7, 0) (28, <Rotate.NOOP: 0>) 0.05\n",
      "(24, 0) (96, <Rotate.NOOP: 0>) 0.05\n",
      "(11, 2) (46, <Rotate.NOOP: 0>) 0.1\n",
      "(12, 3) (51, <Rotate.NOOP: 0>) 0.025\n",
      "(17, 2) (70, <Rotate.NOOP: 0>) 0.1\n",
      "(24, 2) (98, <Rotate.NOOP: 0>) 0.05\n",
      "(1, 0) (4, <Rotate.NOOP: 0>) 0.05\n",
      "(0, 3) (3, <Rotate.NOOP: 0>) 0.05\n",
      "(13, 2) (54, <Rotate.NOOP: 0>) 0.05\n",
      "(16, 2) (66, <Rotate.NOOP: 0>) 0.05\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 0.025\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 0.05\n",
      "(4, 0) (16, <Rotate.NOOP: 0>) 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/Documents/GitHub/CS5446_AI_planning/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/BinPack3DEnv.py:198: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0) (16, <Rotate.NOOP: 0>) 0.1\n",
      "(11, 0) (44, <Rotate.NOOP: 0>) 0.1\n",
      "(20, 2) (82, <Rotate.NOOP: 0>) 0.05\n",
      "(22, 2) (90, <Rotate.NOOP: 0>) 0.1\n",
      "(3, 0) (12, <Rotate.NOOP: 0>) 0.05\n",
      "(11, 3) (47, <Rotate.NOOP: 0>) 0.025\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 0.1\n",
      "(16, 3) (67, <Rotate.NOOP: 0>) 0.025\n",
      "(22, 0) (88, <Rotate.NOOP: 0>) 0.2\n",
      "(8, 2) (34, <Rotate.NOOP: 0>) 0.1\n",
      "(24, 0) (96, <Rotate.NOOP: 0>) 0.1\n",
      "(23, 3) (95, <Rotate.NOOP: 0>) 0.05\n",
      "(19, 3) (79, <Rotate.NOOP: 0>) 0.05\n",
      "(21, 2) (86, <Rotate.NOOP: 0>) 0.1\n",
      "(8, 0) (32, <Rotate.NOOP: 0>) 0.05\n",
      "(9, 0) (36, <Rotate.NOOP: 0>) 0.1\n",
      "(14, 2) (58, <Rotate.NOOP: 0>) 0.05\n",
      "(11, 2) (46, <Rotate.NOOP: 0>) 0.1\n",
      "(21, 3) (87, <Rotate.NOOP: 0>) 0.025\n",
      "(2, 1) (9, <Rotate.NOOP: 0>) 0.05\n",
      "(22, 3) (91, <Rotate.NOOP: 0>) 0.025\n",
      "(23, 3) (95, <Rotate.NOOP: 0>) 0.1\n",
      "(17, 2) (70, <Rotate.NOOP: 0>) 0.05\n",
      "(15, 3) (63, <Rotate.NOOP: 0>) 0.05\n",
      "(13, 3) (55, <Rotate.NOOP: 0>) 0.025\n",
      "(0, 3) (3, <Rotate.NOOP: 0>) 0.05\n",
      "(16, 0) (64, <Rotate.NOOP: 0>) 0.1\n",
      "(22, 0) (88, <Rotate.NOOP: 0>) 0.1\n",
      "(13, 2) (54, <Rotate.NOOP: 0>) 0.05\n",
      "(2, 3) (11, <Rotate.NOOP: 0>) 0.025\n",
      "(7, 2) (30, <Rotate.NOOP: 0>) 0.05\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 0.1\n",
      "(24, 2) (98, <Rotate.NOOP: 0>) 0.05\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 0.1\n",
      "(10, 3) (43, <Rotate.NOOP: 0>) 0.025\n",
      "(5, 2) (22, <Rotate.NOOP: 0>) 0.1\n",
      "(6, 3) (27, <Rotate.NOOP: 0>) 0.025\n",
      "(3, 2) (14, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 1) (1, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 2) (2, <Rotate.NOOP: 0>) 0.05\n",
      "(9, 2) (38, <Rotate.NOOP: 0>) 0.1\n",
      "(7, 0) (28, <Rotate.NOOP: 0>) 0.2\n",
      "(13, 0) (52, <Rotate.NOOP: 0>) 0.05\n",
      "(14, 0) (56, <Rotate.NOOP: 0>) 0.1\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 0.1\n",
      "(12, 0) (48, <Rotate.NOOP: 0>) 0.2\n",
      "(17, 0) (68, <Rotate.NOOP: 0>) 0.2\n",
      "(3, 2) (14, <Rotate.NOOP: 0>) 0.05\n",
      "(1, 2) (6, <Rotate.NOOP: 0>) 0.05\n",
      "(11, 3) (47, <Rotate.NOOP: 0>) 0.1\n",
      "(17, 3) (71, <Rotate.NOOP: 0>) 0.05\n",
      "(8, 2) (34, <Rotate.NOOP: 0>) 0.05\n",
      "(24, 0) (96, <Rotate.NOOP: 0>) 0.05\n",
      "(10, 0) (40, <Rotate.NOOP: 0>) 0.1\n",
      "(19, 3) (79, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 2) (2, <Rotate.NOOP: 0>) 0.025\n",
      "(21, 3) (87, <Rotate.NOOP: 0>) 0.05\n",
      "(5, 3) (23, <Rotate.NOOP: 0>) 0.025\n",
      "(22, 3) (91, <Rotate.NOOP: 0>) 0.05\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 0.2\n",
      "(14, 0) (56, <Rotate.NOOP: 0>) 0.2\n",
      "(11, 0) (44, <Rotate.NOOP: 0>) 0.1\n",
      "(13, 3) (55, <Rotate.NOOP: 0>) 0.1\n",
      "(16, 3) (67, <Rotate.NOOP: 0>) 0.05\n",
      "(5, 2) (22, <Rotate.NOOP: 0>) 0.1\n",
      "(20, 2) (82, <Rotate.NOOP: 0>) 0.05\n",
      "(2, 0) (8, <Rotate.NOOP: 0>) 0.2\n",
      "(15, 2) (62, <Rotate.NOOP: 0>) 0.1\n",
      "(18, 3) (75, <Rotate.NOOP: 0>) 0.05\n",
      "(15, 2) (62, <Rotate.NOOP: 0>) 0.025\n",
      "(10, 3) (43, <Rotate.NOOP: 0>) 0.05\n",
      "(6, 0) (24, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 3) (3, <Rotate.NOOP: 0>) 0.1\n",
      "(7, 3) (31, <Rotate.NOOP: 0>) 0.05\n",
      "(14, 2) (58, <Rotate.NOOP: 0>) 0.025\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 0.05\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 0.05\n",
      "(6, 0) (24, <Rotate.NOOP: 0>) 0.1\n",
      "(23, 2) (94, <Rotate.NOOP: 0>) 0.05\n",
      "(14, 0) (56, <Rotate.NOOP: 0>) 0.1\n",
      "(9, 3) (39, <Rotate.NOOP: 0>) 0.025\n",
      "(13, 2) (54, <Rotate.NOOP: 0>) 0.025\n",
      "(11, 2) (46, <Rotate.NOOP: 0>) 0.05\n",
      "(4, 0) (16, <Rotate.NOOP: 0>) 0.05\n",
      "(21, 0) (84, <Rotate.NOOP: 0>) 0.1\n",
      "(7, 2) (30, <Rotate.NOOP: 0>) 0.05\n",
      "(10, 2) (42, <Rotate.NOOP: 0>) 0.025\n",
      "(9, 0) (36, <Rotate.NOOP: 0>) 0.1\n",
      "(9, 2) (38, <Rotate.NOOP: 0>) 0.025\n",
      "(16, 0) (64, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 0.1\n",
      "(1, 2) (6, <Rotate.NOOP: 0>) 0.1\n",
      "(17, 0) (68, <Rotate.NOOP: 0>) 0.1\n",
      "(8, 0) (32, <Rotate.NOOP: 0>) 0.05\n",
      "(4, 2) (18, <Rotate.NOOP: 0>) 0.05\n",
      "(17, 3) (71, <Rotate.NOOP: 0>) 0.05\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 0.05\n",
      "(22, 2) (90, <Rotate.NOOP: 0>) 0.05\n",
      "(4, 3) (19, <Rotate.NOOP: 0>) 0.025\n",
      "(2, 3) (11, <Rotate.NOOP: 0>) 0.05\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 0.1\n",
      "(8, 3) (35, <Rotate.NOOP: 0>) 0.1\n",
      "(6, 3) (27, <Rotate.NOOP: 0>) 0.1\n",
      "(3, 0) (12, <Rotate.NOOP: 0>) 0.05\n",
      "(3, 2) (14, <Rotate.NOOP: 0>) 0.025\n",
      "(6, 2) (26, <Rotate.NOOP: 0>) 0.05\n",
      "(24, 2) (98, <Rotate.NOOP: 0>) 0.025\n",
      "(4, 2) (18, <Rotate.NOOP: 0>) 0.05\n",
      "(11, 0) (44, <Rotate.NOOP: 0>) 0.1\n",
      "(16, 2) (66, <Rotate.NOOP: 0>) 0.025\n",
      "(8, 2) (34, <Rotate.NOOP: 0>) 0.025\n",
      "(13, 0) (52, <Rotate.NOOP: 0>) 0.05\n",
      "(2, 0) (8, <Rotate.NOOP: 0>) 0.05\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 0.025\n",
      "(16, 0) (64, <Rotate.NOOP: 0>) 0.05\n",
      "(9, 0) (36, <Rotate.NOOP: 0>) 0.1\n",
      "(3, 3) (15, <Rotate.NOOP: 0>) 0.05\n",
      "(2, 3) (11, <Rotate.NOOP: 0>) 0.05\n",
      "(4, 3) (19, <Rotate.NOOP: 0>) 0.1\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 0.1\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 0.0\n"
     ]
    }
   ],
   "source": [
    "#load the environment with a baseline agent\n",
    "env = gym.make('BinPack3D-v1', \n",
    "             container_size = (25, 4, 4),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1,\n",
    "                maxSideLen = 2,\n",
    "            )\n",
    "\n",
    "#default container size is (9, 11, 13), with maxSideLen = 5, minSideLen = 2\n",
    "#container size for our game is (25, 4, 4), with maxSideLen = 2, minSideLen = 1\n",
    "\n",
    "frames = []\n",
    "obs = env.reset()\n",
    "#set environment to render rgb_array\n",
    "frame = env.render()\n",
    "rewards = []\n",
    "while True:\n",
    "    frames.append(frame)\n",
    "    # we cheat the game by look at cut process info and get the \n",
    "    # correct pos to place box, achieving perfect packing\n",
    "    box = env.boxSeqGenerator.next_N_boxes()[0]\n",
    "    pos = (box.x,box.y)\n",
    "    act_pos = env.position_to_actionIdx(pos)\n",
    "    rot = Rotate.NOOP\n",
    "    action = (act_pos, rot)\n",
    "\n",
    "    obs, reward, done,_, info = env.step(action)\n",
    "    frame = env.render()\n",
    "    # print(reward,done,info)\n",
    "    print(pos, action, reward)\n",
    "    rewards.append(reward + rewards[-1] if len(rewards) > 0 else reward)\n",
    "    \n",
    "    if done: break\n",
    "        \n",
    "env.render()\n",
    "\n",
    "imageio.mimsave(GIF_DIR+\"/baseline.gif\", frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using wrapped reward function\n",
    "We define a perfect agent who has knowledge of the exact order of boxes to be placed in the environment by providing the 'CUT-2' sequence order.\n",
    "\n",
    "Then, we want to train an agent who does not have knowledge of the exact order of boxes to stack the incoming boxes.\n",
    "\n",
    "Modifying the reward, we train a PPO and A2C agent using stable_baselines3 to see if the agent is able to change its behavior based on its reward function.\n",
    "We plot the reward in comparison with the perfect agent to test its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test using a wrapper to modify the reward\n",
    "\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class RewardWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.container_volume = env.container_size[0] * env.container_size[1] * env.container_size[2]\n",
    "        self.floor_space = env.container_size[0] * env.container_size[1]\n",
    "        self.prev_floor_space = 0\n",
    "        print(f\"Container dimensions: {env.container_size}, Container volume: {self.container_volume}, Floor space: {self.floor_space}\")\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        base_reward = reward\n",
    "        #base reward is the current ratio of boxes placed in the container to the total volume of the container.\n",
    "        # we want to minimize the floor space used by the boxes and maximize the height of the boxes.\n",
    "        # we weight the height as a positive reward and the floor space as a negative reward.\n",
    "        # height should be modified by the max height of the current box.\n",
    "        ratio_height = obs['height_map'].max() / env.container_size[2]\n",
    "        # larger height is better. use sigmoid to reward the agent for placing boxes higher. limit the range of the reward to -1 to 1.\n",
    "        if ratio_height > 1: #this means that the agent has placed a box that is higher than the container. we should penalize this heavily.\n",
    "            curr_max_height = -100\n",
    "        else:\n",
    "            curr_max_height = np.exp(ratio_height**2) + 1\n",
    "        \n",
    "        # floor space should be modified by the current floor space of the container. we want to minimize this and penalize the agent for using more floor space.\n",
    "        curr_floor_space = obs['valid_placement_mask'].sum() / self.floor_space\n",
    "        # smaller floor space is better. use sigmoid to penalize the agent for using more floor space.\n",
    "        curr_floor_space = -np.exp(-curr_floor_space**2)        \n",
    "\n",
    "        #reward longer sequences of boxes placed in the container. we want to maximize the number of boxes placed in the container.\n",
    "        curr_count = info['counter']\n",
    "        # larger count is better. use sigmoid to reward the agent for placing more boxes. limit the range of the reward to -1 to 1.\n",
    "        reward_count = (1+np.exp(-curr_count))**-1\n",
    "\n",
    "\n",
    "        #if action placement is near the x axis, reward the agent\n",
    "        #get the position of the action in x,y coordinates, and express the x coordinate as a fraction of the container length.\n",
    "        act_pos = self.env.actionIdx_to_position(action[0])[0] / self.env.container_size[0] -1\n",
    "        #smaller x position is better. use sigmoid to reward the agent for placing boxes near the x axis. limit the range of the reward to -1 to 1.\n",
    "        act_x_dist = np.exp(-act_pos**2) *2\n",
    "\n",
    "        #modify the reward. base reward is the current ratio of boxes placed in the container to the total volume of the container.\n",
    "        reward = base_reward + curr_max_height + curr_floor_space + reward_count + act_x_dist\n",
    "\n",
    "        #add reward details to the info dictionary\n",
    "        info['base_reward'] = base_reward\n",
    "        info['max_height'] = curr_max_height\n",
    "        info['floor_space'] = curr_floor_space\n",
    "        info['action_x_dist'] = act_x_dist\n",
    "        info['reward_count'] = reward_count\n",
    "\n",
    "        # print(f\"Base reward: {base_reward}, Modified reward: {reward}, Max height: {curr_max_height}, Floor space: {curr_floor_space}\")\n",
    "        \n",
    "        return obs, reward, done, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "Container dimensions: (25, 4, 4), Container volume: 400, Floor space: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (3, 3)\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (25, 4)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#use wrapped_env to train a PPO agent\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "#import tensorboard for logging\n",
    "\n",
    "base_env = gym.make('BinPack3D-v1',\n",
    "                container_size = (25, 4, 4), #(9, 11, 13),\n",
    "                    boxSeqGenerator='CUT-2', \n",
    "                    enabled_rotations = [Rotate.NOOP],\n",
    "                    n_foreseeable_box = 3,\n",
    "                    minSideLen = 1, # 2\n",
    "                    maxSideLen = 2, # 5\n",
    "                )\n",
    "wrapped_env = RewardWrapper(base_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /Users/dlkh/Documents/GitHub/CS5446_AI_planning/CS5446-Project/tensorboard/ppo_binpack3d_tensorboard/PPO_24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.82     |\n",
      "|    ep_rew_mean     | 19.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 413      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.53       |\n",
      "|    ep_rew_mean          | 23.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 415        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01551788 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.59      |\n",
      "|    explained_variance   | -0.00647   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.5       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0597    |\n",
      "|    value_loss           | 152        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.46        |\n",
      "|    ep_rew_mean          | 23.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013548275 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.0038      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0532     |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 6.73         |\n",
      "|    ep_rew_mean          | 28.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 429          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148663325 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.7         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0591      |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.08       |\n",
      "|    ep_rew_mean          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 432        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177439 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.52      |\n",
      "|    explained_variance   | 0.0865     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 70.1       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    value_loss           | 143        |\n",
      "----------------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /Users/dlkh/Documents/GitHub/CS5446_AI_planning/CS5446-Project/tensorboard/a2c_binpack3d_tensorboard/A2C_11\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.16     |\n",
      "|    ep_rew_mean        | 25.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 414      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.86    |\n",
      "|    explained_variance | 0.0248   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 42.8     |\n",
      "|    value_loss         | 236      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.51     |\n",
      "|    ep_rew_mean        | 32.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 448      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.73    |\n",
      "|    explained_variance | 0.0533   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 71.8     |\n",
      "|    value_loss         | 262      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.87     |\n",
      "|    ep_rew_mean        | 34.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 455      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.56    |\n",
      "|    explained_variance | 0.252    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    value_loss         | 64.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.13     |\n",
      "|    ep_rew_mean        | 30.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 456      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.44    |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -5.65    |\n",
      "|    value_loss         | 14.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.26     |\n",
      "|    ep_rew_mean        | 31.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 459      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0.654    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 5.22     |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.61     |\n",
      "|    ep_rew_mean        | 33.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 463      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.37    |\n",
      "|    explained_variance | 0.0765   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 66.4     |\n",
      "|    value_loss         | 315      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.55     |\n",
      "|    ep_rew_mean        | 32.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 463      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.89    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 7.82     |\n",
      "|    value_loss         | 34.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.14     |\n",
      "|    ep_rew_mean        | 35.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 468      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.48    |\n",
      "|    explained_variance | 0.774    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -20.8    |\n",
      "|    value_loss         | 27.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.06     |\n",
      "|    ep_rew_mean        | 35.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 468      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.23    |\n",
      "|    explained_variance | 0.576    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -15.8    |\n",
      "|    value_loss         | 33.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.83     |\n",
      "|    ep_rew_mean        | 34.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 471      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.56    |\n",
      "|    explained_variance | 0.473    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 45.9     |\n",
      "|    value_loss         | 133      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.63     |\n",
      "|    ep_rew_mean        | 37.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 474      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.93    |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.85     |\n",
      "|    value_loss         | 7.96     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.9      |\n",
      "|    ep_rew_mean        | 38.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.01    |\n",
      "|    explained_variance | 0.816    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.56     |\n",
      "|    ep_rew_mean        | 36.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.56    |\n",
      "|    explained_variance | 0.758    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 8.29     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.82     |\n",
      "|    ep_rew_mean        | 38.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.21    |\n",
      "|    explained_variance | 0.709    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 16.9     |\n",
      "|    value_loss         | 38.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.07     |\n",
      "|    ep_rew_mean        | 35.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.14    |\n",
      "|    explained_variance | 0.876    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 7.9      |\n",
      "|    value_loss         | 9.98     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.24     |\n",
      "|    ep_rew_mean        | 36.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 482      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.2     |\n",
      "|    explained_variance | 0.869    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    value_loss         | 14       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.41     |\n",
      "|    ep_rew_mean        | 41.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 485      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.76    |\n",
      "|    explained_variance | 0.571    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -3.19    |\n",
      "|    value_loss         | 22.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.65     |\n",
      "|    ep_rew_mean        | 42.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 488      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.873    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 10.7     |\n",
      "|    value_loss         | 17.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.19     |\n",
      "|    ep_rew_mean        | 40.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 489      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0.59     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -34.3    |\n",
      "|    value_loss         | 71.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.98     |\n",
      "|    ep_rew_mean        | 39.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 491      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0.742    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    value_loss         | 21.6     |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_PPO = PPO(\"MultiInputPolicy\", wrapped_env, verbose=1, tensorboard_log=TENSORBOARD_DIR+\"/ppo_binpack3d_tensorboard/\")\n",
    "model_PPO.learn(total_timesteps=10000)\n",
    "\n",
    "#use wrapped_env to train a A2C agent\n",
    "model_a2c = A2C(\"MultiInputPolicy\", wrapped_env, verbose=1, tensorboard_log=TENSORBOARD_DIR+\"/a2c_binpack3d_tensorboard/\")\n",
    "model_a2c.learn(total_timesteps=10000)\n",
    "\n",
    "#save the model\n",
    "model_PPO.save(DATA_DIR+\"/ppo_reward_wrapper\")\n",
    "model_a2c.save(DATA_DIR+\"/a2c_reward_wrapper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Step: 0, Best frame length: 0\n",
      "info: {'counter': 3, 'ratio': 0.035, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.7551038420890235, 'action_x_dist': 1.4616225884400078, 'reward_count': 0.9525741268224334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/miniconda3/envs/cs5446_ws/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:364: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: {'counter': 8, 'ratio': 0.0825, 'base_reward': 0.0, 'max_height': 2.7550546569602985, 'floor_space': -0.697676326071031, 'action_x_dist': 1.1224874728864698, 'reward_count': 0.9996646498695336}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlkh/Documents/GitHub/CS5446_AI_planning/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/BinPack3DEnv.py:198: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: {'counter': 10, 'ratio': 0.095, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.8382826032242335, 'action_x_dist': 1.7042875779324227, 'reward_count': 0.9999546021312976}\n",
      "info: {'counter': 15, 'ratio': 0.085, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.6040489749380253, 'action_x_dist': 0.7357588823428847, 'reward_count': 0.999999694097773}\n",
      "info: {'counter': 18, 'ratio': 0.175, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.697676326071031, 'action_x_dist': 1.8880549658356713, 'reward_count': 0.9999999847700205}\n",
      "info: {'counter': 29, 'ratio': 0.29, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.8382826032242335, 'action_x_dist': 1.5884317052330934, 'reward_count': 0.9999999999997455}\n",
      "Step: 100, Best frame length: 30\n",
      "Step: 200, Best frame length: 30\n",
      "Step: 300, Best frame length: 30\n",
      "Step: 400, Best frame length: 30\n",
      "Step: 500, Best frame length: 30\n",
      "Step: 600, Best frame length: 30\n",
      "Step: 700, Best frame length: 30\n",
      "Step: 800, Best frame length: 30\n",
      "Step: 900, Best frame length: 30\n",
      "Best ppo len:  30\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Step: 0, Best frame length: 0\n",
      "info: {'counter': 4, 'ratio': 0.05, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.7389684882589442, 'action_x_dist': 1.526148407202672, 'reward_count': 0.9820137900379085}\n",
      "info: {'counter': 6, 'ratio': 0.085, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.5357433806505847, 'action_x_dist': 1.9494498032035878, 'reward_count': 0.9975273768433653}\n",
      "info: {'counter': 8, 'ratio': 0.11, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.865541462221766, 'action_x_dist': 1.526148407202672, 'reward_count': 0.9996646498695336}\n",
      "info: {'counter': 9, 'ratio': 0.13, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.865541462221766, 'action_x_dist': 1.987240872758298, 'reward_count': 0.9998766054240137}\n",
      "info: {'counter': 10, 'ratio': 0.0625, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.6040489749380253, 'action_x_dist': 1.2595407628020063, 'reward_count': 0.9999546021312976}\n",
      "info: {'counter': 13, 'ratio': 0.0625, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.8521437889662113, 'action_x_dist': 1.4616225884400078, 'reward_count': 0.999997739675702}\n",
      "info: {'counter': 17, 'ratio': 0.22, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.7389684882589442, 'action_x_dist': 0.9219605724216672, 'reward_count': 0.9999999586006244}\n",
      "info: {'counter': 18, 'ratio': 0.0975, 'base_reward': 0.0, 'max_height': 2.2840254166877414, 'floor_space': -0.6724012623970027, 'action_x_dist': 1.9494498032035878, 'reward_count': 0.9999999847700205}\n",
      "info: {'counter': 23, 'ratio': 0.235, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.7709744845001153, 'action_x_dist': 1.4616225884400078, 'reward_count': 0.9999999998973812}\n",
      "Step: 100, Best frame length: 24\n",
      "Step: 200, Best frame length: 24\n",
      "Step: 300, Best frame length: 24\n",
      "info: {'counter': 30, 'ratio': 0.125, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -0.9568582668619097, 'action_x_dist': 1.1224874728864698, 'reward_count': 0.9999999999999065}\n",
      "Step: 400, Best frame length: 31\n",
      "Step: 500, Best frame length: 31\n",
      "Step: 600, Best frame length: 31\n",
      "Step: 700, Best frame length: 31\n",
      "Step: 800, Best frame length: 31\n",
      "Step: 900, Best frame length: 31\n",
      "Best a2c len:  31\n"
     ]
    }
   ],
   "source": [
    "#load the PPO model\n",
    "model_PPO = PPO.load(DATA_DIR+\"/ppo_reward_wrapper\", env=wrapped_env)\n",
    "best_frames = []\n",
    "best_PPO_rewards = []\n",
    "obs = model_PPO.env.reset()\n",
    "frame = model_PPO.env.render(mode=\"rgb_array\")\n",
    "done = False\n",
    "#save the longest sequence of frames for the gif\n",
    "max_framelen = 0\n",
    "for i in range(1000):\n",
    "    #count every 100 steps\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step: {i}, Best frame length: {max_framelen}\")\n",
    "    PPO_rewards = []\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frames.append(frame)\n",
    "        action, _state = model_PPO.predict(obs, deterministic=False)\n",
    "        obs, reward, done,_, info = wrapped_env.step(action.flatten())\n",
    "        # print(obs, reward, done, info)\n",
    "        PPO_rewards.append(reward + PPO_rewards[-1] if len(PPO_rewards) > 0 else reward)\n",
    "        frame = model_PPO.env.render(mode=\"rgb_array\")\n",
    "        if frame is None:\n",
    "            print(\"Frame is None!!\")\n",
    "            break\n",
    "        # VecEnv resets automatically\n",
    "        if done:\n",
    "            obs = model_PPO.env.reset()\n",
    "    #save the longest sequence of frames for the gif\n",
    "    if len(frames) > max_framelen:\n",
    "        max_framelen = len(frames)\n",
    "        best_frames = frames\n",
    "        best_PPO_rewards = PPO_rewards\n",
    "        print(f'info: {info}')\n",
    "    else:\n",
    "        frames = []\n",
    "        done = False\n",
    "\n",
    "print(\"Best ppo len: \", len(best_frames))\n",
    "imageio.mimsave(GIF_DIR+\"/ppo_wrapper\"+\".gif\", best_frames)\n",
    "\n",
    "#load the A2C model\n",
    "model_a2c = A2C.load(DATA_DIR+\"/a2c_reward_wrapper\", env=wrapped_env)\n",
    "best_frames = []\n",
    "best_A2C_rewards = []\n",
    "obs = model_a2c.env.reset()\n",
    "frame = model_a2c.env.render(mode=\"rgb_array\")\n",
    "done = False\n",
    "#save the longest sequence of frames for the gif\n",
    "max_framelen = 0\n",
    "for i in range(1000):\n",
    "    #count every 100 steps\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step: {i}, Best frame length: {max_framelen}\")\n",
    "    A2C_rewards = []\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frames.append(frame)\n",
    "        action, _state = model_a2c.predict(obs, deterministic=False)\n",
    "        obs, reward, done,_, info = wrapped_env.step(action.flatten())\n",
    "        # print(obs, reward, done, info)\n",
    "        A2C_rewards.append(reward + A2C_rewards[-1] if len(A2C_rewards) > 0 else reward)\n",
    "        frame = model_a2c.env.render(mode=\"rgb_array\")\n",
    "        if frame is None:\n",
    "            print(\"Frame is None!!\")\n",
    "            break\n",
    "        # VecEnv resets automatically\n",
    "        if done:\n",
    "            obs = model_a2c.env.reset()\n",
    "    #save the longest sequence of frames for the gif\n",
    "    if len(frames) > max_framelen:\n",
    "        max_framelen = len(frames)\n",
    "        best_frames = frames\n",
    "        best_A2C_rewards = A2C_rewards\n",
    "        print(f'info: {info}')\n",
    "    else:\n",
    "        frames = []\n",
    "        done = False\n",
    "\n",
    "print(\"Best a2c len: \", len(best_frames))\n",
    "imageio.mimsave(GIF_DIR+\"/a2c_wrapper\"+\".gif\", best_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "Container dimensions: (25, 4, 4), Container volume: 400, Floor space: 100\n",
      "{'counter': 1, 'ratio': 0.005, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.054584848086097, 'reward_count': 0.7310585786300049}\n",
      "{'counter': 2, 'ratio': 0.0075, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.8880549658356713, 'reward_count': 0.8807970779778823}\n",
      "{'counter': 3, 'ratio': 0.01, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.6040489749380253, 'action_x_dist': 1.971406368244886, 'reward_count': 0.9525741268224334}\n",
      "{'counter': 4, 'ratio': 0.015, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.7143373137359575, 'action_x_dist': 1.6479748666634064, 'reward_count': 0.9820137900379085}\n",
      "{'counter': 5, 'ratio': 0.025, 'base_reward': 0.1, 'max_height': 2.064494458917859, 'floor_space': -0.7470673031371956, 'action_x_dist': 1.9215788783046464, 'reward_count': 0.9933071490757153}\n",
      "{'counter': 6, 'ratio': 0.035, 'base_reward': 0.1, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.7042875779324227, 'reward_count': 0.9975273768433653}\n",
      "{'counter': 7, 'ratio': 0.0375, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 0.7357588823428847, 'reward_count': 0.9990889488055994}\n",
      "{'counter': 8, 'ratio': 0.04, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.5527220643033939, 'action_x_dist': 1.1224874728864698, 'reward_count': 0.9996646498695336}\n",
      "{'counter': 9, 'ratio': 0.045, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.2595407628020063, 'reward_count': 0.9998766054240137}\n",
      "{'counter': 10, 'ratio': 0.0475, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.8053368241618841, 'reward_count': 0.9999546021312976}\n",
      "{'counter': 11, 'ratio': 0.05, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.6479748666634064, 'reward_count': 0.999983298578152}\n",
      "{'counter': 12, 'ratio': 0.0525, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.6040489749380253, 'action_x_dist': 0.9876243960666924, 'reward_count': 0.9999938558253978}\n",
      "{'counter': 13, 'ratio': 0.0575, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.7568934786998627, 'reward_count': 0.999997739675702}\n",
      "{'counter': 14, 'ratio': 0.06, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.7143373137359575, 'action_x_dist': 1.327831526670947, 'reward_count': 0.9999991684719722}\n",
      "{'counter': 15, 'ratio': 0.065, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 0.9876243960666924, 'reward_count': 0.999999694097773}\n",
      "{'counter': 16, 'ratio': 0.0675, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.7225996099901936, 'action_x_dist': 0.7357588823428847, 'reward_count': 0.9999998874648379}\n",
      "{'counter': 17, 'ratio': 0.0725, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.697676326071031, 'action_x_dist': 1.2595407628020063, 'reward_count': 0.9999999586006244}\n",
      "{'counter': 18, 'ratio': 0.0775, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.987240872758298, 'reward_count': 0.9999999847700205}\n",
      "{'counter': 19, 'ratio': 0.08, 'base_reward': 0.025, 'max_height': 2.064494458917859, 'floor_space': -0.7551038420890235, 'action_x_dist': 1.9215788783046464, 'reward_count': 0.9999999943972036}\n",
      "{'counter': 20, 'ratio': 0.085, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.7225996099901936, 'action_x_dist': 0.7357588823428847, 'reward_count': 0.9999999979388463}\n",
      "{'counter': 21, 'ratio': 0.09, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.7225996099901936, 'action_x_dist': 1.9215788783046464, 'reward_count': 0.9999999992417439}\n",
      "{'counter': 22, 'ratio': 0.095, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.7225996099901936, 'action_x_dist': 0.7957638409024094, 'reward_count': 0.9999999997210531}\n",
      "{'counter': 23, 'ratio': 0.1, 'base_reward': 0.05, 'max_height': 2.064494458917859, 'floor_space': -0.9296937947569544, 'action_x_dist': 1.8491890295204214, 'reward_count': 0.9999999998973812}\n",
      "{'counter': 24, 'ratio': 0.11, 'base_reward': 0.1, 'max_height': 2.064494458917859, 'floor_space': -0.7551038420890235, 'action_x_dist': 1.327831526670947, 'reward_count': 0.9999999999622486}\n",
      "{'counter': 25, 'ratio': 0.12, 'base_reward': 0.1, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.9215788783046464, 'reward_count': 0.999999999986112}\n",
      "{'counter': 26, 'ratio': 0.1225, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 0.9219605724216672, 'reward_count': 0.999999999994891}\n",
      "{'counter': 27, 'ratio': 0.125, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.8491890295204214, 'reward_count': 0.9999999999981204}\n",
      "{'counter': 28, 'ratio': 0.1275, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.1224874728864698, 'reward_count': 0.9999999999993086}\n",
      "{'counter': 29, 'ratio': 0.1325, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.3827397594480691, 'action_x_dist': 1.987240872758298, 'reward_count': 0.9999999999997455}\n",
      "{'counter': 30, 'ratio': 0.1375, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.952752609803211, 'action_x_dist': 1.9215788783046464, 'reward_count': 0.9999999999999065}\n",
      "{'counter': 31, 'ratio': 0.1475, 'base_reward': 0.1, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.526148407202672, 'reward_count': 0.9999999999999656}\n",
      "{'counter': 32, 'ratio': 0.15, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.054584848086097, 'reward_count': 0.9999999999999873}\n",
      "{'counter': 33, 'ratio': 0.1525, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.395352652142062, 'reward_count': 0.9999999999999953}\n",
      "{'counter': 34, 'ratio': 0.1575, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 0.9876243960666924, 'reward_count': 0.9999999999999982}\n",
      "{'counter': 35, 'ratio': 0.16, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.7865492022134549, 'action_x_dist': 1.4616225884400078, 'reward_count': 0.9999999999999993}\n",
      "{'counter': 36, 'ratio': 0.165, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.3902764284635212, 'action_x_dist': 0.9219605724216672, 'reward_count': 0.9999999999999998}\n",
      "{'counter': 37, 'ratio': 0.17, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.36787944117144233, 'action_x_dist': 1.8880549658356713, 'reward_count': 1.0}\n",
      "{'counter': 38, 'ratio': 0.1725, 'base_reward': 0.025, 'max_height': 2.7550546569602985, 'floor_space': -0.3978819204512047, 'action_x_dist': 0.9219605724216672, 'reward_count': 1.0}\n",
      "{'counter': 39, 'ratio': 0.1775, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.7389684882589442, 'action_x_dist': 0.9219605724216672, 'reward_count': 1.0}\n",
      "{'counter': 40, 'ratio': 0.1825, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.9484748552256046, 'action_x_dist': 1.1909450844785396, 'reward_count': 1.0}\n",
      "{'counter': 41, 'ratio': 0.2025, 'base_reward': 0.2, 'max_height': 2.7550546569602985, 'floor_space': -0.4368785675332222, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 42, 'ratio': 0.2075, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.7470673031371956, 'action_x_dist': 1.9968025586352127, 'reward_count': 1.0}\n",
      "{'counter': 43, 'ratio': 0.2125, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.526148407202672, 'reward_count': 1.0}\n",
      "{'counter': 44, 'ratio': 0.2175, 'base_reward': 0.05, 'max_height': 2.7550546569602985, 'floor_space': -0.9645438342768154, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 45, 'ratio': 0.2275, 'base_reward': 0.1, 'max_height': 2.7550546569602985, 'floor_space': -0.7389684882589442, 'action_x_dist': 1.8053368241618841, 'reward_count': 1.0}\n",
      "{'counter': 46, 'ratio': 0.2325, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8092883481713321, 'action_x_dist': 1.8880549658356713, 'reward_count': 1.0}\n",
      "{'counter': 47, 'ratio': 0.2375, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.763074203601336, 'action_x_dist': 1.9215788783046464, 'reward_count': 1.0}\n",
      "{'counter': 48, 'ratio': 0.2475, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.8239874333317032, 'action_x_dist': 1.9215788783046464, 'reward_count': 1.0}\n",
      "{'counter': 49, 'ratio': 0.2525, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.8880549658356713, 'reward_count': 1.0}\n",
      "{'counter': 50, 'ratio': 0.2575, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9568582668619097, 'action_x_dist': 0.7957638409024094, 'reward_count': 1.0}\n",
      "{'counter': 51, 'ratio': 0.2675, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7143373137359575, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 52, 'ratio': 0.2775, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9440274829178357, 'action_x_dist': 1.8491890295204214, 'reward_count': 1.0}\n",
      "{'counter': 53, 'ratio': 0.2875, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.3978819204512047, 'action_x_dist': 1.987240872758298, 'reward_count': 1.0}\n",
      "{'counter': 54, 'ratio': 0.29, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.4773047992614458, 'action_x_dist': 1.9215788783046464, 'reward_count': 1.0}\n",
      "{'counter': 55, 'ratio': 0.295, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.4855368951540795, 'action_x_dist': 1.526148407202672, 'reward_count': 1.0}\n",
      "{'counter': 56, 'ratio': 0.3, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.4055545050633206, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 57, 'ratio': 0.3025, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.4938121980333462, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 58, 'ratio': 0.3075, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7389684882589442, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 59, 'ratio': 0.3125, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7551038420890235, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 60, 'ratio': 0.3225, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7709744845001153, 'action_x_dist': 1.054584848086097, 'reward_count': 1.0}\n",
      "{'counter': 61, 'ratio': 0.3325, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7865492022134549, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 62, 'ratio': 0.3425, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.4055545050633206, 'action_x_dist': 0.9876243960666924, 'reward_count': 1.0}\n",
      "{'counter': 63, 'ratio': 0.345, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.4055545050633206, 'action_x_dist': 1.395352652142062, 'reward_count': 1.0}\n",
      "{'counter': 64, 'ratio': 0.3475, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.4055545050633206, 'action_x_dist': 1.7568934786998627, 'reward_count': 1.0}\n",
      "{'counter': 65, 'ratio': 0.35, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.5527220643033939, 'action_x_dist': 1.8491890295204214, 'reward_count': 1.0}\n",
      "{'counter': 66, 'ratio': 0.355, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8166864825981108, 'action_x_dist': 0.7957638409024094, 'reward_count': 1.0}\n",
      "{'counter': 67, 'ratio': 0.36, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.5612437364432349, 'action_x_dist': 1.971406368244886, 'reward_count': 1.0}\n",
      "{'counter': 68, 'ratio': 0.365, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9346342525174487, 'action_x_dist': 1.2595407628020063, 'reward_count': 1.0}\n",
      "{'counter': 69, 'ratio': 0.375, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.4132923777703442, 'action_x_dist': 0.7957638409024094, 'reward_count': 1.0}\n",
      "{'counter': 70, 'ratio': 0.3775, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.7042875779324227, 'reward_count': 1.0}\n",
      "{'counter': 71, 'ratio': 0.3875, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.6554062543268405, 'action_x_dist': 1.987240872758298, 'reward_count': 1.0}\n",
      "{'counter': 72, 'ratio': 0.3925, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8847059049434836, 'action_x_dist': 1.6479748666634064, 'reward_count': 1.0}\n",
      "{'counter': 73, 'ratio': 0.4125, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.4132923777703442, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 74, 'ratio': 0.415, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.763074203601336, 'action_x_dist': 1.1909450844785396, 'reward_count': 1.0}\n",
      "{'counter': 75, 'ratio': 0.42, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7308112942200039, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 76, 'ratio': 0.43, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7551038420890235, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 77, 'ratio': 0.44, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.6554062543268405, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 78, 'ratio': 0.445, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7942158526165467, 'action_x_dist': 1.7042875779324227, 'reward_count': 1.0}\n",
      "{'counter': 79, 'ratio': 0.455, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.6808590290919248, 'action_x_dist': 1.7042875779324227, 'reward_count': 1.0}\n",
      "{'counter': 80, 'ratio': 0.46, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8092883481713321, 'action_x_dist': 0.9876243960666924, 'reward_count': 1.0}\n",
      "{'counter': 81, 'ratio': 0.47, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.697676326071031, 'action_x_dist': 0.857912797358146, 'reward_count': 1.0}\n",
      "{'counter': 82, 'ratio': 0.475, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.4448580662229411, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 83, 'ratio': 0.4775, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.697676326071031, 'action_x_dist': 1.9968025586352127, 'reward_count': 1.0}\n",
      "{'counter': 84, 'ratio': 0.4825, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9440274829178357, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 85, 'ratio': 0.5025, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.9607894391523232, 'action_x_dist': 1.6479748666634064, 'reward_count': 1.0}\n",
      "{'counter': 86, 'ratio': 0.5225, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.908373174209268, 'action_x_dist': 1.987240872758298, 'reward_count': 1.0}\n",
      "{'counter': 87, 'ratio': 0.5325, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.908373174209268, 'action_x_dist': 1.8053368241618841, 'reward_count': 1.0}\n",
      "{'counter': 88, 'ratio': 0.5425, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9296937947569544, 'action_x_dist': 1.8053368241618841, 'reward_count': 1.0}\n",
      "{'counter': 89, 'ratio': 0.5525, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.8166864825981108, 'action_x_dist': 0.9876243960666924, 'reward_count': 1.0}\n",
      "{'counter': 90, 'ratio': 0.5575, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9394130628134758, 'action_x_dist': 0.9876243960666924, 'reward_count': 1.0}\n",
      "{'counter': 91, 'ratio': 0.5675, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9440274829178357, 'action_x_dist': 0.9219605724216672, 'reward_count': 1.0}\n",
      "{'counter': 92, 'ratio': 0.5775, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7709744845001153, 'action_x_dist': 1.971406368244886, 'reward_count': 1.0}\n",
      "{'counter': 93, 'ratio': 0.5825, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9484748552256046, 'action_x_dist': 0.9219605724216672, 'reward_count': 1.0}\n",
      "{'counter': 94, 'ratio': 0.5925, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.46911844239466416, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 95, 'ratio': 0.595, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.952752609803211, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 96, 'ratio': 0.605, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9879729106308383, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 97, 'ratio': 0.625, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.9645438342768154, 'action_x_dist': 1.8491890295204214, 'reward_count': 1.0}\n",
      "{'counter': 98, 'ratio': 0.635, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7942158526165467, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 99, 'ratio': 0.64, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9681192569165628, 'action_x_dist': 1.9968025586352127, 'reward_count': 1.0}\n",
      "{'counter': 100, 'ratio': 0.65, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.4938121980333462, 'action_x_dist': 1.2595407628020063, 'reward_count': 1.0}\n",
      "{'counter': 101, 'ratio': 0.6525, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.7865492022134549, 'action_x_dist': 1.2595407628020063, 'reward_count': 1.0}\n",
      "{'counter': 102, 'ratio': 0.6575, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.7942158526165467, 'action_x_dist': 1.987240872758298, 'reward_count': 1.0}\n",
      "{'counter': 103, 'ratio': 0.6625, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9777512371933363, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 104, 'ratio': 0.6725, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9805908312024284, 'action_x_dist': 1.7568934786998627, 'reward_count': 1.0}\n",
      "{'counter': 105, 'ratio': 0.6825, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9832420039192554, 'action_x_dist': 1.395352652142062, 'reward_count': 1.0}\n",
      "{'counter': 106, 'ratio': 0.6925, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.985703184122443, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 107, 'ratio': 0.7025, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.8521437889662113, 'action_x_dist': 1.054584848086097, 'reward_count': 1.0}\n",
      "{'counter': 108, 'ratio': 0.7075, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9900498337491681, 'action_x_dist': 0.9876243960666924, 'reward_count': 1.0}\n",
      "{'counter': 109, 'ratio': 0.7175, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9919327166055711, 'action_x_dist': 0.7957638409024094, 'reward_count': 1.0}\n",
      "{'counter': 110, 'ratio': 0.7275, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.8720574275147192, 'action_x_dist': 1.1909450844785396, 'reward_count': 1.0}\n",
      "{'counter': 111, 'ratio': 0.7325, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.569782824730923, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 112, 'ratio': 0.735, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9984012793176064, 'action_x_dist': 1.8880549658356713, 'reward_count': 1.0}\n",
      "{'counter': 113, 'ratio': 0.755, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.9996000799893344, 'action_x_dist': 1.526148407202672, 'reward_count': 1.0}\n",
      "{'counter': 114, 'ratio': 0.775, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.9440274829178357, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 115, 'ratio': 0.785, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9984012793176064, 'action_x_dist': 1.8053368241618841, 'reward_count': 1.0}\n",
      "{'counter': 116, 'ratio': 0.795, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9999000049998333, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 117, 'ratio': 0.815, 'base_reward': 0.2, 'max_height': 3.718281828459045, 'floor_space': -0.8239874333317032, 'action_x_dist': 0.7957638409024094, 'reward_count': 1.0}\n",
      "{'counter': 118, 'ratio': 0.82, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.629770381401003, 'action_x_dist': 0.857912797358146, 'reward_count': 1.0}\n",
      "{'counter': 119, 'ratio': 0.8225, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.638329928495075, 'action_x_dist': 1.054584848086097, 'reward_count': 1.0}\n",
      "{'counter': 120, 'ratio': 0.825, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.8521437889662113, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 121, 'ratio': 0.83, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8166864825981108, 'action_x_dist': 1.054584848086097, 'reward_count': 1.0}\n",
      "{'counter': 122, 'ratio': 0.835, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9440274829178357, 'action_x_dist': 1.9494498032035878, 'reward_count': 1.0}\n",
      "{'counter': 123, 'ratio': 0.845, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9999000049998333, 'action_x_dist': 1.327831526670947, 'reward_count': 1.0}\n",
      "{'counter': 124, 'ratio': 0.855, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9394130628134758, 'action_x_dist': 1.7568934786998627, 'reward_count': 1.0}\n",
      "{'counter': 125, 'ratio': 0.865, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9568582668619097, 'action_x_dist': 1.1909450844785396, 'reward_count': 1.0}\n",
      "{'counter': 126, 'ratio': 0.875, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.7788007830714049, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 127, 'ratio': 0.8775, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.7865492022134549, 'action_x_dist': 1.8491890295204214, 'reward_count': 1.0}\n",
      "{'counter': 128, 'ratio': 0.88, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.7942158526165467, 'action_x_dist': 1.395352652142062, 'reward_count': 1.0}\n",
      "{'counter': 129, 'ratio': 0.8825, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9394130628134758, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 130, 'ratio': 0.8875, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.8166864825981108, 'action_x_dist': 0.857912797358146, 'reward_count': 1.0}\n",
      "{'counter': 131, 'ratio': 0.89, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.8239874333317032, 'action_x_dist': 1.1909450844785396, 'reward_count': 1.0}\n",
      "{'counter': 132, 'ratio': 0.8925, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.952752609803211, 'action_x_dist': 1.2595407628020063, 'reward_count': 1.0}\n",
      "{'counter': 133, 'ratio': 0.8975, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9919327166055711, 'action_x_dist': 1.6479748666634064, 'reward_count': 1.0}\n",
      "{'counter': 134, 'ratio': 0.9075, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.8720574275147192, 'action_x_dist': 1.971406368244886, 'reward_count': 1.0}\n",
      "{'counter': 135, 'ratio': 0.91, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9568582668619097, 'action_x_dist': 0.857912797358146, 'reward_count': 1.0}\n",
      "{'counter': 136, 'ratio': 0.915, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9607894391523232, 'action_x_dist': 1.8880549658356713, 'reward_count': 1.0}\n",
      "{'counter': 137, 'ratio': 0.92, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9715136109702958, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 138, 'ratio': 0.925, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9777512371933363, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 139, 'ratio': 0.93, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9245945147602107, 'action_x_dist': 1.6479748666634064, 'reward_count': 1.0}\n",
      "{'counter': 140, 'ratio': 0.9325, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9296937947569544, 'action_x_dist': 1.7568934786998627, 'reward_count': 1.0}\n",
      "{'counter': 141, 'ratio': 0.935, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9346342525174487, 'action_x_dist': 1.8053368241618841, 'reward_count': 1.0}\n",
      "{'counter': 142, 'ratio': 0.9375, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9805908312024284, 'action_x_dist': 1.987240872758298, 'reward_count': 1.0}\n",
      "{'counter': 143, 'ratio': 0.9425, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9879729106308383, 'action_x_dist': 0.9219605724216672, 'reward_count': 1.0}\n",
      "{'counter': 144, 'ratio': 0.9475, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9900498337491681, 'action_x_dist': 1.7568934786998627, 'reward_count': 1.0}\n",
      "{'counter': 145, 'ratio': 0.9525, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9645438342768154, 'action_x_dist': 1.1224874728864698, 'reward_count': 1.0}\n",
      "{'counter': 146, 'ratio': 0.955, 'base_reward': 0.025, 'max_height': 3.718281828459045, 'floor_space': -0.9919327166055711, 'action_x_dist': 1.5884317052330934, 'reward_count': 1.0}\n",
      "{'counter': 147, 'ratio': 0.96, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9975031223974601, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 148, 'ratio': 0.97, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9991004048785274, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 149, 'ratio': 0.98, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -0.9984012793176064, 'action_x_dist': 1.4616225884400078, 'reward_count': 1.0}\n",
      "{'counter': 150, 'ratio': 0.985, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9991004048785274, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 151, 'ratio': 0.99, 'base_reward': 0.05, 'max_height': 3.718281828459045, 'floor_space': -0.9999000049998333, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n",
      "{'counter': 152, 'ratio': 1.0, 'base_reward': 0.1, 'max_height': 3.718281828459045, 'floor_space': -1.0, 'action_x_dist': 1.7042875779324227, 'reward_count': 1.0}\n",
      "{'counter': 152, 'ratio': 1.0, 'base_reward': 0.0, 'max_height': 3.718281828459045, 'floor_space': -1.0, 'action_x_dist': 0.7357588823428847, 'reward_count': 1.0}\n"
     ]
    }
   ],
   "source": [
    "base_env = gym.make('BinPack3D-v1', \n",
    "             container_size = (25, 4, 4), #(9, 11, 13),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1, # 2\n",
    "                maxSideLen = 2, # 5\n",
    "            )\n",
    "wrapped_env = RewardWrapper(base_env)\n",
    "\n",
    "\n",
    "frames = []\n",
    "obs = wrapped_env.reset()\n",
    "frame = wrapped_env.render()\n",
    "wrapped_env_rewards = []\n",
    "while True:\n",
    "    frames.append(frame)\n",
    "    box = wrapped_env.boxSeqGenerator.next_N_boxes()[0]\n",
    "    pos = (box.x,box.y)\n",
    "    act_pos = wrapped_env.position_to_actionIdx(pos)\n",
    "    rot = Rotate.NOOP\n",
    "    action = (act_pos, rot)\n",
    "\n",
    "    obs, reward, done,_, info = wrapped_env.step(action)\n",
    "    frame = wrapped_env.render()\n",
    "    print(info)\n",
    "    # print(reward,done,info)\n",
    "    wrapped_env_rewards.append(reward + wrapped_env_rewards[-1] if len(wrapped_env_rewards) > 0 else reward)\n",
    "    \n",
    "    if done: break\n",
    "\n",
    "wrapped_env.render()\n",
    "# print(obs)\n",
    "imageio.mimsave(GIF_DIR+\"/modified.gif\", frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#clear the plots\n",
    "plt.close(\"all\")\n",
    "#plot the rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rewards, label=\"baseline\")\n",
    "plt.plot(wrapped_env_rewards, label=\"modified_reward\")\n",
    "plt.plot(PPO_rewards, label=\"PPO\")\n",
    "plt.plot(A2C_rewards, label=\"A2C\")\n",
    "#limit the range of the x-axis to the number of steps of A2C\n",
    "plt.xlim(0, max(len(PPO_rewards), len(A2C_rewards)))\n",
    "#scale the y-axis to the range of the rewards\n",
    "plt.ylim(-4, 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the observation space\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).flatten()\n",
    "    \n",
    "base_env = gym.make('BinPack3D-v1',\n",
    "                container_size = (9, 11, 13),\n",
    "                    boxSeqGenerator='CUT-2', \n",
    "                    enabled_rotations = [Rotate.NOOP],\n",
    "                    n_foreseeable_box = 3,\n",
    "                    minSideLen = 2,\n",
    "                    maxSideLen = 5,\n",
    "                )\n",
    "wrapped_env = FlattenObservation(base_env)\n",
    "\n",
    "#we want to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a random agent to test the environment\n",
    "from gymnasium import Wrapper\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class RandomAgent(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.Prob = self.calculate_Prob()\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        return obs, reward, done, truncated, info\n",
    "    \n",
    "    def act(self, obs):\n",
    "        #choose a random position from the action space. action space is a multi-discrete space\n",
    "        (x, y) = self.env.action_space.sample()\n",
    "        print(self.env.action_space, x, y, self.env.container_size)\n",
    "        pos = x\n",
    "        rot = random.choice(self.env.enabled_rotations)\n",
    "        return (pos, rot)\n",
    "    \n",
    "    def create_agent(self, **kwargs):\n",
    "        agent = ValueIterationAgent(env = self.env, gamma=0.9, theta=0.0001, max_iter=1000)\n",
    "        agent.initialize()\n",
    "\n",
    "        return agent\n",
    "    \n",
    "    def calculate_Prob(self):\n",
    "        #calculate the transition probabilities\n",
    "        Prob = np.zeros((self.env.observation_space.nvec[0], self.env.action_space.n, self.env.observation_space.nvec[0]))\n",
    "        for s in range(self.env.observation_space.nvec[0]):\n",
    "            for a in range(self.env.action_space.n):\n",
    "                for s_prime in range(self.env.observation_space.nvec[0]):\n",
    "                    Prob[s, a, s_prime] = self.env.calculate_prob(s, a, s_prime)\n",
    "                    \n",
    "        return Prob\n",
    "\n",
    "class ValueIterationAgent(object):\n",
    "    def __init__(self, env=None, gamma=0.99, theta=0.001, max_iter=1000):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.disc_actions = self.env.action_space.nvec\n",
    "        self.disc_states = self.env.observation_space.nvec\n",
    "        self.Prob = self.env.Prob\n",
    "\n",
    "    def initialize(self):\n",
    "        self.value_policy, self.policy_function = self.value_iteration()\n",
    "\n",
    "    def value_iteration(self):\n",
    "        value_policy = np.zeros(self.disc_states)\n",
    "        policy_function = np.zeros(self.disc_states)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            delta = 0\n",
    "            for s in range(self.disc_states):\n",
    "                v = value_policy[s]\n",
    "                value_policy[s] = self.calculate_value(s, value_policy)\n",
    "                delta = max(delta, abs(v - value_policy[s]))\n",
    "\n",
    "            if delta < self.theta:\n",
    "                print('Converged at iteration', i)\n",
    "                break\n",
    "\n",
    "        for s in range(self.disc_states):\n",
    "            policy_function[s] = self.calculate_policy(s, value_policy)\n",
    "\n",
    "        return value_policy, policy_function\n",
    "    \n",
    "    def calculate_value(self, s, value_policy):\n",
    "        max_val = float('-inf')\n",
    "        for a in range(self.env.action_space.n):\n",
    "            val = 0\n",
    "            for s_prime in range(self.disc_states):\n",
    "                val += self.Prob[s, a, s_prime] * (self.env.R[s, a, s_prime] + self.gamma * value_policy[s_prime])\n",
    "            max_val = max(max_val, val)\n",
    "        return max_val\n",
    "    \n",
    "    def calculate_policy(self, s, value_policy):\n",
    "        max_val = float('-inf')\n",
    "        max_action = 0\n",
    "        for a in range(self.env.action_space.n):\n",
    "            val = 0\n",
    "            for s_prime in range(self.disc_states):\n",
    "                val += self.Prob[s, a, s_prime] * (self.env.R[s, a, s_prime] + self.gamma * value_policy[s_prime])\n",
    "            if val > max_val:\n",
    "                max_val = val\n",
    "                max_action = a\n",
    "        return max_action\n",
    "\n",
    "base_env = gym.make('BinPack3D-v1', \n",
    "                    container_size = (9, 11, 13),\n",
    "                    boxSeqGenerator='CUT-2', \n",
    "                    enabled_rotations = [Rotate.NOOP],\n",
    "                    n_foreseeable_box = 3,\n",
    "                    minSideLen = 2,\n",
    "                    maxSideLen = 5,\n",
    "                    )\n",
    "wrapped_env = RandomAgent(base_env)\n",
    "\n",
    "frames = []\n",
    "obs = wrapped_env.reset()\n",
    "frame = wrapped_env.render()\n",
    "rewards = []\n",
    "for i in range(100):\n",
    "    frames.append(frame)\n",
    "    action = wrapped_env.act(obs)\n",
    "    obs, reward, done,_, info = wrapped_env.step(action)\n",
    "    frame = wrapped_env.render()\n",
    "    print(reward,done,info)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "\n",
    "wrapped_env.render()\n",
    "\n",
    "imageio.mimsave(DATA_DIR+\"/random.gif\", frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5446_ws]",
   "language": "python",
   "name": "conda-env-cs5446_ws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

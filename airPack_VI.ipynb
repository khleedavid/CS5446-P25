{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies for the project\n",
    "import gymnasium as gym\n",
    "import gym_BinPack3D\n",
    "from gym_BinPack3D.envs import Box, Rotate\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.path.join(os.getcwd(), '')\n",
    "DATA_DIR = os.path.join(CWD, 'data')\n",
    "GIF_DIR = os.path.join(CWD, 'gifs')\n",
    "TENSORBOARD_DIR = os.path.join(CWD, 'tensorboard')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(GIF_DIR, exist_ok=True)\n",
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultiDiscrete([100   4]),\n",
       " Dict('coming_boxes': Box(0.0, 25.0, (3, 3), float32), 'height_map': Box(0.0, 4.0, (25, 4), float32), 'valid_placement_mask': MultiBinary((4, 25, 4))))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#register the environment\n",
    "gym.envs.register(\n",
    "    id='BinPack3D-v1',\n",
    "    entry_point='gym_BinPack3D.envs:PackingGame',\n",
    ")\n",
    "\n",
    "#define the environment.\n",
    "#container_size: size of the container in 3D\n",
    "#boxSeqGenerator: how the boxes are generated.\n",
    "#enabled_rotations: which rotations are allowed for the boxes\n",
    "#n_foreseeable_box: how many boxes are shown to the agent\n",
    "#box_set: the set of boxes that are used in the environment. \n",
    "\n",
    "env = gym.make('BinPack3D-v1', \n",
    "                container_size = (25, 4, 4),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP, Rotate.XY, Rotate.XZ, Rotate.YZ],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1,\n",
    "                maxSideLen = 2,\n",
    "            )\n",
    "\n",
    "\n",
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Baseline Agent\n",
    "Here we load an agent with perfect information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "(2, 2) (10, <Rotate.NOOP: 0>) 48.0\n",
      "(10, 2) (42, <Rotate.NOOP: 0>) 40.0\n",
      "(3, 1) (13, <Rotate.NOOP: 0>) 47.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.boxSeqGenerator to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.boxSeqGenerator` for environment variables or `env.get_wrapper_attr('boxSeqGenerator')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.position_to_actionIdx to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.position_to_actionIdx` for environment variables or `env.get_wrapper_attr('position_to_actionIdx')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1) (65, <Rotate.NOOP: 0>) 34.0\n",
      "(15, 1) (61, <Rotate.NOOP: 0>) 35.0\n",
      "(8, 1) (33, <Rotate.NOOP: 0>) 42.0\n",
      "(8, 0) (32, <Rotate.NOOP: 0>) 42.0\n",
      "(3, 1) (13, <Rotate.NOOP: 0>) 47.0\n",
      "(10, 0) (40, <Rotate.NOOP: 0>) 40.0\n",
      "(15, 1) (61, <Rotate.NOOP: 0>) 35.0\n",
      "(13, 0) (52, <Rotate.NOOP: 0>) 37.0\n",
      "(7, 0) (28, <Rotate.NOOP: 0>) 43.0\n",
      "(23, 0) (92, <Rotate.NOOP: 0>) 27.0\n",
      "(22, 1) (89, <Rotate.NOOP: 0>) 28.0\n",
      "(13, 1) (53, <Rotate.NOOP: 0>) 37.0\n",
      "(14, 0) (56, <Rotate.NOOP: 0>) 36.0\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 31.0\n",
      "(5, 1) (21, <Rotate.NOOP: 0>) 45.0\n",
      "(5, 1) (21, <Rotate.NOOP: 0>) 45.0\n",
      "(0, 3) (3, <Rotate.NOOP: 0>) 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/Documents/GitHub-khlee/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/BinPack3DEnv.py:211: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2) (30, <Rotate.NOOP: 0>) 43.0\n",
      "(9, 1) (37, <Rotate.NOOP: 0>) 41.0\n",
      "(5, 3) (23, <Rotate.NOOP: 0>) 45.0\n",
      "(19, 1) (77, <Rotate.NOOP: 0>) 31.0\n",
      "(2, 3) (11, <Rotate.NOOP: 0>) 48.0\n",
      "(17, 1) (69, <Rotate.NOOP: 0>) 33.0\n",
      "(7, 3) (31, <Rotate.NOOP: 0>) 43.0\n",
      "(12, 1) (49, <Rotate.NOOP: 0>) 38.0\n",
      "(8, 1) (33, <Rotate.NOOP: 0>) 42.0\n",
      "(3, 2) (14, <Rotate.NOOP: 0>) 47.0\n",
      "(9, 0) (36, <Rotate.NOOP: 0>) 41.0\n",
      "(16, 3) (67, <Rotate.NOOP: 0>) 34.0\n",
      "(0, 1) (1, <Rotate.NOOP: 0>) 50.0\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 50.0\n",
      "(21, 3) (87, <Rotate.NOOP: 0>) 29.0\n",
      "(12, 0) (48, <Rotate.NOOP: 0>) 38.0\n",
      "(20, 2) (82, <Rotate.NOOP: 0>) 30.0\n",
      "(5, 3) (23, <Rotate.NOOP: 0>) 45.0\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 31.0\n",
      "(0, 1) (1, <Rotate.NOOP: 0>) 50.0\n",
      "(23, 0) (92, <Rotate.NOOP: 0>) 27.0\n",
      "(12, 3) (51, <Rotate.NOOP: 0>) 38.0\n",
      "(2, 0) (8, <Rotate.NOOP: 0>) 48.0\n",
      "(2, 2) (10, <Rotate.NOOP: 0>) 48.0\n",
      "(8, 3) (35, <Rotate.NOOP: 0>) 42.0\n",
      "(13, 0) (52, <Rotate.NOOP: 0>) 37.0\n",
      "(22, 0) (88, <Rotate.NOOP: 0>) 28.0\n",
      "(20, 3) (83, <Rotate.NOOP: 0>) 30.0\n",
      "(3, 0) (12, <Rotate.NOOP: 0>) 47.0\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 45.0\n",
      "(17, 3) (71, <Rotate.NOOP: 0>) 33.0\n",
      "(4, 2) (18, <Rotate.NOOP: 0>) 46.0\n",
      "(10, 1) (41, <Rotate.NOOP: 0>) 40.0\n",
      "(23, 2) (94, <Rotate.NOOP: 0>) 27.0\n",
      "(8, 3) (35, <Rotate.NOOP: 0>) 42.0\n",
      "(16, 0) (64, <Rotate.NOOP: 0>) 34.0\n",
      "(4, 3) (19, <Rotate.NOOP: 0>) 46.0\n",
      "(17, 0) (68, <Rotate.NOOP: 0>) 33.0\n",
      "(10, 3) (43, <Rotate.NOOP: 0>) 40.0\n",
      "(10, 0) (40, <Rotate.NOOP: 0>) 40.0\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 31.0\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 30.0\n",
      "(2, 3) (11, <Rotate.NOOP: 0>) 48.0\n",
      "(13, 3) (55, <Rotate.NOOP: 0>) 37.0\n",
      "(15, 3) (63, <Rotate.NOOP: 0>) 35.0\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 45.0\n",
      "(23, 3) (95, <Rotate.NOOP: 0>) 27.0\n",
      "(0, 3) (3, <Rotate.NOOP: 0>) 50.0\n",
      "(16, 1) (65, <Rotate.NOOP: 0>) 34.0\n",
      "(8, 1) (33, <Rotate.NOOP: 0>) 42.0\n",
      "(17, 2) (70, <Rotate.NOOP: 0>) 33.0\n",
      "(17, 3) (71, <Rotate.NOOP: 0>) 33.0\n",
      "(10, 2) (42, <Rotate.NOOP: 0>) 40.0\n",
      "(7, 0) (28, <Rotate.NOOP: 0>) 43.0\n",
      "(23, 2) (94, <Rotate.NOOP: 0>) 27.0\n",
      "(2, 0) (8, <Rotate.NOOP: 0>) 48.0\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 31.0\n",
      "(22, 0) (88, <Rotate.NOOP: 0>) 28.0\n",
      "(11, 1) (45, <Rotate.NOOP: 0>) 39.0\n",
      "(23, 3) (95, <Rotate.NOOP: 0>) 27.0\n",
      "(20, 3) (83, <Rotate.NOOP: 0>) 30.0\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 50.0\n",
      "(15, 3) (63, <Rotate.NOOP: 0>) 35.0\n",
      "(13, 3) (55, <Rotate.NOOP: 0>) 37.0\n",
      "(0, 1) (1, <Rotate.NOOP: 0>) 50.0\n",
      "(22, 2) (90, <Rotate.NOOP: 0>) 28.0\n",
      "(6, 1) (25, <Rotate.NOOP: 0>) 44.0\n",
      "(13, 1) (53, <Rotate.NOOP: 0>) 37.0\n",
      "(15, 0) (60, <Rotate.NOOP: 0>) 35.0\n",
      "(6, 3) (27, <Rotate.NOOP: 0>) 44.0\n",
      "(13, 1) (53, <Rotate.NOOP: 0>) 37.0\n",
      "(12, 3) (51, <Rotate.NOOP: 0>) 38.0\n",
      "(11, 0) (44, <Rotate.NOOP: 0>) 39.0\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 30.0\n",
      "(15, 3) (63, <Rotate.NOOP: 0>) 35.0\n",
      "(16, 3) (67, <Rotate.NOOP: 0>) 34.0\n",
      "(8, 0) (32, <Rotate.NOOP: 0>) 42.0\n",
      "(9, 3) (39, <Rotate.NOOP: 0>) 41.0\n",
      "(23, 2) (94, <Rotate.NOOP: 0>) 27.0\n",
      "(16, 1) (65, <Rotate.NOOP: 0>) 34.0\n",
      "(22, 3) (91, <Rotate.NOOP: 0>) 28.0\n",
      "(1, 1) (5, <Rotate.NOOP: 0>) 49.0\n",
      "(13, 3) (55, <Rotate.NOOP: 0>) 37.0\n",
      "(7, 3) (31, <Rotate.NOOP: 0>) 43.0\n",
      "(1, 3) (7, <Rotate.NOOP: 0>) 49.0\n",
      "(11, 0) (44, <Rotate.NOOP: 0>) 39.0\n",
      "(17, 0) (68, <Rotate.NOOP: 0>) 33.0\n",
      "(19, 0) (76, <Rotate.NOOP: 0>) 31.0\n",
      "(5, 0) (20, <Rotate.NOOP: 0>) 45.0\n",
      "(5, 2) (22, <Rotate.NOOP: 0>) 45.0\n",
      "(7, 2) (30, <Rotate.NOOP: 0>) 43.0\n",
      "(10, 0) (40, <Rotate.NOOP: 0>) 40.0\n",
      "(3, 0) (12, <Rotate.NOOP: 0>) 47.0\n",
      "(0, 2) (2, <Rotate.NOOP: 0>) 50.0\n",
      "(3, 3) (15, <Rotate.NOOP: 0>) 47.0\n",
      "(5, 3) (23, <Rotate.NOOP: 0>) 45.0\n",
      "(20, 1) (81, <Rotate.NOOP: 0>) 30.0\n",
      "(16, 3) (67, <Rotate.NOOP: 0>) 34.0\n",
      "(17, 2) (70, <Rotate.NOOP: 0>) 33.0\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) 50.0\n",
      "(19, 2) (78, <Rotate.NOOP: 0>) 31.0\n",
      "(1, 0) (4, <Rotate.NOOP: 0>) 49.0\n",
      "(11, 2) (46, <Rotate.NOOP: 0>) 39.0\n",
      "(4, 0) (16, <Rotate.NOOP: 0>) 46.0\n",
      "(18, 0) (72, <Rotate.NOOP: 0>) 32.0\n",
      "(9, 3) (39, <Rotate.NOOP: 0>) 41.0\n",
      "(7, 0) (28, <Rotate.NOOP: 0>) 43.0\n",
      "(20, 0) (80, <Rotate.NOOP: 0>) 30.0\n",
      "(3, 3) (15, <Rotate.NOOP: 0>) 47.0\n",
      "(21, 0) (84, <Rotate.NOOP: 0>) 29.0\n",
      "(3, 0) (12, <Rotate.NOOP: 0>) 47.0\n",
      "(17, 0) (68, <Rotate.NOOP: 0>) 33.0\n",
      "(4, 3) (19, <Rotate.NOOP: 0>) 46.0\n",
      "(21, 2) (86, <Rotate.NOOP: 0>) 29.0\n",
      "(0, 0) (0, <Rotate.NOOP: 0>) -200\n"
     ]
    }
   ],
   "source": [
    "#load the environment with a baseline agent\n",
    "env = gym.make('BinPack3D-v1', \n",
    "             container_size = (25, 4, 4),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1,\n",
    "                maxSideLen = 2,\n",
    "            )\n",
    "\n",
    "#default container size is (9, 11, 13), with maxSideLen = 5, minSideLen = 2\n",
    "#container size for our game is (25, 4, 4), with maxSideLen = 2, minSideLen = 1\n",
    "\n",
    "frames = []\n",
    "obs = env.reset()\n",
    "#set environment to render rgb_array\n",
    "frame = env.render()\n",
    "rewards = []\n",
    "while True:\n",
    "    frames.append(frame)\n",
    "    # we cheat the game by look at cut process info and get the \n",
    "    # correct pos to place box, achieving perfect packing\n",
    "    box = env.boxSeqGenerator.next_N_boxes()[0]\n",
    "    pos = (box.x,box.y)\n",
    "    act_pos = env.position_to_actionIdx(pos)\n",
    "    rot = Rotate.NOOP\n",
    "    action = (act_pos, rot)\n",
    "\n",
    "    obs, reward, done,_, info = env.step(action)\n",
    "    frame = env.render()\n",
    "    # print(reward,done,info)\n",
    "    print(pos, action, reward)\n",
    "    rewards.append(reward + rewards[-1] if len(rewards) > 0 else reward)\n",
    "    \n",
    "    if done: break\n",
    "        \n",
    "env.render()\n",
    "\n",
    "imageio.mimsave(GIF_DIR+\"/baseline.gif\", frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using wrapped reward function\n",
    "We define a perfect agent who has knowledge of the exact order of boxes to be placed in the environment by providing the 'CUT-2' sequence order.\n",
    "\n",
    "Then, we want to train an agent who does not have knowledge of the exact order of boxes to stack the incoming boxes.\n",
    "\n",
    "Modifying the reward, we train a PPO and A2C agent using stable_baselines3 to see if the agent is able to change its behavior based on its reward function.\n",
    "We plot the reward in comparison with the perfect agent to test its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test using a wrapper to modify the reward\n",
    "\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class RewardWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.container_volume = env.container_size[0] * env.container_size[1] * env.container_size[2]\n",
    "        self.floor_space = env.container_size[0] * env.container_size[1]\n",
    "        self.prev_floor_space = 0\n",
    "        print(f\"Container dimensions: {env.container_size}, Container volume: {self.container_volume}, Floor space: {self.floor_space}\")\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "\n",
    "        base_reward = reward        \n",
    "        #base reward is the current ratio of boxes placed in the container to the total volume of the container.\n",
    "        # we want to minimize the floor space used by the boxes and maximize the height of the boxes.\n",
    "        # we weight the height as a positive reward and the floor space as a negative reward.\n",
    "        # height should be modified by the max height of the current box.\n",
    "        ratio_height = obs['height_map'].max() / env.container_size[2]\n",
    "        # larger height is better. use sigmoid to reward the agent for placing boxes higher. limit the range of the reward to -1 to 1.\n",
    "        if ratio_height > 1: #this means that the agent has placed a box that is higher than the container. we should penalize this heavily.\n",
    "            curr_max_height = -100\n",
    "        else:\n",
    "            curr_max_height = np.exp(ratio_height**2) + 1\n",
    "        \n",
    "        # floor space should be modified by the current floor space of the container. we want to minimize this and penalize the agent for using more floor space.\n",
    "        curr_floor_space = obs['valid_placement_mask'].sum() / self.floor_space\n",
    "        # smaller floor space is better. use sigmoid to penalize the agent for using more floor space.\n",
    "        curr_floor_space = -np.exp(-curr_floor_space**2) * 5\n",
    "\n",
    "        #reward longer sequences of boxes placed in the container. we want to maximize the number of boxes placed in the container.\n",
    "        curr_count = info['counter']\n",
    "        # larger count is better. use sigmoid to reward the agent for placing more boxes. limit the range of the reward to -1 to 1.\n",
    "        reward_count = (1+np.exp(-curr_count))**-1\n",
    "\n",
    "        #if action placement is near the x axis, reward the agent\n",
    "        #get the position of the action in x,y coordinates, and express the x coordinate as a fraction of the container length.\n",
    "        act_pos = self.env.actionIdx_to_position(action[0])[0] / self.env.container_size[0] -1\n",
    "        #smaller x position is better. use sigmoid to reward the agent for placing boxes near the x axis. limit the range of the reward to -1 to 1.\n",
    "        act_x_dist = np.exp(-act_pos**2) *5\n",
    "        # Encourage starting from the back of the container and filling towards the front\n",
    "        # if the max x position of the boxes is greater than the position of the current box, penalize the agent\n",
    "        # get map of boxes placed in the container\n",
    "        # max_x = obs[]\n",
    "\n",
    "        x_penalty = (box.x / self.container.dx) * 5  # Increase penalty as x increases\n",
    "\n",
    "\n",
    "        #modify the reward. base reward is the current ratio of boxes placed in the container to the total volume of the container.\n",
    "        reward = base_reward + curr_max_height + curr_floor_space + reward_count + act_x_dist - x_penalty\n",
    "        if done:\n",
    "            reward = -100\n",
    "\n",
    "        #add reward details to the info dictionary\n",
    "        info['base_reward'] = base_reward\n",
    "        info['max_height'] = curr_max_height\n",
    "        info['floor_space'] = curr_floor_space\n",
    "        info['action_x_dist'] = act_x_dist\n",
    "        info['reward_count'] = reward_count\n",
    "        info['x_penalty'] = x_penalty\n",
    "\n",
    "        # print(f\"Base reward: {base_reward}, Modified reward: {reward}, Max height: {curr_max_height}, Floor space: {curr_floor_space}\")\n",
    "        \n",
    "        return obs, reward, done, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:21:01.558375: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "Container dimensions: (25, 4, 4), Container volume: 400, Floor space: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.container_size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.container_size` for environment variables or `env.get_wrapper_attr('container_size')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#use wrapped_env to train a PPO agent\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "#import tensorboard for logging\n",
    "\n",
    "# base_env = gym.make('BinPack3D-v1',\n",
    "#                 container_size = (25, 4, 4), #(9, 11, 13),\n",
    "#                     boxSeqGenerator='CUT-2', \n",
    "#                     enabled_rotations = [Rotate.NOOP],\n",
    "#                     n_foreseeable_box = 3,\n",
    "#                     minSideLen = 1, # 2\n",
    "#                     maxSideLen = 2, # 5\n",
    "#                 )\n",
    "\n",
    "base_env = gym.make('BinPack3D-v1', \n",
    "                container_size = (10, 5, 5),\n",
    "                boxSeqGenerator='random', \n",
    "                box_set = [Box(2,1,1), Box(1,1,1)],\n",
    "                # boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP],\n",
    "                n_foreseeable_box = 5,\n",
    "                # minSideLen = 2,\n",
    "                # maxSideLen = 5,\n",
    "            )                \n",
    "wrapped_env = RewardWrapper(base_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /home/btg/Documents/GitHub-khlee/CS5446-Project/Documents/GitHub/CS5446_AI_planning/CS5446-Project/tensorboard/ppo_binpack3d_tensorboard/PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.container to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.container` for environment variables or `env.get_wrapper_attr('container')` that will search the reminding wrappers.\u001b[0m\n",
      "  env_spec.additional_wrappers += (wrapper_spec,)\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.container_size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.container_size` for environment variables or `env.get_wrapper_attr('container_size')` that will search the reminding wrappers.\u001b[0m\n",
      "  env_spec.additional_wrappers += (wrapper_spec,)\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.actionIdx_to_position to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.actionIdx_to_position` for environment variables or `env.get_wrapper_attr('actionIdx_to_position')` that will search the reminding wrappers.\u001b[0m\n",
      "  env_spec.additional_wrappers += (wrapper_spec,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5.23     |\n",
      "|    ep_rew_mean     | 79.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 443      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.16        |\n",
      "|    ep_rew_mean          | 117         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012782655 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | -0.000127   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.86e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0364     |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.18        |\n",
      "|    ep_rew_mean          | 78.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012623473 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.0252      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.03e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0342     |\n",
      "|    value_loss           | 1.81e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.12       |\n",
      "|    ep_rew_mean          | 122        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 417        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01236206 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.55      |\n",
      "|    explained_variance   | 0.0429     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.24e+03   |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0342    |\n",
      "|    value_loss           | 1.82e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.19        |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011802794 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.96e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 1.56e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.72        |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 425         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009592233 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.0843      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 2.48e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.64        |\n",
      "|    ep_rew_mean          | 188         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011259474 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.45       |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.82e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 1.86e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.25        |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 433         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009936566 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 1.86e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.43         |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 436          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105636045 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.0959       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.49e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0219      |\n",
      "|    value_loss           | 1.97e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.46        |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011381604 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.35       |\n",
      "|    explained_variance   | 0.0852      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+04    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.86        |\n",
      "|    ep_rew_mean          | 194         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 442         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012180505 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.0942      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+04    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 2.31e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.17         |\n",
      "|    ep_rew_mean          | 209          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 444          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109365545 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.29        |\n",
      "|    explained_variance   | 0.0987       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    value_loss           | 2.07e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.46        |\n",
      "|    ep_rew_mean          | 224         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010817882 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+04    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 1.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.9         |\n",
      "|    ep_rew_mean          | 204         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 447         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010088589 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21e+04    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 1.98e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.88        |\n",
      "|    ep_rew_mean          | 202         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 448         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958246 |\n",
      "|    clip_fraction        | 0.0417      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.87        |\n",
      "|    ep_rew_mean          | 201         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 450         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007680501 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.87e+03    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.94        |\n",
      "|    ep_rew_mean          | 249         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 452         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009735766 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.47        |\n",
      "|    ep_rew_mean          | 268         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 454         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010143215 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+04    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.11        |\n",
      "|    ep_rew_mean          | 213         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 455         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008332372 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.27e+03    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.71e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.53       |\n",
      "|    ep_rew_mean          | 232        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 456        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00826749 |\n",
      "|    clip_fraction        | 0.0332     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.1       |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.23e+04   |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    value_loss           | 1.83e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.66       |\n",
      "|    ep_rew_mean          | 236        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 458        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01028172 |\n",
      "|    clip_fraction        | 0.035      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 0.146      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.71e+03   |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 2e+04      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.4         |\n",
      "|    ep_rew_mean          | 225         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009369649 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.63e+03    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.39       |\n",
      "|    ep_rew_mean          | 223        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 460        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00977288 |\n",
      "|    clip_fraction        | 0.0466     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.05      |\n",
      "|    explained_variance   | 0.159      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.5e+03    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 1.84e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.36        |\n",
      "|    ep_rew_mean          | 271         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005335425 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.74e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.88        |\n",
      "|    ep_rew_mean          | 204         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008379489 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.75e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.96        |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 462         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009337299 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.36e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.82        |\n",
      "|    ep_rew_mean          | 243         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986669 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.74e+03    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.48        |\n",
      "|    ep_rew_mean          | 228         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008678054 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.14        |\n",
      "|    ep_rew_mean          | 215         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008899901 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.66e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.56e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.57         |\n",
      "|    ep_rew_mean          | 234          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049743364 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.73e+03     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 1.7e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.46         |\n",
      "|    ep_rew_mean          | 275          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060861725 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.88        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7e+03        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    value_loss           | 1.58e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.91        |\n",
      "|    ep_rew_mean          | 205         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006893686 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.27e+03    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.84         |\n",
      "|    ep_rew_mean          | 250          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047145486 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.158        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.06e+03     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 1.81e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.32        |\n",
      "|    ep_rew_mean          | 226         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005685446 |\n",
      "|    clip_fraction        | 0.00718     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.84       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.24e+03    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    value_loss           | 1.62e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.07      |\n",
      "|    ep_rew_mean          | 254       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 468       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 153       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0058464 |\n",
      "|    clip_fraction        | 0.0111    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.84     |\n",
      "|    explained_variance   | 0.176     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.96e+03  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.00802  |\n",
      "|    value_loss           | 1.61e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.57        |\n",
      "|    ep_rew_mean          | 235         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005071478 |\n",
      "|    clip_fraction        | 0.00356     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 1.62e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.42         |\n",
      "|    ep_rew_mean          | 229          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053898385 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.83        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.93e+03     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00783     |\n",
      "|    value_loss           | 1.66e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.75         |\n",
      "|    ep_rew_mean          | 241          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074564544 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.84        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.35e+03     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    value_loss           | 1.64e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.43         |\n",
      "|    ep_rew_mean          | 226          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059373435 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.85        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.46e+03     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    value_loss           | 1.46e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.65         |\n",
      "|    ep_rew_mean          | 234          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045844438 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.85        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.14e+03     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 1.63e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.61        |\n",
      "|    ep_rew_mean          | 233         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005199507 |\n",
      "|    clip_fraction        | 0.0103      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.9e+03     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 1.52e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 7.78         |\n",
      "|    ep_rew_mean          | 197          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 470          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051576192 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.86        |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.78e+03     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    value_loss           | 1.69e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.58        |\n",
      "|    ep_rew_mean          | 231         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200416 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.83e+03    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 1.55e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.58        |\n",
      "|    ep_rew_mean          | 230         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004292722 |\n",
      "|    clip_fraction        | 0.00244     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.84e+03    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.46       |\n",
      "|    ep_rew_mean          | 268        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 471        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 195        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00306526 |\n",
      "|    clip_fraction        | 0.00356    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.85      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.88e+03   |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    value_loss           | 1.59e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.25        |\n",
      "|    ep_rew_mean          | 216         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 472         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004255155 |\n",
      "|    clip_fraction        | 0.00532     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.42e+03    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 1.65e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.43         |\n",
      "|    ep_rew_mean          | 225          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061299447 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.83        |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.05e+03     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00939     |\n",
      "|    value_loss           | 1.59e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.79        |\n",
      "|    ep_rew_mean          | 242         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004434819 |\n",
      "|    clip_fraction        | 0.00171     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.41e+03    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 1.64e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.43       |\n",
      "|    ep_rew_mean          | 271        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00576253 |\n",
      "|    clip_fraction        | 0.00771    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.81      |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.47e+03   |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00746   |\n",
      "|    value_loss           | 1.49e+04   |\n",
      "----------------------------------------\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /home/btg/Documents/GitHub-khlee/CS5446-Project/Documents/GitHub/CS5446_AI_planning/CS5446-Project/tensorboard/a2c_binpack3d_tensorboard/A2C_1\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 6.82      |\n",
      "|    ep_rew_mean        | 148       |\n",
      "| time/                 |           |\n",
      "|    fps                | 340       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.14     |\n",
      "|    explained_variance | -0.000669 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 479       |\n",
      "|    value_loss         | 1.77e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.52     |\n",
      "|    ep_rew_mean        | 137      |\n",
      "| time/                 |          |\n",
      "|    fps                | 347      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.01    |\n",
      "|    explained_variance | 0.0039   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 417      |\n",
      "|    value_loss         | 1.93e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.77     |\n",
      "|    ep_rew_mean        | 148      |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.01    |\n",
      "|    explained_variance | 0.00279  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 426      |\n",
      "|    value_loss         | 1.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.2      |\n",
      "|    ep_rew_mean        | 170      |\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.96    |\n",
      "|    explained_variance | 0.00182  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 482      |\n",
      "|    value_loss         | 1.82e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.06     |\n",
      "|    ep_rew_mean        | 164      |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.77    |\n",
      "|    explained_variance | 0.214    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 445      |\n",
      "|    value_loss         | 1.82e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.39     |\n",
      "|    ep_rew_mean        | 176      |\n",
      "| time/                 |          |\n",
      "|    fps                | 349      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.61    |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 46.5     |\n",
      "|    value_loss         | 7.48e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.35     |\n",
      "|    ep_rew_mean        | 176      |\n",
      "| time/                 |          |\n",
      "|    fps                | 349      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.62    |\n",
      "|    explained_variance | 0.004    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 202      |\n",
      "|    value_loss         | 1.35e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.31     |\n",
      "|    ep_rew_mean        | 175      |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.6     |\n",
      "|    explained_variance | 0.107    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 24       |\n",
      "|    value_loss         | 3.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.07     |\n",
      "|    ep_rew_mean        | 207      |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.73    |\n",
      "|    explained_variance | 0.0902   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 148      |\n",
      "|    value_loss         | 1.15e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.07     |\n",
      "|    ep_rew_mean        | 207      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.63    |\n",
      "|    explained_variance | 0.00805  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 141      |\n",
      "|    value_loss         | 1.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.95     |\n",
      "|    ep_rew_mean        | 205      |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.43    |\n",
      "|    explained_variance | 0.466    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 285      |\n",
      "|    value_loss         | 9.64e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.85     |\n",
      "|    ep_rew_mean        | 201      |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.7     |\n",
      "|    explained_variance | 0.0271   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 354      |\n",
      "|    value_loss         | 1.76e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.64     |\n",
      "|    ep_rew_mean        | 192      |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.94    |\n",
      "|    explained_variance | -0.461   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 464      |\n",
      "|    value_loss         | 2.58e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.56     |\n",
      "|    ep_rew_mean        | 190      |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.37    |\n",
      "|    explained_variance | 0.174    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 186      |\n",
      "|    value_loss         | 9.05e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.72     |\n",
      "|    ep_rew_mean        | 198      |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.38    |\n",
      "|    explained_variance | 0.413    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 279      |\n",
      "|    value_loss         | 6.93e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.73     |\n",
      "|    ep_rew_mean        | 201      |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.35    |\n",
      "|    explained_variance | 0.362    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 249      |\n",
      "|    value_loss         | 1.17e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.37     |\n",
      "|    ep_rew_mean        | 187      |\n",
      "| time/                 |          |\n",
      "|    fps                | 353      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.00125  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -195     |\n",
      "|    value_loss         | 7.41e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.75     |\n",
      "|    ep_rew_mean        | 203      |\n",
      "| time/                 |          |\n",
      "|    fps                | 354      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.679    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -88.8    |\n",
      "|    value_loss         | 1.62e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.17     |\n",
      "|    ep_rew_mean        | 220      |\n",
      "| time/                 |          |\n",
      "|    fps                | 355      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.35    |\n",
      "|    explained_variance | 0.361    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -99.3    |\n",
      "|    value_loss         | 4.78e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.75     |\n",
      "|    ep_rew_mean        | 204      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 319      |\n",
      "|    value_loss         | 1.34e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8        |\n",
      "|    ep_rew_mean        | 213      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.36    |\n",
      "|    explained_variance | 0.156    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -105     |\n",
      "|    value_loss         | 6.09e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.23     |\n",
      "|    ep_rew_mean        | 225      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.62    |\n",
      "|    explained_variance | 0.535    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 336      |\n",
      "|    value_loss         | 1.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.85     |\n",
      "|    ep_rew_mean        | 205      |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.5     |\n",
      "|    explained_variance | 0.6      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -113     |\n",
      "|    value_loss         | 2.71e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.64     |\n",
      "|    ep_rew_mean        | 238      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.37    |\n",
      "|    explained_variance | 0.0323   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 349      |\n",
      "|    value_loss         | 1.05e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.78     |\n",
      "|    ep_rew_mean        | 241      |\n",
      "| time/                 |          |\n",
      "|    fps                | 358      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.98    |\n",
      "|    explained_variance | 0.609    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 224      |\n",
      "|    value_loss         | 7.1e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.85     |\n",
      "|    ep_rew_mean        | 243      |\n",
      "| time/                 |          |\n",
      "|    fps                | 359      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.94    |\n",
      "|    explained_variance | 0.0965   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 45.6     |\n",
      "|    value_loss         | 1.15e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.92     |\n",
      "|    ep_rew_mean        | 249      |\n",
      "| time/                 |          |\n",
      "|    fps                | 357      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0.12     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 247      |\n",
      "|    value_loss         | 1.27e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.68     |\n",
      "|    ep_rew_mean        | 243      |\n",
      "| time/                 |          |\n",
      "|    fps                | 358      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0.0725   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -59      |\n",
      "|    value_loss         | 1.03e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.35     |\n",
      "|    ep_rew_mean        | 228      |\n",
      "| time/                 |          |\n",
      "|    fps                | 359      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.27    |\n",
      "|    explained_variance | 0.104    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -206     |\n",
      "|    value_loss         | 9.86e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.78     |\n",
      "|    ep_rew_mean        | 247      |\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0.126    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 476      |\n",
      "|    value_loss         | 1.92e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.16     |\n",
      "|    ep_rew_mean        | 262      |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.4     |\n",
      "|    explained_variance | 0.413    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -31      |\n",
      "|    value_loss         | 6.12e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.08     |\n",
      "|    ep_rew_mean        | 259      |\n",
      "| time/                 |          |\n",
      "|    fps                | 360      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0.000446 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -333     |\n",
      "|    value_loss         | 1.91e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.75     |\n",
      "|    ep_rew_mean        | 245      |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0.0342   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 242      |\n",
      "|    value_loss         | 2.39e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.56     |\n",
      "|    ep_rew_mean        | 233      |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0.521    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 131      |\n",
      "|    value_loss         | 3.64e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.54     |\n",
      "|    ep_rew_mean        | 231      |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | 0.0181   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 336      |\n",
      "|    value_loss         | 1.74e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.55     |\n",
      "|    ep_rew_mean        | 234      |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.33    |\n",
      "|    explained_variance | 0.421    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 436      |\n",
      "|    value_loss         | 1.99e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.16     |\n",
      "|    ep_rew_mean        | 263      |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.19    |\n",
      "|    explained_variance | 0.000322 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 362      |\n",
      "|    value_loss         | 1.76e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.49     |\n",
      "|    ep_rew_mean        | 278      |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0.105    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 306      |\n",
      "|    value_loss         | 1.02e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.08     |\n",
      "|    ep_rew_mean        | 220      |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0.508    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 199      |\n",
      "|    value_loss         | 9.63e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.57     |\n",
      "|    ep_rew_mean        | 244      |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.35    |\n",
      "|    explained_variance | 0.0236   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 210      |\n",
      "|    value_loss         | 7.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.86     |\n",
      "|    ep_rew_mean        | 255      |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.23    |\n",
      "|    explained_variance | 0.77     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 45.6     |\n",
      "|    value_loss         | 1.58e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.97     |\n",
      "|    ep_rew_mean        | 258      |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.77    |\n",
      "|    explained_variance | 0.629    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 282      |\n",
      "|    value_loss         | 1.09e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.74     |\n",
      "|    ep_rew_mean        | 248      |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 0.446    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 45.9     |\n",
      "|    value_loss         | 9.56e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.61     |\n",
      "|    ep_rew_mean        | 290      |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.64    |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -64.8    |\n",
      "|    value_loss         | 2.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.31     |\n",
      "|    ep_rew_mean        | 278      |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.716    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 87.5     |\n",
      "|    value_loss         | 5.3e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 9.1       |\n",
      "|    ep_rew_mean        | 271       |\n",
      "| time/                 |           |\n",
      "|    fps                | 364       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.57     |\n",
      "|    explained_variance | -4.29e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -42.1     |\n",
      "|    value_loss         | 1.68e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.83     |\n",
      "|    ep_rew_mean        | 256      |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.58    |\n",
      "|    explained_variance | 0.787    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 113      |\n",
      "|    value_loss         | 1.83e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.88     |\n",
      "|    ep_rew_mean        | 257      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | 0.45     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 174      |\n",
      "|    value_loss         | 6.43e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.53     |\n",
      "|    ep_rew_mean        | 240      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | -0.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -160     |\n",
      "|    value_loss         | 1.36e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.35     |\n",
      "|    ep_rew_mean        | 235      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.38    |\n",
      "|    explained_variance | 0.403    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -47.2    |\n",
      "|    value_loss         | 9.07e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.23     |\n",
      "|    ep_rew_mean        | 282      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.84    |\n",
      "|    explained_variance | 0.621    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -12.9    |\n",
      "|    value_loss         | 1.83e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.39     |\n",
      "|    ep_rew_mean        | 286      |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0.000366 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 4.02     |\n",
      "|    value_loss         | 1.61e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.41     |\n",
      "|    ep_rew_mean        | 282      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9     |\n",
      "|    explained_variance | 0.653    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 418      |\n",
      "|    value_loss         | 1.26e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 312      |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.3     |\n",
      "|    explained_variance | 0.674    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 23.5     |\n",
      "|    value_loss         | 7.91e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.57     |\n",
      "|    ep_rew_mean        | 294      |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.66    |\n",
      "|    explained_variance | 0.0242   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 539      |\n",
      "|    value_loss         | 2.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.62     |\n",
      "|    ep_rew_mean        | 297      |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.43    |\n",
      "|    explained_variance | 0.735    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -138     |\n",
      "|    value_loss         | 4.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.97     |\n",
      "|    ep_rew_mean        | 313      |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 0.507    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 110      |\n",
      "|    value_loss         | 5.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.75     |\n",
      "|    ep_rew_mean        | 300      |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.04    |\n",
      "|    explained_variance | 0.194    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 65.8     |\n",
      "|    value_loss         | 3.33e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.89     |\n",
      "|    ep_rew_mean        | 305      |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.8     |\n",
      "|    explained_variance | 0.113    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -284     |\n",
      "|    value_loss         | 1.88e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.83     |\n",
      "|    ep_rew_mean        | 301      |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.64    |\n",
      "|    explained_variance | 0.00676  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 358      |\n",
      "|    value_loss         | 2.39e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.73     |\n",
      "|    ep_rew_mean        | 296      |\n",
      "| time/                 |          |\n",
      "|    fps                | 368      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | 0.0108   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -254     |\n",
      "|    value_loss         | 2.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 311      |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.54    |\n",
      "|    explained_variance | 0.696    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 107      |\n",
      "|    value_loss         | 1.63e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.3     |\n",
      "|    ep_rew_mean        | 314      |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | -0.00535 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -420     |\n",
      "|    value_loss         | 2.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.18     |\n",
      "|    ep_rew_mean        | 269      |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.44    |\n",
      "|    explained_variance | 0.496    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 256      |\n",
      "|    value_loss         | 1.2e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.66     |\n",
      "|    ep_rew_mean        | 244      |\n",
      "| time/                 |          |\n",
      "|    fps                | 369      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0.674    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 215      |\n",
      "|    value_loss         | 7.31e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.15     |\n",
      "|    ep_rew_mean        | 262      |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.441    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 239      |\n",
      "|    value_loss         | 5.92e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.67     |\n",
      "|    ep_rew_mean        | 290      |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.26    |\n",
      "|    explained_variance | 0.504    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 28.6     |\n",
      "|    value_loss         | 1.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.96     |\n",
      "|    ep_rew_mean        | 306      |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.23    |\n",
      "|    explained_variance | -0.2     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -429     |\n",
      "|    value_loss         | 3e+04    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.87     |\n",
      "|    ep_rew_mean        | 296      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.59    |\n",
      "|    explained_variance | 0.000257 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 63.3     |\n",
      "|    value_loss         | 2.35e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.14     |\n",
      "|    ep_rew_mean        | 257      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 2.5      |\n",
      "|    value_loss         | 7.15e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.65     |\n",
      "|    ep_rew_mean        | 288      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.07    |\n",
      "|    explained_variance | 0.0541   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -158     |\n",
      "|    value_loss         | 2.15e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.59     |\n",
      "|    ep_rew_mean        | 293      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | -0.389   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 164      |\n",
      "|    value_loss         | 1.21e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.78     |\n",
      "|    ep_rew_mean        | 300      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 0.816    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -320     |\n",
      "|    value_loss         | 1.35e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 346      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.62    |\n",
      "|    explained_variance | 0.423    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 136      |\n",
      "|    value_loss         | 6.52e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 357      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 0.0196   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -300     |\n",
      "|    value_loss         | 2.82e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.96     |\n",
      "|    ep_rew_mean        | 310      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 173      |\n",
      "|    value_loss         | 6.23e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.4      |\n",
      "|    ep_rew_mean        | 286      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0.837    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 70.1     |\n",
      "|    value_loss         | 3.08e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.31     |\n",
      "|    ep_rew_mean        | 277      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.78    |\n",
      "|    explained_variance | 0.292    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 146      |\n",
      "|    value_loss         | 4.55e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.31     |\n",
      "|    ep_rew_mean        | 278      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0.805    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 41.8     |\n",
      "|    value_loss         | 846      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.78     |\n",
      "|    ep_rew_mean        | 300      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.24    |\n",
      "|    explained_variance | 0.777    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 178      |\n",
      "|    value_loss         | 6.06e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.81     |\n",
      "|    ep_rew_mean        | 300      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 0.433    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 198      |\n",
      "|    value_loss         | 1.4e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.19     |\n",
      "|    ep_rew_mean        | 275      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | 0.354    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -294     |\n",
      "|    value_loss         | 1.8e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.09     |\n",
      "|    ep_rew_mean        | 268      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | 0.759    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -312     |\n",
      "|    value_loss         | 1.86e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.02     |\n",
      "|    ep_rew_mean        | 261      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.54    |\n",
      "|    explained_variance | 0.347    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 84.2     |\n",
      "|    value_loss         | 4.03e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.31     |\n",
      "|    ep_rew_mean        | 271      |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.2     |\n",
      "|    explained_variance | 0.0261   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -159     |\n",
      "|    value_loss         | 3e+04    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 305      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.74    |\n",
      "|    explained_variance | 0.943    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | 151      |\n",
      "|    value_loss         | 3.9e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 331      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.36    |\n",
      "|    explained_variance | 8.39e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 434      |\n",
      "|    value_loss         | 2.11e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 334      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0.438    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.282   |\n",
      "|    value_loss         | 4.4e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 335      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0.00032  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 214      |\n",
      "|    value_loss         | 1.85e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.4     |\n",
      "|    ep_rew_mean        | 328      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.89    |\n",
      "|    explained_variance | 0.769    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 335      |\n",
      "|    value_loss         | 1.17e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.88     |\n",
      "|    ep_rew_mean        | 306      |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.88    |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | -235     |\n",
      "|    value_loss         | 1.45e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 318      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | 0.953    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 220      |\n",
      "|    value_loss         | 6.42e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 357      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.48    |\n",
      "|    explained_variance | 0.791    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -23      |\n",
      "|    value_loss         | 4.71e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 313      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | 0.967    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -11      |\n",
      "|    value_loss         | 201      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.96     |\n",
      "|    ep_rew_mean        | 258      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.82    |\n",
      "|    explained_variance | 0.942    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 89.4     |\n",
      "|    value_loss         | 2.86e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10       |\n",
      "|    ep_rew_mean        | 305      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | 0.154    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 171      |\n",
      "|    value_loss         | 2.2e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.3     |\n",
      "|    ep_rew_mean        | 318      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | 0.388    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -328     |\n",
      "|    value_loss         | 2.56e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.6      |\n",
      "|    ep_rew_mean        | 286      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0.00064  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -227     |\n",
      "|    value_loss         | 4e+04    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 310      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | 0.55     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -161     |\n",
      "|    value_loss         | 1.77e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.5     |\n",
      "|    ep_rew_mean        | 333      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0.0798   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 202      |\n",
      "|    value_loss         | 1.19e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 347      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | -36.6    |\n",
      "|    value_loss         | 2.43e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.3     |\n",
      "|    ep_rew_mean        | 322      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 136      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.985   |\n",
      "|    explained_variance | 0.00941  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | 63.8     |\n",
      "|    value_loss         | 8.91e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 314      |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.57    |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 144      |\n",
      "|    value_loss         | 2.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.7     |\n",
      "|    ep_rew_mean        | 337      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.59    |\n",
      "|    explained_variance | 0.333    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -389     |\n",
      "|    value_loss         | 3.06e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 353      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.16    |\n",
      "|    explained_variance | 0.825    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | 136      |\n",
      "|    value_loss         | 1.15e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 341      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 0.764    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | 62.2     |\n",
      "|    value_loss         | 1.14e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.3     |\n",
      "|    ep_rew_mean        | 372      |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0.747    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | 28.4     |\n",
      "|    value_loss         | 2.94e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.2     |\n",
      "|    ep_rew_mean        | 372      |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | 0.623    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 62.8     |\n",
      "|    value_loss         | 4.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 381      |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.0286   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 76.8     |\n",
      "|    value_loss         | 9.75e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 370      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 146      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.62    |\n",
      "|    explained_variance | 0.519    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 318      |\n",
      "|    value_loss         | 1.93e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.2     |\n",
      "|    ep_rew_mean        | 363      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 147      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.83    |\n",
      "|    explained_variance | 0.143    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | 42.3     |\n",
      "|    value_loss         | 6.8e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 381      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.51    |\n",
      "|    explained_variance | 0.679    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 28.5     |\n",
      "|    value_loss         | 1.42e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.2     |\n",
      "|    ep_rew_mean        | 362      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0.914    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -401     |\n",
      "|    value_loss         | 1.84e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.4     |\n",
      "|    ep_rew_mean        | 321      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0.729    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -13.4    |\n",
      "|    value_loss         | 5.37e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 311      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.71    |\n",
      "|    explained_variance | 0.813    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 144      |\n",
      "|    value_loss         | 3.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 336      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 153      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | 196      |\n",
      "|    value_loss         | 5.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 339      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 155      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.7     |\n",
      "|    explained_variance | 0.65     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 424      |\n",
      "|    value_loss         | 1.49e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 336      |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.59    |\n",
      "|    explained_variance | 0.853    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -73.7    |\n",
      "|    value_loss         | 4.48e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 359      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 157      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.3     |\n",
      "|    explained_variance | 0.827    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 109      |\n",
      "|    value_loss         | 1.36e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 374      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0.761    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -429     |\n",
      "|    value_loss         | 3.92e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 354      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.51    |\n",
      "|    explained_variance | 0.901    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -11.1    |\n",
      "|    value_loss         | 1.89e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 341      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 161      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0.436    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 130      |\n",
      "|    value_loss         | 6.13e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 343      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.257    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 186      |\n",
      "|    value_loss         | 7.87e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 328      |\n",
      "| time/                 |          |\n",
      "|    fps                | 377      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.29    |\n",
      "|    explained_variance | 0.968    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | 59.5     |\n",
      "|    value_loss         | 406      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.4     |\n",
      "|    ep_rew_mean        | 337      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | 0.925    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    value_loss         | 3.04e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 370      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0.833    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | 0.0343   |\n",
      "|    value_loss         | 1.32e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.3     |\n",
      "|    ep_rew_mean        | 377      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 3.09e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 107      |\n",
      "|    value_loss         | 1.32e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.1     |\n",
      "|    ep_rew_mean        | 309      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.59    |\n",
      "|    explained_variance | 0.473    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 263      |\n",
      "|    value_loss         | 1.4e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.8      |\n",
      "|    ep_rew_mean        | 290      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0.948    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -33.3    |\n",
      "|    value_loss         | 1.03e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 306      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0.928    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 85.7     |\n",
      "|    value_loss         | 1.03e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11       |\n",
      "|    ep_rew_mean        | 342      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.06    |\n",
      "|    explained_variance | -13.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -317     |\n",
      "|    value_loss         | 5.26e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12       |\n",
      "|    ep_rew_mean        | 393      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -63      |\n",
      "|    value_loss         | 789      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.8     |\n",
      "|    ep_rew_mean        | 387      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0.442    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -264     |\n",
      "|    value_loss         | 1.57e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 357      |\n",
      "| time/                 |          |\n",
      "|    fps                | 378      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0.965    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 22.7     |\n",
      "|    value_loss         | 1.18e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 347      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | 0.914    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 5.91     |\n",
      "|    value_loss         | 1.92e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 353      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.42    |\n",
      "|    explained_variance | 0.71     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 15.3     |\n",
      "|    value_loss         | 2.03e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.7     |\n",
      "|    ep_rew_mean        | 382      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.08    |\n",
      "|    explained_variance | 0.823    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 140      |\n",
      "|    value_loss         | 1.25e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 381      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.27    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -161     |\n",
      "|    value_loss         | 7.55e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.6     |\n",
      "|    ep_rew_mean        | 341      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.49    |\n",
      "|    explained_variance | 0.839    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -24.2    |\n",
      "|    value_loss         | 672      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10       |\n",
      "|    ep_rew_mean        | 312      |\n",
      "| time/                 |          |\n",
      "|    fps                | 379      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 184      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0.06     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | 20.8     |\n",
      "|    value_loss         | 4.51e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.5     |\n",
      "|    ep_rew_mean        | 334      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 185      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 0.699    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -65.3    |\n",
      "|    value_loss         | 2.46e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 380      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.72    |\n",
      "|    explained_variance | 0.543    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    value_loss         | 1.82e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.3     |\n",
      "|    ep_rew_mean        | 369      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 187      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.26    |\n",
      "|    explained_variance | 0.994    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 46.5     |\n",
      "|    value_loss         | 399      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.3     |\n",
      "|    ep_rew_mean        | 325      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -297     |\n",
      "|    value_loss         | 2.84e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.42     |\n",
      "|    ep_rew_mean        | 236      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 190      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.27    |\n",
      "|    explained_variance | 0.663    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | -16.5    |\n",
      "|    value_loss         | 1.38e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.38     |\n",
      "|    ep_rew_mean        | 281      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 192      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0.881    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -22      |\n",
      "|    value_loss         | 6.75e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 346      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.08    |\n",
      "|    explained_variance | 0.0802   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 168      |\n",
      "|    value_loss         | 9.87e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.7     |\n",
      "|    ep_rew_mean        | 335      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 194      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 2.2      |\n",
      "|    value_loss         | 7.95e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 337      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.665    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 210      |\n",
      "|    value_loss         | 1.23e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.8     |\n",
      "|    ep_rew_mean        | 336      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | 0.735    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | 95.2     |\n",
      "|    value_loss         | 4.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 351      |\n",
      "| time/                 |          |\n",
      "|    fps                | 380      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 198      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | 0.348    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 67.2     |\n",
      "|    value_loss         | 2.03e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 368      |\n",
      "| time/                 |          |\n",
      "|    fps                | 381      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.5     |\n",
      "|    explained_variance | 0.728    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -330     |\n",
      "|    value_loss         | 1.63e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.3     |\n",
      "|    ep_rew_mean        | 362      |\n",
      "| time/                 |          |\n",
      "|    fps                | 381      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 200      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 0.129    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 92.8     |\n",
      "|    value_loss         | 4.78e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 346      |\n",
      "| time/                 |          |\n",
      "|    fps                | 381      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0.784    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -72.5    |\n",
      "|    value_loss         | 9.75e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 353      |\n",
      "| time/                 |          |\n",
      "|    fps                | 381      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.0462   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 21.2     |\n",
      "|    value_loss         | 1.47e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 368      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 204      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.613    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -80.4    |\n",
      "|    value_loss         | 2.17e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.2     |\n",
      "|    ep_rew_mean        | 359      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.74    |\n",
      "|    explained_variance | 0.952    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 77.1     |\n",
      "|    value_loss         | 1.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.2     |\n",
      "|    ep_rew_mean        | 365      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0.444    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 27.6     |\n",
      "|    value_loss         | 2.61e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.8     |\n",
      "|    ep_rew_mean        | 394      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 208      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | 0.868    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 295      |\n",
      "|    value_loss         | 1.39e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.8     |\n",
      "|    ep_rew_mean        | 393      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | 0.767    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | 261      |\n",
      "|    value_loss         | 6.82e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.4     |\n",
      "|    ep_rew_mean        | 364      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 210      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.66    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 273      |\n",
      "|    value_loss         | 1.43e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.5     |\n",
      "|    ep_rew_mean        | 320      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.52    |\n",
      "|    explained_variance | 0.733    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | 165      |\n",
      "|    value_loss         | 5.46e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.4     |\n",
      "|    ep_rew_mean        | 318      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 38.1     |\n",
      "|    value_loss         | 634      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 372      |\n",
      "| time/                 |          |\n",
      "|    fps                | 382      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 214      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | -131     |\n",
      "|    value_loss         | 9.08e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.3     |\n",
      "|    ep_rew_mean        | 416      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0.285    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | -147     |\n",
      "|    value_loss         | 5.05e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.9     |\n",
      "|    ep_rew_mean        | 404      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 216      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | 0.879    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 39.2     |\n",
      "|    value_loss         | 917      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12       |\n",
      "|    ep_rew_mean        | 407      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | 0.905    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 91.5     |\n",
      "|    value_loss         | 6.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.1     |\n",
      "|    ep_rew_mean        | 406      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.22    |\n",
      "|    explained_variance | 0.79     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | 15.8     |\n",
      "|    value_loss         | 955      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 410      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.69    |\n",
      "|    explained_variance | 0.913    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -123     |\n",
      "|    value_loss         | 3.18e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.9     |\n",
      "|    ep_rew_mean        | 398      |\n",
      "| time/                 |          |\n",
      "|    fps                | 383      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 221      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.66    |\n",
      "|    explained_variance | 0.000203 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | 256      |\n",
      "|    value_loss         | 2.18e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.5     |\n",
      "|    ep_rew_mean        | 424      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.48    |\n",
      "|    explained_variance | 0.411    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 57.8     |\n",
      "|    value_loss         | 3.29e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 411      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 223      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.513    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -288     |\n",
      "|    value_loss         | 4.01e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 13.1     |\n",
      "|    ep_rew_mean        | 453      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 225      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | 0.0654   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 359      |\n",
      "|    value_loss         | 2.7e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.4     |\n",
      "|    ep_rew_mean        | 419      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.82    |\n",
      "|    explained_variance | 0.218    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 63       |\n",
      "|    value_loss         | 6.05e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12       |\n",
      "|    ep_rew_mean        | 403      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    value_loss         | 5.54e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.5     |\n",
      "|    ep_rew_mean        | 426      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.3     |\n",
      "|    explained_variance | 0.732    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | -160     |\n",
      "|    value_loss         | 1.79e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 13       |\n",
      "|    ep_rew_mean        | 452      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.132   |\n",
      "|    explained_variance | 0.00031  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 1.12     |\n",
      "|    value_loss         | 2.18e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 13.2     |\n",
      "|    ep_rew_mean        | 457      |\n",
      "| time/                 |          |\n",
      "|    fps                | 384      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 231      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0.484    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -217     |\n",
      "|    value_loss         | 3.16e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.7     |\n",
      "|    ep_rew_mean        | 394      |\n",
      "| time/                 |          |\n",
      "|    fps                | 385      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.819    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -118     |\n",
      "|    value_loss         | 1.26e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12       |\n",
      "|    ep_rew_mean        | 404      |\n",
      "| time/                 |          |\n",
      "|    fps                | 385      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 233      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 201      |\n",
      "|    value_loss         | 4.47e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 414      |\n",
      "| time/                 |          |\n",
      "|    fps                | 385      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 0.671    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    value_loss         | 2.9e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 411      |\n",
      "| time/                 |          |\n",
      "|    fps                | 385      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 0.606    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | 11.4     |\n",
      "|    value_loss         | 1.8e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.7     |\n",
      "|    ep_rew_mean        | 431      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.55    |\n",
      "|    explained_variance | 0.823    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | 338      |\n",
      "|    value_loss         | 1.2e+04  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.4     |\n",
      "|    ep_rew_mean        | 415      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.72    |\n",
      "|    explained_variance | -0.61    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | 385      |\n",
      "|    value_loss         | 2.69e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.8     |\n",
      "|    ep_rew_mean        | 392      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 239      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0.927    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 177      |\n",
      "|    value_loss         | 3.51e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.9     |\n",
      "|    ep_rew_mean        | 392      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.949   |\n",
      "|    explained_variance | 0.377    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -46.6    |\n",
      "|    value_loss         | 2.89e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.3     |\n",
      "|    ep_rew_mean        | 408      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 241      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.39    |\n",
      "|    explained_variance | 0.943    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 27.7     |\n",
      "|    value_loss         | 695      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.8     |\n",
      "|    ep_rew_mean        | 390      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.71    |\n",
      "|    explained_variance | 0.82     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | 105      |\n",
      "|    value_loss         | 2.89e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 359      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.961   |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    value_loss         | 178      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.5     |\n",
      "|    ep_rew_mean        | 376      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 245      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.86    |\n",
      "|    explained_variance | 0.912    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 107      |\n",
      "|    value_loss         | 4.06e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.6     |\n",
      "|    ep_rew_mean        | 379      |\n",
      "| time/                 |          |\n",
      "|    fps                | 386      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.73    |\n",
      "|    explained_variance | 0.864    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -93.2    |\n",
      "|    value_loss         | 8.93e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.7     |\n",
      "|    ep_rew_mean        | 386      |\n",
      "| time/                 |          |\n",
      "|    fps                | 387      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.99    |\n",
      "|    explained_variance | 0.265    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | -874     |\n",
      "|    value_loss         | 7.94e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.8     |\n",
      "|    ep_rew_mean        | 433      |\n",
      "| time/                 |          |\n",
      "|    fps                | 387      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 249      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 0.619    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 242      |\n",
      "|    value_loss         | 8.99e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.4     |\n",
      "|    ep_rew_mean        | 416      |\n",
      "| time/                 |          |\n",
      "|    fps                | 387      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.18    |\n",
      "|    explained_variance | 0.582    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | -365     |\n",
      "|    value_loss         | 3.36e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12       |\n",
      "|    ep_rew_mean        | 392      |\n",
      "| time/                 |          |\n",
      "|    fps                | 387      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | 0.852    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | 93.7     |\n",
      "|    value_loss         | 2.78e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.3     |\n",
      "|    ep_rew_mean        | 403      |\n",
      "| time/                 |          |\n",
      "|    fps                | 387      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.96    |\n",
      "|    explained_variance | 0.918    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 64       |\n",
      "|    value_loss         | 713      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 400      |\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 253      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.97    |\n",
      "|    explained_variance | 0.602    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | 100      |\n",
      "|    value_loss         | 8.25e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 12.2     |\n",
      "|    ep_rew_mean        | 400      |\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.603   |\n",
      "|    explained_variance | 0.0093   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 43.8     |\n",
      "|    value_loss         | 1.49e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.6     |\n",
      "|    ep_rew_mean        | 379      |\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 54.4     |\n",
      "|    value_loss         | 1.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.3     |\n",
      "|    ep_rew_mean        | 369      |\n",
      "| time/                 |          |\n",
      "|    fps                | 388      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.7     |\n",
      "|    explained_variance | 0.764    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -800     |\n",
      "|    value_loss         | 8.16e+04 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_PPO = PPO(\"MultiInputPolicy\", wrapped_env, verbose=1, tensorboard_log=TENSORBOARD_DIR+\"/ppo_binpack3d_tensorboard/\", device='cuda')\n",
    "model_PPO.learn(total_timesteps=100000)\n",
    "\n",
    "#use wrapped_env to train a A2C agent\n",
    "model_a2c = A2C(\"MultiInputPolicy\", wrapped_env, verbose=1, tensorboard_log=TENSORBOARD_DIR+\"/a2c_binpack3d_tensorboard/\", device='cpu')\n",
    "model_a2c.learn(total_timesteps=100000)\n",
    "\n",
    "#save the model\n",
    "model_PPO.save(DATA_DIR+\"/ppo_reward_wrapper\")\n",
    "model_a2c.save(DATA_DIR+\"/a2c_reward_wrapper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Step: 0, Best frame length: 0\n",
      "info: {'counter': 13, 'ratio': 0.15, 'base_reward': -200, 'max_height': 3.718281828459045, 'floor_space': -3.694842441294721, 'action_x_dist': 4.968102181895745, 'reward_count': 0.999997739675702, 'x_penalty': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/Documents/GitHub-khlee/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/BinPack3DEnv.py:211: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: {'counter': 14, 'ratio': 0.1175, 'base_reward': -200, 'max_height': 3.718281828459045, 'floor_space': -3.9710792630827334, 'action_x_dist': 1.8393972058572117, 'reward_count': 0.9999991684719722, 'x_penalty': 0.0}\n",
      "info: {'counter': 17, 'ratio': 0.18, 'base_reward': -200, 'max_height': 3.718281828459045, 'floor_space': -4.54186587104634, 'action_x_dist': 1.8393972058572117, 'reward_count': 0.9999999586006244, 'x_penalty': 0.0}\n",
      "info: {'counter': 21, 'ratio': 0.1225, 'base_reward': -200, 'max_height': 3.718281828459045, 'floor_space': -3.6540564711000196, 'action_x_dist': 1.8393972058572117, 'reward_count': 0.9999999992417439, 'x_penalty': 0.0}\n",
      "Step: 100, Best frame length: 22\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_166260/3224017745.py\", line 22, in <module>\n",
      "    frame = model_PPO.env.render(mode=\"rgb_array\")\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 103, in render\n",
      "    return super().render(mode=mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\", line 255, in render\n",
      "    images = self.get_images()\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 94, in get_images\n",
      "    return [env.render() for env in self.envs]  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\", line 94, in <listcomp>\n",
      "    return [env.render() for env in self.envs]  # type: ignore[misc]\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py\", line 471, in render\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py\", line 471, in render\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py\", line 70, in render\n",
      "    return self.env.render(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py\", line 67, in render\n",
      "    @property\n",
      "             \n",
      "  File \"/home/btg/Documents/GitHub-khlee/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/BinPack3DEnv.py\", line 222, in render\n",
      "    plot_box(box, ax, color=(0,0.5,1,1))\n",
      "  File \"/home/btg/Documents/GitHub-khlee/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/VisUtil.py\", line 84, in plot_box\n",
      "    plot_parallelepiped(cube_definition, ax, color, showEdges)\n",
      "  File \"/home/btg/Documents/GitHub-khlee/CS5446-Project/gym-BinPack3D/gym_BinPack3D/envs/VisUtil.py\", line 62, in plot_parallelepiped\n",
      "    ax.scatter(points[:,0], points[:,1], points[:,2], s=0)\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/matplotlib/__init__.py\", line 1465, in inner\n",
      "    return func(ax, *map(sanitize_sequence, args), **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/mpl_toolkits/mplot3d/axes3d.py\", line 2384, in scatter\n",
      "    patches = super().scatter(xs, ys, s=s, c=c, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/matplotlib/__init__.py\", line 1465, in inner\n",
      "    return func(ax, *map(sanitize_sequence, args), **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/matplotlib/axes/_axes.py\", line 4680, in scatter\n",
      "    cbook._combine_masks(\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/matplotlib/cbook.py\", line 1078, in _combine_masks\n",
      "    x = safe_masked_invalid(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/matplotlib/cbook.py\", line 740, in safe_masked_invalid\n",
      "    xm = np.ma.masked_where(~(np.isfinite(x)), x, copy=False)\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/numpy/ma/core.py\", line 3081, in __array_wrap__\n",
      "    # args sometimes contains outputs (gh-10459), which we don't want\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/numpy/ma/core.py\", line 3191, in view\n",
      "    else:\n",
      "         \n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/numpy/ma/core.py\", line 2984, in __array_finalize__\n",
      "    # be called in all kinds of places for all kinds of reasons -- could\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/numpy/ma/core.py\", line 2967, in _update_from\n",
      "    _basedict=_optinfo)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "#load the PPO model\n",
    "model_PPO = PPO.load(DATA_DIR+\"/ppo_reward_wrapper\", env=wrapped_env)\n",
    "best_frames = []\n",
    "best_PPO_rewards = []\n",
    "obs = model_PPO.env.reset()\n",
    "frame = model_PPO.env.render(mode=\"rgb_array\")\n",
    "done = False\n",
    "#save the longest sequence of frames for the gif\n",
    "max_framelen = 0\n",
    "for i in range(1000):\n",
    "    #count every 100 steps\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step: {i}, Best frame length: {max_framelen}\")\n",
    "    PPO_rewards = []\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frames.append(frame)\n",
    "        action, _state = model_PPO.predict(obs, deterministic=False)\n",
    "        obs, reward, done,_, info = wrapped_env.step(action.flatten())\n",
    "        # print(obs, reward, done, info)\n",
    "        PPO_rewards.append(reward + PPO_rewards[-1] if len(PPO_rewards) > 0 else reward)\n",
    "        frame = model_PPO.env.render(mode=\"rgb_array\")\n",
    "        if frame is None:\n",
    "            print(\"Frame is None!!\")\n",
    "            break\n",
    "        # VecEnv resets automatically\n",
    "        if done:\n",
    "            obs = model_PPO.env.reset()\n",
    "    #save the longest sequence of frames for the gif\n",
    "    if len(frames) > max_framelen:\n",
    "        max_framelen = len(frames)\n",
    "        best_frames = frames\n",
    "        best_PPO_rewards = PPO_rewards\n",
    "        print(f'info: {info}')\n",
    "    else:\n",
    "        frames = []\n",
    "        done = False\n",
    "\n",
    "print(\"Best ppo len: \", len(best_frames))\n",
    "imageio.mimsave(GIF_DIR+\"/ppo_wrapper\"+\".gif\", best_frames)\n",
    "\n",
    "#load the A2C model\n",
    "model_a2c = A2C.load(DATA_DIR+\"/a2c_reward_wrapper\", env=wrapped_env)\n",
    "best_frames = []\n",
    "best_A2C_rewards = []\n",
    "obs = model_a2c.env.reset()\n",
    "frame = model_a2c.env.render(mode=\"rgb_array\")\n",
    "done = False\n",
    "#save the longest sequence of frames for the gif\n",
    "max_framelen = 0\n",
    "for i in range(1000):\n",
    "    #count every 100 steps\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step: {i}, Best frame length: {max_framelen}\")\n",
    "    A2C_rewards = []\n",
    "    frames = []\n",
    "    while not done:\n",
    "        frames.append(frame)\n",
    "        action, _state = model_a2c.predict(obs, deterministic=False)\n",
    "        obs, reward, done,_, info = wrapped_env.step(action.flatten())\n",
    "        # print(obs, reward, done, info)\n",
    "        A2C_rewards.append(reward + A2C_rewards[-1] if len(A2C_rewards) > 0 else reward)\n",
    "        frame = model_a2c.env.render(mode=\"rgb_array\")\n",
    "        if frame is None:\n",
    "            print(\"Frame is None!!\")\n",
    "            break\n",
    "        # VecEnv resets automatically\n",
    "        if done:\n",
    "            obs = model_a2c.env.reset()\n",
    "    #save the longest sequence of frames for the gif\n",
    "    if len(frames) > max_framelen:\n",
    "        max_framelen = len(frames)\n",
    "        best_frames = frames\n",
    "        best_A2C_rewards = A2C_rewards\n",
    "        print(f'info: {info}')\n",
    "    else:\n",
    "        frames = []\n",
    "        done = False\n",
    "\n",
    "print(\"Best a2c len: \", len(best_frames))\n",
    "imageio.mimsave(GIF_DIR+\"/a2c_wrapper\"+\".gif\", best_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using CUT-2 logic box sequence\n",
      "Container dimensions: (25, 4, 4), Container volume: 400, Floor space: 100\n",
      "{'counter': 1, 'ratio': 0.005, 'base_reward': 45.0, 'max_height': 2.064494458917859, 'floor_space': -3.148851907005015, 'action_x_dist': 2.636462120215243, 'reward_count': 0.7310585786300049, 'x_penalty': 1.0}\n",
      "{'counter': 2, 'ratio': 0.025, 'base_reward': 30.0, 'max_height': 2.2840254166877414, 'floor_space': -3.3620063119850134, 'action_x_dist': 4.803947195761616, 'reward_count': 0.8807970779778823, 'x_penalty': 4.0}\n",
      "{'counter': 3, 'ratio': 0.035, 'base_reward': 44.0, 'max_height': 2.2840254166877414, 'floor_space': -3.446426552733132, 'action_x_dist': 2.8062186822161745, 'reward_count': 0.9525741268224334, 'x_penalty': 1.2}\n",
      "{'counter': 4, 'ratio': 0.055, 'base_reward': 28.0, 'max_height': 2.2840254166877414, 'floor_space': -3.148851907005015, 'action_x_dist': 4.928515920612215, 'reward_count': 0.9820137900379085, 'x_penalty': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.boxSeqGenerator to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.boxSeqGenerator` for environment variables or `env.get_wrapper_attr('boxSeqGenerator')` that will search the reminding wrappers.\u001b[0m\n",
      "  env_spec.additional_wrappers += (wrapper_spec,)\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.position_to_actionIdx to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.position_to_actionIdx` for environment variables or `env.get_wrapper_attr('position_to_actionIdx')` that will search the reminding wrappers.\u001b[0m\n",
      "  env_spec.additional_wrappers += (wrapper_spec,)\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/btg/miniconda3/envs/cs5446_proj/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: int32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'counter': 5, 'ratio': 0.06, 'base_reward': 42.0, 'max_height': 2.2840254166877414, 'floor_space': -3.6540564711000196, 'action_x_dist': 3.1488519070050156, 'reward_count': 0.9933071490757153, 'x_penalty': 1.6}\n",
      "{'counter': 6, 'ratio': 0.08, 'base_reward': 45.0, 'max_height': 2.7550546569602985, 'floor_space': -1.9894096022560235, 'action_x_dist': 2.636462120215243, 'reward_count': 0.9975273768433653, 'x_penalty': 1.0}\n",
      "{'counter': 7, 'ratio': 0.085, 'base_reward': 48.0, 'max_height': 2.7550546569602985, 'floor_space': -3.234382123810649, 'action_x_dist': 2.144781993395365, 'reward_count': 0.9990889488055994, 'x_penalty': 0.4}\n",
      "{'counter': 8, 'ratio': 0.09, 'base_reward': 41.0, 'max_height': 2.7550546569602985, 'floor_space': -3.2770312716342027, 'action_x_dist': 3.3195788166773674, 'reward_count': 0.9996646498695336, 'x_penalty': 1.7999999999999998}\n",
      "{'counter': 9, 'ratio': 0.095, 'base_reward': 39.0, 'max_height': 2.7550546569602985, 'floor_space': -4.008984279834707, 'action_x_dist': 3.6540564711000196, 'reward_count': 0.9998766054240137, 'x_penalty': 2.2}\n",
      "{'counter': 10, 'ratio': 0.115, 'base_reward': 35.0, 'max_height': 2.7550546569602985, 'floor_space': -3.4042951454596238, 'action_x_dist': 4.260718944831057, 'reward_count': 0.9999546021312976, 'x_penalty': 3.0}\n",
      "{'counter': 11, 'ratio': 0.12, 'base_reward': 28.0, 'max_height': 2.7550546569602985, 'floor_space': -3.4042951454596238, 'action_x_dist': 4.928515920612215, 'reward_count': 0.999983298578152, 'x_penalty': 4.4}\n",
      "{'counter': 12, 'ratio': 0.125, 'base_reward': 42.0, 'max_height': 2.7550546569602985, 'floor_space': -4.294511931039239, 'action_x_dist': 3.1488519070050156, 'reward_count': 0.9999938558253978, 'x_penalty': 1.6}\n",
      "{'counter': 13, 'ratio': 0.145, 'base_reward': 32.0, 'max_height': 2.7550546569602985, 'floor_space': -4.32770731110883, 'action_x_dist': 4.622972573801054, 'reward_count': 0.999997739675702, 'x_penalty': 3.5999999999999996}\n",
      "{'counter': 14, 'ratio': 0.155, 'base_reward': 35.0, 'max_height': 2.7550546569602985, 'floor_space': -3.694842441294721, 'action_x_dist': 4.260718944831057, 'reward_count': 0.9999991684719722, 'x_penalty': 3.0}\n",
      "{'counter': 15, 'ratio': 0.165, 'base_reward': 36.0, 'max_height': 2.7550546569602985, 'floor_space': -4.392233696749656, 'action_x_dist': 4.1199371666585165, 'reward_count': 0.999999694097773, 'x_penalty': 2.8000000000000003}\n",
      "{'counter': 16, 'ratio': 0.175, 'base_reward': 39.0, 'max_height': 2.7550546569602985, 'floor_space': -4.454157423171544, 'action_x_dist': 3.6540564711000196, 'reward_count': 0.9999998874648379, 'x_penalty': 2.2}\n",
      "{'counter': 17, 'ratio': 0.185, 'base_reward': 47.0, 'max_height': 2.7550546569602985, 'floor_space': -4.51334206040471, 'action_x_dist': 2.304901431054168, 'reward_count': 0.9999999586006244, 'x_penalty': 0.6}\n",
      "{'counter': 18, 'ratio': 0.195, 'base_reward': 32.0, 'max_height': 2.7550546569602985, 'floor_space': -4.569655926356141, 'action_x_dist': 4.622972573801054, 'reward_count': 0.9999999847700205, 'x_penalty': 3.5999999999999996}\n",
      "{'counter': 19, 'ratio': 0.205, 'base_reward': 34.0, 'max_height': 2.7550546569602985, 'floor_space': -3.6540564711000196, 'action_x_dist': 4.392233696749656, 'reward_count': 0.9999999943972036, 'x_penalty': 3.2}\n",
      "{'counter': 20, 'ratio': 0.21, 'base_reward': 35.0, 'max_height': 2.7550546569602985, 'floor_space': -4.569655926356141, 'action_x_dist': 4.260718944831057, 'reward_count': 0.9999999979388463, 'x_penalty': 3.0}\n",
      "{'counter': 21, 'ratio': 0.22, 'base_reward': 27.0, 'max_height': 2.7550546569602985, 'floor_space': -4.648468973784771, 'action_x_dist': 4.968102181895745, 'reward_count': 0.9999999992417439, 'x_penalty': 4.6000000000000005}\n",
      "{'counter': 22, 'ratio': 0.24, 'base_reward': 32.0, 'max_height': 2.7550546569602985, 'floor_space': -3.694842441294721, 'action_x_dist': 4.622972573801054, 'reward_count': 0.9999999997210531, 'x_penalty': 3.5999999999999996}\n",
      "{'counter': 23, 'ratio': 0.245, 'base_reward': 37.0, 'max_height': 2.7550546569602985, 'floor_space': -3.735336515685978, 'action_x_dist': 3.9710792630827334, 'reward_count': 0.9999999998973812, 'x_penalty': 2.6}\n",
      "{'counter': 24, 'ratio': 0.25, 'base_reward': 27.0, 'max_height': 2.7550546569602985, 'floor_space': -4.569655926356141, 'action_x_dist': 4.968102181895745, 'reward_count': 0.9999999999622486, 'x_penalty': 4.6000000000000005}\n",
      "{'counter': 25, 'ratio': 0.26, 'base_reward': 30.0, 'max_height': 2.7550546569602985, 'floor_space': -3.694842441294721, 'action_x_dist': 4.803947195761616, 'reward_count': 0.999999999986112, 'x_penalty': 4.0}\n",
      "{'counter': 26, 'ratio': 0.265, 'base_reward': 49.0, 'max_height': 2.7550546569602985, 'floor_space': -4.648468973784771, 'action_x_dist': 1.9894096022560235, 'reward_count': 0.999999999994891, 'x_penalty': 0.2}\n",
      "{'counter': 27, 'ratio': 0.275, 'base_reward': 46.0, 'max_height': 2.7550546569602985, 'floor_space': -4.6731712625872435, 'action_x_dist': 2.469060990166731, 'reward_count': 0.9999999999981204, 'x_penalty': 0.8}\n",
      "{'counter': 28, 'ratio': 0.285, 'base_reward': 49.0, 'max_height': 2.7550546569602985, 'floor_space': -4.6731712625872435, 'action_x_dist': 1.9894096022560235, 'reward_count': 0.9999999999993086, 'x_penalty': 0.2}\n",
      "{'counter': 29, 'ratio': 0.295, 'base_reward': 38.0, 'max_height': 2.7550546569602985, 'floor_space': -4.04644174085666, 'action_x_dist': 3.8153710180066804, 'reward_count': 0.9999999999997455, 'x_penalty': 2.4}\n",
      "{'counter': 30, 'ratio': 0.305, 'base_reward': 35.0, 'max_height': 2.7550546569602985, 'floor_space': -3.612998049950968, 'action_x_dist': 4.260718944831057, 'reward_count': 0.9999999999999065, 'x_penalty': 3.0}\n",
      "{'counter': 31, 'ratio': 0.31, 'base_reward': 47.0, 'max_height': 2.7550546569602985, 'floor_space': -4.596696587832591, 'action_x_dist': 2.304901431054168, 'reward_count': 0.9999999999999656, 'x_penalty': 0.6}\n",
      "{'counter': 32, 'ratio': 0.32, 'base_reward': 29.0, 'max_height': 2.7550546569602985, 'floor_space': -4.04644174085666, 'action_x_dist': 4.8736245080089695, 'reward_count': 0.9999999999999873, 'x_penalty': 4.2}\n",
      "{'counter': 33, 'ratio': 0.33, 'base_reward': 26.0, 'max_height': 2.7550546569602985, 'floor_space': -3.571686568679788, 'action_x_dist': 4.992006396588032, 'reward_count': 0.9999999999999953, 'x_penalty': 4.8}\n",
      "{'counter': 34, 'ratio': 0.335, 'base_reward': 36.0, 'max_height': 2.7550546569602985, 'floor_space': -1.8393972058572117, 'action_x_dist': 4.1199371666585165, 'reward_count': 0.9999999999999982, 'x_penalty': 2.8000000000000003}\n",
      "{'counter': 35, 'ratio': 0.3375, 'base_reward': 50.0, 'max_height': 2.7550546569602985, 'floor_space': -4.54186587104634, 'action_x_dist': 1.8393972058572117, 'reward_count': 0.9999999999999993, 'x_penalty': 0.0}\n",
      "{'counter': 36, 'ratio': 0.3475, 'base_reward': 35.0, 'max_height': 3.718281828459045, 'floor_space': -3.735336515685978, 'action_x_dist': 4.260718944831057, 'reward_count': 0.9999999999999998, 'x_penalty': 3.0}\n",
      "{'counter': 37, 'ratio': 0.3525, 'base_reward': 39.0, 'max_height': 3.718281828459045, 'floor_space': -3.7755192104451174, 'action_x_dist': 3.6540564711000196, 'reward_count': 1.0, 'x_penalty': 2.2}\n",
      "{'counter': 38, 'ratio': 0.3575, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.622972573801054, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 39, 'ratio': 0.3675, 'base_reward': 28.0, 'max_height': 3.718281828459045, 'floor_space': -3.8548724225005766, 'action_x_dist': 4.928515920612215, 'reward_count': 1.0, 'x_penalty': 4.4}\n",
      "{'counter': 40, 'ratio': 0.3725, 'base_reward': 30.0, 'max_height': 3.718281828459045, 'floor_space': -4.1199371666585165, 'action_x_dist': 4.803947195761616, 'reward_count': 1.0, 'x_penalty': 4.0}\n",
      "{'counter': 41, 'ratio': 0.3825, 'base_reward': 33.0, 'max_height': 3.718281828459045, 'floor_space': -3.8548724225005766, 'action_x_dist': 4.51334206040471, 'reward_count': 1.0, 'x_penalty': 3.4000000000000004}\n",
      "{'counter': 42, 'ratio': 0.3875, 'base_reward': 40.0, 'max_height': 3.718281828459045, 'floor_space': -3.8940039153570245, 'action_x_dist': 3.488381630355155, 'reward_count': 1.0, 'x_penalty': 2.0}\n",
      "{'counter': 43, 'ratio': 0.3925, 'base_reward': 31.0, 'max_height': 3.718281828459045, 'floor_space': -3.8548724225005766, 'action_x_dist': 4.720137414589178, 'reward_count': 1.0, 'x_penalty': 3.8}\n",
      "{'counter': 44, 'ratio': 0.3975, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.226346517639093, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 45, 'ratio': 0.4075, 'base_reward': 43.0, 'max_height': 3.718281828459045, 'floor_space': -3.8940039153570245, 'action_x_dist': 2.977362711196349, 'reward_count': 1.0, 'x_penalty': 1.4000000000000001}\n",
      "{'counter': 46, 'ratio': 0.4125, 'base_reward': 40.0, 'max_height': 3.718281828459045, 'floor_space': -4.54186587104634, 'action_x_dist': 3.488381630355155, 'reward_count': 1.0, 'x_penalty': 2.0}\n",
      "{'counter': 47, 'ratio': 0.4225, 'base_reward': 42.0, 'max_height': 3.718281828459045, 'floor_space': -4.1199371666585165, 'action_x_dist': 3.1488519070050156, 'reward_count': 1.0, 'x_penalty': 1.6}\n",
      "{'counter': 48, 'ratio': 0.4325, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.155936992180854, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 49, 'ratio': 0.4425, 'base_reward': 37.0, 'max_height': 3.718281828459045, 'floor_space': -4.720137414589178, 'action_x_dist': 3.9710792630827334, 'reward_count': 1.0, 'x_penalty': 2.6}\n",
      "{'counter': 50, 'ratio': 0.4625, 'base_reward': 47.0, 'max_height': 3.718281828459045, 'floor_space': -3.8940039153570245, 'action_x_dist': 2.304901431054168, 'reward_count': 1.0, 'x_penalty': 0.6}\n",
      "{'counter': 51, 'ratio': 0.4675, 'base_reward': 32.0, 'max_height': 3.718281828459045, 'floor_space': -4.622972573801054, 'action_x_dist': 4.622972573801054, 'reward_count': 1.0, 'x_penalty': 3.5999999999999996}\n",
      "{'counter': 52, 'ratio': 0.4775, 'base_reward': 44.0, 'max_height': 3.718281828459045, 'floor_space': -4.763763049016055, 'action_x_dist': 2.8062186822161745, 'reward_count': 1.0, 'x_penalty': 1.2}\n",
      "{'counter': 53, 'ratio': 0.4975, 'base_reward': 28.0, 'max_height': 3.718281828459045, 'floor_space': -3.9327460110672745, 'action_x_dist': 4.928515920612215, 'reward_count': 1.0, 'x_penalty': 4.4}\n",
      "{'counter': 54, 'ratio': 0.5025, 'base_reward': 44.0, 'max_height': 3.718281828459045, 'floor_space': -2.304901431054168, 'action_x_dist': 2.8062186822161745, 'reward_count': 1.0, 'x_penalty': 1.2}\n",
      "{'counter': 55, 'ratio': 0.505, 'base_reward': 48.0, 'max_height': 3.718281828459045, 'floor_space': -3.9710792630827334, 'action_x_dist': 2.144781993395365, 'reward_count': 1.0, 'x_penalty': 0.4}\n",
      "{'counter': 56, 'ratio': 0.51, 'base_reward': 33.0, 'max_height': 3.718281828459045, 'floor_space': -4.454157423171544, 'action_x_dist': 4.51334206040471, 'reward_count': 1.0, 'x_penalty': 3.4000000000000004}\n",
      "{'counter': 57, 'ratio': 0.52, 'base_reward': 30.0, 'max_height': 3.718281828459045, 'floor_space': -4.484100475118934, 'action_x_dist': 4.803947195761616, 'reward_count': 1.0, 'x_penalty': 4.0}\n",
      "{'counter': 58, 'ratio': 0.53, 'base_reward': 34.0, 'max_height': 3.718281828459045, 'floor_space': -3.9327460110672745, 'action_x_dist': 4.392233696749656, 'reward_count': 1.0, 'x_penalty': 3.2}\n",
      "{'counter': 59, 'ratio': 0.535, 'base_reward': 28.0, 'max_height': 3.718281828459045, 'floor_space': -4.51334206040471, 'action_x_dist': 4.928515920612215, 'reward_count': 1.0, 'x_penalty': 4.4}\n",
      "{'counter': 60, 'ratio': 0.545, 'base_reward': 26.0, 'max_height': 3.718281828459045, 'floor_space': -4.8736245080089695, 'action_x_dist': 4.992006396588032, 'reward_count': 1.0, 'x_penalty': 4.8}\n",
      "{'counter': 61, 'ratio': 0.565, 'base_reward': 39.0, 'max_height': 3.718281828459045, 'floor_space': -4.720137414589178, 'action_x_dist': 3.6540564711000196, 'reward_count': 1.0, 'x_penalty': 2.2}\n",
      "{'counter': 62, 'ratio': 0.575, 'base_reward': 47.0, 'max_height': 3.718281828459045, 'floor_space': -4.763763049016055, 'action_x_dist': 2.304901431054168, 'reward_count': 1.0, 'x_penalty': 0.6}\n",
      "{'counter': 63, 'ratio': 0.585, 'base_reward': 46.0, 'max_height': 3.718281828459045, 'floor_space': -4.622972573801054, 'action_x_dist': 2.469060990166731, 'reward_count': 1.0, 'x_penalty': 0.8}\n",
      "{'counter': 64, 'ratio': 0.595, 'base_reward': 42.0, 'max_height': 3.718281828459045, 'floor_space': -4.648468973784771, 'action_x_dist': 3.1488519070050156, 'reward_count': 1.0, 'x_penalty': 1.6}\n",
      "{'counter': 65, 'ratio': 0.605, 'base_reward': 29.0, 'max_height': 3.718281828459045, 'floor_space': -4.008984279834707, 'action_x_dist': 4.8736245080089695, 'reward_count': 1.0, 'x_penalty': 4.2}\n",
      "{'counter': 66, 'ratio': 0.61, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.784291334309549, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 67, 'ratio': 0.62, 'base_reward': 49.0, 'max_height': 3.718281828459045, 'floor_space': -4.083432412990554, 'action_x_dist': 1.9894096022560235, 'reward_count': 1.0, 'x_penalty': 0.2}\n",
      "{'counter': 68, 'ratio': 0.625, 'base_reward': 38.0, 'max_height': 3.718281828459045, 'floor_space': -4.083432412990554, 'action_x_dist': 3.8153710180066804, 'reward_count': 1.0, 'x_penalty': 2.4}\n",
      "{'counter': 69, 'ratio': 0.63, 'base_reward': 45.0, 'max_height': 3.718281828459045, 'floor_space': -4.784291334309549, 'action_x_dist': 2.636462120215243, 'reward_count': 1.0, 'x_penalty': 1.0}\n",
      "{'counter': 70, 'ratio': 0.64, 'base_reward': 49.0, 'max_height': 3.718281828459045, 'floor_space': -2.5524097487114465, 'action_x_dist': 1.9894096022560235, 'reward_count': 1.0, 'x_penalty': 0.2}\n",
      "{'counter': 71, 'ratio': 0.6425, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.763763049016055, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 72, 'ratio': 0.6525, 'base_reward': 41.0, 'max_height': 3.718281828459045, 'floor_space': -4.155936992180854, 'action_x_dist': 3.3195788166773674, 'reward_count': 1.0, 'x_penalty': 1.7999999999999998}\n",
      "{'counter': 73, 'ratio': 0.6575, 'base_reward': 32.0, 'max_height': 3.718281828459045, 'floor_space': -4.763763049016055, 'action_x_dist': 4.622972573801054, 'reward_count': 1.0, 'x_penalty': 3.5999999999999996}\n",
      "{'counter': 74, 'ratio': 0.6675, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.950249168745841, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 75, 'ratio': 0.6875, 'base_reward': 37.0, 'max_height': 3.718281828459045, 'floor_space': -4.840596284582814, 'action_x_dist': 3.9710792630827334, 'reward_count': 1.0, 'x_penalty': 2.6}\n",
      "{'counter': 76, 'ratio': 0.6975, 'base_reward': 41.0, 'max_height': 3.718281828459045, 'floor_space': -4.226346517639093, 'action_x_dist': 3.3195788166773674, 'reward_count': 1.0, 'x_penalty': 1.7999999999999998}\n",
      "{'counter': 77, 'ratio': 0.7025, 'base_reward': 36.0, 'max_height': 3.718281828459045, 'floor_space': -4.975559927079149, 'action_x_dist': 4.1199371666585165, 'reward_count': 1.0, 'x_penalty': 2.8000000000000003}\n",
      "{'counter': 78, 'ratio': 0.7225, 'base_reward': 41.0, 'max_height': 3.718281828459045, 'floor_space': -4.622972573801054, 'action_x_dist': 3.3195788166773674, 'reward_count': 1.0, 'x_penalty': 1.7999999999999998}\n",
      "{'counter': 79, 'ratio': 0.7325, 'base_reward': 35.0, 'max_height': 3.718281828459045, 'floor_space': -4.260718944831057, 'action_x_dist': 4.260718944831057, 'reward_count': 1.0, 'x_penalty': 3.0}\n",
      "{'counter': 80, 'ratio': 0.7375, 'base_reward': 29.0, 'max_height': 3.718281828459045, 'floor_space': -4.720137414589178, 'action_x_dist': 4.8736245080089695, 'reward_count': 1.0, 'x_penalty': 4.2}\n",
      "{'counter': 81, 'ratio': 0.7475, 'base_reward': 30.0, 'max_height': 3.718281828459045, 'floor_space': -4.902954156012142, 'action_x_dist': 4.803947195761616, 'reward_count': 1.0, 'x_penalty': 4.0}\n",
      "{'counter': 82, 'ratio': 0.7575, 'base_reward': 33.0, 'max_height': 3.718281828459045, 'floor_space': -4.392233696749656, 'action_x_dist': 4.51334206040471, 'reward_count': 1.0, 'x_penalty': 3.4000000000000004}\n",
      "{'counter': 83, 'ratio': 0.7625, 'base_reward': 31.0, 'max_height': 3.718281828459045, 'floor_space': -4.454157423171544, 'action_x_dist': 4.720137414589178, 'reward_count': 1.0, 'x_penalty': 3.8}\n",
      "{'counter': 84, 'ratio': 0.7675, 'base_reward': 26.0, 'max_height': 3.718281828459045, 'floor_space': -4.803947195761616, 'action_x_dist': 4.992006396588032, 'reward_count': 1.0, 'x_penalty': 4.8}\n",
      "{'counter': 85, 'ratio': 0.7775, 'base_reward': 27.0, 'max_height': 3.718281828459045, 'floor_space': -4.982032361154967, 'action_x_dist': 4.968102181895745, 'reward_count': 1.0, 'x_penalty': 4.6000000000000005}\n",
      "{'counter': 86, 'ratio': 0.7975, 'base_reward': 46.0, 'max_height': 3.718281828459045, 'floor_space': -4.569655926356141, 'action_x_dist': 2.469060990166731, 'reward_count': 1.0, 'x_penalty': 0.8}\n",
      "{'counter': 87, 'ratio': 0.8025, 'base_reward': 47.0, 'max_height': 3.718281828459045, 'floor_space': -4.596696587832591, 'action_x_dist': 2.304901431054168, 'reward_count': 1.0, 'x_penalty': 0.6}\n",
      "{'counter': 88, 'ratio': 0.8075, 'base_reward': 33.0, 'max_height': 3.718281828459045, 'floor_space': -4.8736245080089695, 'action_x_dist': 4.51334206040471, 'reward_count': 1.0, 'x_penalty': 3.4000000000000004}\n",
      "{'counter': 89, 'ratio': 0.8175, 'base_reward': 43.0, 'max_height': 3.718281828459045, 'floor_space': -4.648468973784771, 'action_x_dist': 2.977362711196349, 'reward_count': 1.0, 'x_penalty': 1.4000000000000001}\n",
      "{'counter': 90, 'ratio': 0.8225, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.720137414589178, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 91, 'ratio': 0.8275, 'base_reward': 37.0, 'max_height': 3.718281828459045, 'floor_space': -4.939864553154191, 'action_x_dist': 3.9710792630827334, 'reward_count': 1.0, 'x_penalty': 2.6}\n",
      "{'counter': 92, 'ratio': 0.8375, 'base_reward': 44.0, 'max_height': 3.718281828459045, 'floor_space': -4.763763049016055, 'action_x_dist': 2.8062186822161745, 'reward_count': 1.0, 'x_penalty': 1.2}\n",
      "{'counter': 93, 'ratio': 0.8425, 'base_reward': 26.0, 'max_height': 3.718281828459045, 'floor_space': -4.9875156119873, 'action_x_dist': 4.992006396588032, 'reward_count': 1.0, 'x_penalty': 4.8}\n",
      "{'counter': 94, 'ratio': 0.8625, 'base_reward': 49.0, 'max_height': 3.718281828459045, 'floor_space': -4.939864553154191, 'action_x_dist': 1.9894096022560235, 'reward_count': 1.0, 'x_penalty': 0.2}\n",
      "{'counter': 95, 'ratio': 0.8725, 'base_reward': 37.0, 'max_height': 3.718281828459045, 'floor_space': -4.992006396588032, 'action_x_dist': 3.9710792630827334, 'reward_count': 1.0, 'x_penalty': 2.6}\n",
      "{'counter': 96, 'ratio': 0.8925, 'base_reward': 39.0, 'max_height': 3.718281828459045, 'floor_space': -4.975559927079149, 'action_x_dist': 3.6540564711000196, 'reward_count': 1.0, 'x_penalty': 2.2}\n",
      "{'counter': 97, 'ratio': 0.9025, 'base_reward': 39.0, 'max_height': 3.718281828459045, 'floor_space': -4.916210019596277, 'action_x_dist': 3.6540564711000196, 'reward_count': 1.0, 'x_penalty': 2.2}\n",
      "{'counter': 98, 'ratio': 0.9075, 'base_reward': 49.0, 'max_height': 3.718281828459045, 'floor_space': -4.9875156119873, 'action_x_dist': 1.9894096022560235, 'reward_count': 1.0, 'x_penalty': 0.2}\n",
      "{'counter': 99, 'ratio': 0.9175, 'base_reward': 33.0, 'max_height': 3.718281828459045, 'floor_space': -4.992006396588032, 'action_x_dist': 4.51334206040471, 'reward_count': 1.0, 'x_penalty': 3.4000000000000004}\n",
      "{'counter': 100, 'ratio': 0.9275, 'base_reward': 31.0, 'max_height': 3.718281828459045, 'floor_space': -4.9875156119873, 'action_x_dist': 4.720137414589178, 'reward_count': 1.0, 'x_penalty': 3.8}\n",
      "{'counter': 101, 'ratio': 0.9375, 'base_reward': 47.0, 'max_height': 3.718281828459045, 'floor_space': -4.857568054851479, 'action_x_dist': 2.304901431054168, 'reward_count': 1.0, 'x_penalty': 0.6}\n",
      "{'counter': 102, 'ratio': 0.94, 'base_reward': 50.0, 'max_height': 3.718281828459045, 'floor_space': -4.992006396588032, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n",
      "{'counter': 103, 'ratio': 0.95, 'base_reward': 40.0, 'max_height': 3.718281828459045, 'floor_space': -4.982032361154967, 'action_x_dist': 3.488381630355155, 'reward_count': 1.0, 'x_penalty': 2.0}\n",
      "{'counter': 104, 'ratio': 0.955, 'base_reward': 36.0, 'max_height': 3.718281828459045, 'floor_space': -4.9955020243926365, 'action_x_dist': 4.1199371666585165, 'reward_count': 1.0, 'x_penalty': 2.8000000000000003}\n",
      "{'counter': 105, 'ratio': 0.965, 'base_reward': 44.0, 'max_height': 3.718281828459045, 'floor_space': -4.992006396588032, 'action_x_dist': 2.8062186822161745, 'reward_count': 1.0, 'x_penalty': 1.2}\n",
      "{'counter': 106, 'ratio': 0.97, 'base_reward': 41.0, 'max_height': 3.718281828459045, 'floor_space': -4.9955020243926365, 'action_x_dist': 3.3195788166773674, 'reward_count': 1.0, 'x_penalty': 1.7999999999999998}\n",
      "{'counter': 107, 'ratio': 0.975, 'base_reward': 49.0, 'max_height': 3.718281828459045, 'floor_space': -4.9955020243926365, 'action_x_dist': 1.9894096022560235, 'reward_count': 1.0, 'x_penalty': 0.2}\n",
      "{'counter': 108, 'ratio': 0.98, 'base_reward': 40.0, 'max_height': 3.718281828459045, 'floor_space': -4.999500024999167, 'action_x_dist': 3.488381630355155, 'reward_count': 1.0, 'x_penalty': 2.0}\n",
      "{'counter': 109, 'ratio': 1.0, 'base_reward': 43.0, 'max_height': 3.718281828459045, 'floor_space': -5.0, 'action_x_dist': 2.977362711196349, 'reward_count': 1.0, 'x_penalty': 1.4000000000000001}\n",
      "{'counter': 109, 'ratio': 1.0, 'base_reward': -200, 'max_height': 3.718281828459045, 'floor_space': -5.0, 'action_x_dist': 1.8393972058572117, 'reward_count': 1.0, 'x_penalty': 0.0}\n"
     ]
    }
   ],
   "source": [
    "base_env = gym.make('BinPack3D-v1', \n",
    "             container_size = (25, 4, 4), #(9, 11, 13),\n",
    "                boxSeqGenerator='CUT-2', \n",
    "                enabled_rotations = [Rotate.NOOP],\n",
    "                n_foreseeable_box = 3,\n",
    "                minSideLen = 1, # 2\n",
    "                maxSideLen = 2, # 5\n",
    "            )\n",
    "wrapped_env = RewardWrapper(base_env)\n",
    "\n",
    "\n",
    "frames = []\n",
    "obs = wrapped_env.reset()\n",
    "frame = wrapped_env.render()\n",
    "wrapped_env_rewards = []\n",
    "while True:\n",
    "    frames.append(frame)\n",
    "    box = wrapped_env.boxSeqGenerator.next_N_boxes()[0]\n",
    "    pos = (box.x,box.y)\n",
    "    act_pos = wrapped_env.position_to_actionIdx(pos)\n",
    "    rot = Rotate.NOOP\n",
    "    action = (act_pos, rot)\n",
    "\n",
    "    obs, reward, done,_, info = wrapped_env.step(action)\n",
    "    frame = wrapped_env.render()\n",
    "    print(info)\n",
    "    # print(reward,done,info)\n",
    "    wrapped_env_rewards.append(reward + wrapped_env_rewards[-1] if len(wrapped_env_rewards) > 0 else reward)\n",
    "    \n",
    "    if done: break\n",
    "\n",
    "wrapped_env.render()\n",
    "# print(obs)\n",
    "imageio.mimsave(GIF_DIR+\"/modified.gif\", frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAGsCAYAAADnrYdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABV7UlEQVR4nO3dfZwVdd3/8fecOXPm3O7hfpfVRTEJIVATrhAqwRS0LkSuun6aGMpPH6ipyIYmaWleVwZqKXbJpUmXSSmGXT9Ds4ygUswQQYxUxLvExGDFm+Xsnvubmd8fZ/awywKy7OLi8no+HvM4Z2a+Z+Yze6jOu+/M92u4rusKAAAAACBfdxcAAAAAAAcLAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4PF3dwEHiuM42rp1q2KxmAzD6O5yAAAAAHQT13XV3Nys2tpa+Xx77yPqsQFp69atqqur6+4yAAAAABwktmzZosMPP3yvbXpsQIrFYpLKf4SqqqpurgYAAABAd2lqalJdXV0lI+xNjw1ILbfVVVVVEZAAAAAA7NOjNwzSAAAAAAAeAhIAAAAAeAhIAAAAAODpsc8gAQAA4MArlUoqFArdXQYOcZZlyTTNLjkWAQkAAAAd5rquGhoatGPHju4uBZAk9erVSzU1NZ2eA5WABAAAgA5rCUcDBgxQOBzu9I9SYH+5rqt0Oq3t27dLkgYOHNip4xGQAAAA0CGlUqkSjvr27dvd5QAKhUKSpO3bt2vAgAGdut2OQRoAAADQIS3PHIXD4W6uBNip5d9jZ5+JIyABAABgv3BbHQ4mXfXvkYAEAAAAAB4CEgAAAAB4CEgAAAA4ZEyYMEH19fXddv4ZM2Zo6tSpB009aI9R7AAAAIBu8qtf/UqWZXV3GWiFgAQAAAB0kz59+nR3CdgFt9gBAACgU1zXVTpf7JbFdd0O11ssFnX55ZerV69e6tu3r77zne9UjnP//fdr9OjRisViqqmp0bRp0yoTkEpSY2Ojzj33XPXv31+hUEhDhgzRvffeW9n/z3/+U2effbZ69+6tvn376swzz9Sbb765x1p2vcXuyCOP1Lx583TBBRcoFotp0KBBWrRoUZvPdPQc6Bh6kAAAANApmUJJw6//fbec+6X/PE3hQMd+0v7sZz/ThRdeqGeeeUbPPvusLrroIh1xxBGaOXOm8vm8vve972no0KHavn27vvGNb2jGjBl67LHHJEnXXXedXnrpJf3ud79Tv3799PrrryuTyUiS0um0Tj75ZH3+85/Xk08+Kb/frxtvvFGnn366nn/+eQUCgX2q79Zbb9X3vvc9XXvttfp//+//6etf/7pOOukkHXPMMV12DuwZAQkAAACHlLq6Oi1YsECGYWjo0KF64YUXtGDBAs2cOVMXXHBBpd1RRx2l//qv/9JnPvMZJZNJRaNRvfXWW/r0pz+t0aNHSyr3+LRYunSpfD6f/ud//qcyJ8+9996rXr166YknntCkSZP2qb4vfelLuvTSSyVJc+fO1YIFC/TEE0/omGOO6bJzYM8ISAAAAOiUkGXqpf88rdvO3VEnnnhim0lFx44dq1tvvVWlUknPP/+8brjhBm3YsEEffPCBHMeRJL311lsaPny4vv71r+srX/mKnnvuOU2aNElTp07VuHHjJEnr16/X66+/rlgs1uZ82WxWf//73/e5vmOPPbby3jAM1dTUVG7z66pzYM8ISAAAAOgUwzA6fJvbwSibzWrSpEmaNGmS7r//fvXv319vvfWWTjvtNOXzeUnSF7/4Rf3jH//Qb3/7W/3hD3/QKaecossuu0w//OEP5TiORo0apSVLlrQ7dv/+/fe5jl1HtTMMoxLUuuoc2LOP/79kAAAAoAPWrFnTbn3IkCF6+eWX9d577+mmm25SXV2dJOnZZ59t9/n+/ftrxowZmjFjhj7/+c/rm9/8pn74wx/qhBNO0IMPPqgBAwaoqqrqgNT+UZzjUMcodgAAADikbNmyRXPmzNErr7yiX/ziF7rjjjs0e/ZsDRo0SIFAQHfccYfeeOMN/frXv9b3vve9Np+9/vrr9cgjj+j111/Xxo0b9Zvf/EbDhg2TJJ177rnq16+fzjzzTP35z3/W5s2btWrVKs2ePVtvv/12l9T+UZzjUEdAAgAAwCHlvPPOUyaT0Wc+8xlddtllmjVrli666CL1799fixcv1v/+7/9q+PDhuummm/TDH/6wzWcDgYCuueYaHXvssTrppJNkmqaWLl0qSQqHw3ryySc1aNAgffnLX9awYcN0wQUXKJPJdFlvz0dxjkOd4e7P4PEfA01NTYrH40okEvxjAQAA6ELZbFabN2/W4MGDFQwGu7scQNLe/112JBvQgwQAAAAAHgISAAAAAHg6FJBuuOEGGYbRZqmpqansd11XN9xwg2praxUKhTRhwgRt3LixzTFyuZxmzZqlfv36KRKJaMqUKe0eKGtsbNT06dMVj8cVj8c1ffp07dixY/+vEgAAAAD2QYd7kD71qU9p27ZtleWFF16o7Lvlllt02223aeHChVq3bp1qamo0ceJENTc3V9rU19dr2bJlWrp0qZ566iklk0lNnjxZpVKp0mbatGnasGGDli9fruXLl2vDhg2aPn16Jy8VAAAAAPauw/Mg+f3+Nr1GLVzX1e23365vf/vb+vKXvyxJ+tnPfqbq6mo98MADuvjii5VIJHTPPffovvvu06mnnipJuv/++1VXV6c//OEPOu2007Rp0yYtX75ca9as0ZgxYyRJP/nJTzR27Fi98sorGjp0aGeuFwAAAAD2qMM9SK+99ppqa2s1ePBgffWrX9Ubb7whSdq8ebMaGho0adKkSlvbtjV+/HitXr1akrR+/XoVCoU2bWprazVixIhKm6efflrxeLwSjiTpxBNPVDwer7TZnVwup6ampjYLAAAAAHREhwLSmDFj9POf/1y///3v9ZOf/EQNDQ0aN26c3n//fTU0NEiSqqur23ymurq6sq+hoUGBQEC9e/fea5sBAwa0O/eAAQMqbXZn/vz5lWeW4vF4ZfZjAAAAANhXHQpIX/ziF/WVr3xFI0eO1Kmnnqrf/va3ksq30rUwDKPNZ1zXbbdtV7u22V37DzvONddco0QiUVm2bNmyT9cEAAAAAC06Ncx3JBLRyJEj9dprr1WeS9q1l2f79u2VXqWamhrl83k1Njbutc0777zT7lzvvvtuu96p1mzbVlVVVZsFAAAAADqiUwEpl8tp06ZNGjhwoAYPHqyamhqtXLmysj+fz2vVqlUaN26cJGnUqFGyLKtNm23btunFF1+stBk7dqwSiYTWrl1bafPMM88okUhU2gAAAAAHswkTJqi+vr6yfuSRR+r222+vrDc0NGjixImKRCLq1auXpPJdVA8//HCnzjtjxgxNnTq1U8c4WD3xxBMyDOOAT//ToVHsrrrqKp1xxhkaNGiQtm/frhtvvFFNTU06//zzZRiG6uvrNW/ePA0ZMkRDhgzRvHnzFA6HNW3aNElSPB7XhRdeqCuvvFJ9+/ZVnz59dNVVV1Vu2ZOkYcOG6fTTT9fMmTN19913S5IuuugiTZ48mRHsAAAA8LG0bt06RSKRyvqCBQu0bds2bdiwQfF4XFK542DXZ/Xx0etQQHr77bd1zjnn6L333lP//v114oknas2aNTriiCMkSVdffbUymYwuvfRSNTY2asyYMVqxYoVisVjlGAsWLJDf79dZZ52lTCajU045RYsXL5ZpmpU2S5Ys0RVXXFEZ7W7KlClauHBhV1wvAAAA8JHr379/m/W///3vGjVqlIYMGVLZtrupdD5K+XxegUCgW2s4GOro0C12S5cu1datW5XP5/XPf/5TDz30kIYPH17ZbxiGbrjhBm3btk3ZbFarVq3SiBEj2hwjGAzqjjvu0Pvvv690Oq1HH3203Yhzffr00f33318Zrvv++++vdD0CAADgIOO6Uj7VPYvrdqjUCRMmaNasWaqvr1fv3r1VXV2tRYsWKZVK6f/+3/+rWCymT3ziE/rd735X+cyqVav0mc98RrZta+DAgfrWt76lYrFY2Z9KpXTeeecpGo1q4MCBuvXWW9udt/UtdkceeaQeeugh/fznP5dhGJoxY4ak9rfY/fOf/9TZZ5+t3r17q2/fvjrzzDP15ptvVvaXSiXNmTNHvXr1Ut++fXX11VfL7cDfY8KECbr88ss1Z84c9evXTxMnTpQkvfTSS/rSl76kaDSq6upqTZ8+Xe+9954k6dFHH1WvXr3kOI4kacOGDTIMQ9/85jcrx7344ot1zjnnSJLef/99nXPOOTr88MMVDoc1cuRI/eIXv9inOh577DF98pOfVCgU0sknn9zm2g+kDk8UCwAAALRRSEvzarvn3NdulQKRD2/Xys9+9jNdffXVWrt2rR588EF9/etf18MPP6x/+7d/07XXXqsFCxZo+vTpeuutt9TY2KgvfelLmjFjhn7+85/r5Zdf1syZMxUMBnXDDTdIkr75zW/q8ccf17Jly1RTU6Nrr71W69ev1/HHH7/b869bt07nnXeeqqqq9KMf/UihUKhdm3Q6rZNPPlmf//zn9eSTT8rv9+vGG2/U6aefrueff16BQEC33nqrfvrTn+qee+7R8OHDdeutt2rZsmX6whe+0KG/xde//nX95S9/keu62rZtm8aPH6+ZM2fqtttuUyaT0dy5c3XWWWfpT3/6k0466SQ1Nzfrr3/9q0aNGqVVq1apX79+WrVqVeWYTzzxhL7xjW9IkrLZrEaNGqW5c+eqqqpKv/3tbzV9+nQdddRRbeY93bWOLVu26Mtf/rIuueQSff3rX9ezzz6rK6+8cp+vqzMISAAAADikHHfccfrOd74jqTxVzE033aR+/fpp5syZkqTrr79ed911l55//vnK3U4LFy6UYRg65phjtHXrVs2dO1fXX3+90um07rnnHv385z+v9Hz87Gc/0+GHH77H8/fv31+2bSsUCu3xtrqlS5fK5/Ppf/7nfypT3dx7773q1auXnnjiCU2aNEm33367rrnmGn3lK1+RJP34xz/W73//+w79LY4++mjdcsstlfXrr79eJ5xwgubNm1fZ9tOf/lR1dXV69dVX9clPflLHH3+8nnjiCY0aNaoShv7jP/5Dzc3NSqVSevXVVzVhwgRJ0mGHHaarrrqqcqxZs2Zp+fLl+t///d82AWnXOq699lodddRRWrBggQzD0NChQ/XCCy/o5ptv7tD17Q8CEgAAADrHCpd7crrr3B107LHHVt6bpqm+fftq5MiRlW0tU8ts375dmzZt0tixY9vMx/nZz35WyWRSb7/9thobG5XP5zV27NjK/j59+nR6cLH169fr9ddfb/Msv1Tukfn73/+uRCKhbdu2tTmv3+/X6NGjO3Sb3ejRo9ud9/HHH1c0Gm3X9u9//7s++clPasKECXriiSc0Z84c/fnPf9aNN96ohx56SE899ZR27Nih6upqHXPMMZLKtwHedNNNevDBB/XPf/5TuVxOuVyuzYAVu6tj06ZNOvHEE9v83Vtf64FEQAIAAEDnGEaHb3PrTpZltVk3DKPNtpYf5Y7jyHXdNj/SJVUCiGEYHQojHeE4jkaNGqUlS5a027frgA+dsWtQcRxHZ5xxxm57agYOHCip/MzQPffco7/97W/y+XwaPny4xo8fr1WrVqmxsVHjx4+vfObWW2/VggULdPvtt2vkyJGKRCKqr69XPp/fax0H6u+6Lzo1DxIAAADQkw0fPlyrV69u84N99erVisViOuyww3T00UfLsiytWbOmsr+xsVGvvvpqp857wgkn6LXXXtOAAQN09NFHt1ni8bji8bgGDhzY5rzFYlHr16/v9Hk3btyoI488st15W0JMy3NIt99+u8aPHy/DMDR+/Hg98cQTeuKJJ9oEpD//+c8688wz9bWvfU3HHXecjjrqKL322msfWsfw4cPbXJukdusHCgEJAAAA2INLL71UW7Zs0axZs/Tyyy/rkUce0Xe/+13NmTNHPp9P0WhUF154ob75zW/qj3/8o1588UXNmDFDPl/nfmafe+656tevn84880z9+c9/1ubNm7Vq1SrNnj1bb7/9tiRp9uzZuummm7Rs2TK9/PLLuvTSSzs9iepll12mDz74QOecc47Wrl2rN954QytWrNAFF1ygUqkkqTy36fHHH6/777+/8qzRSSedpOeee67N80dS+dmilStXavXq1dq0aZMuvvhiNTQ0fGgdl1xyif7+979rzpw5euWVV/TAAw9o8eLFnbq2fUVAAgAAAPbgsMMO02OPPaa1a9fquOOO0yWXXKILL7ywMsiDJP3gBz/QSSedpClTpujUU0/V5z73OY0aNapT5w2Hw3ryySc1aNAgffnLX9awYcN0wQUXKJPJqKqqSpJ05ZVX6rzzztOMGTM0duxYxWIx/du//VunzltbW6u//OUvKpVKOu200zRixAjNnj1b8Xi8Teg7+eSTVSqVKmGod+/eGj58uPr3769hw4ZV2l133XU64YQTdNppp2nChAmqqanR1KlTP7SOQYMG6aGHHtKjjz6q4447Tj/+8Y/bDBxxIBlud97gdwA1NTUpHo8rkUhU/hEBAACg87LZrDZv3qzBgwcrGAx2dzmApL3/u+xINqAHCQAAAAA8BCQAAACgh3nrrbcUjUb3uLz11lvdXeJBi2G+AQAAgB6mtrZWGzZs2Ot+7B4BCQAAAOhh/H6/jj766O4u42OJW+wAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAIeMGTNmyDAMGYYhy7J01FFH6aqrrlIqldKbb75Z2WcYhnr37q2TTjpJq1atanOMLVu26MILL1Rtba0CgYCOOOIIzZ49W++//343XRW6EgEJAAAAh5TTTz9d27Zt0xtvvKEbb7xRd955p6666qrK/j/84Q/atm2bVq1apaqqKn3pS1/S5s2bJUlvvPGGRo8erVdffVW/+MUv9Prrr+vHP/6x/vjHP2rs2LH64IMPuuuy0EWYKBYAAACd4rquMsVMt5w75A/JMIwOfca2bdXU1EiSpk2bpscff1wPP/yw5s6dK0nq27evampqVFNTo7vvvluHH364VqxYoYsvvliXXXaZAoGAVqxYoVAoJEkaNGiQPv3pT+sTn/iEvv3tb+uuu+7q2ovER4qABAAAgE7JFDMa88CYbjn3M9OeUdgKd+oYoVBIhUJht/vC4fKxC4WCPvjgA/3+97/X97///Uo4alFTU6Nzzz1XDz74oO68884OhzYcPLjFDgAAAIestWvX6oEHHtApp5zSbl8qldI111wj0zQ1fvx4vfbaa3JdV8OGDdvtsYYNG6bGxka9++67B7psHED0IAEAAKBTQv6Qnpn2TLedu6N+85vfKBqNqlgsqlAo6Mwzz9Qdd9yhdDotSRo3bpx8Pp/S6bQGDhyoxYsXa+TIkXrmmb1fo+u6kkTv0cccAQkAAACdYhhGp29z+yidfPLJuuuuu2RZlmpra2VZliTpzTfflCQ9+OCDGj58uHr16qW+fftWPnf00UfLMAy99NJLmjp1arvjvvzyy+rdu7f69ev3UVwGDhBusQMAAMAhJRKJ6Oijj9YRRxxRCUet1dXV6ROf+ESbcCSVB2+YOHGi7rzzTmUybQelaGho0JIlS3T22WfTg/QxR0ACAAAA9tHChQuVy+V02mmn6cknn9SWLVu0fPlyTZw4UYcddpi+//3vd3eJ6CQCEgAAALCPhgwZomeffVaf+MQndPbZZ+sTn/iELrroIp188sl6+umn1adPn+4uEZ3EM0gAAAA4ZCxevHiP+4488sjKQAt7c8QRR+jee+/twqpwMKEHCQAAAAA8BCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAHFJWr14t0zR1+umnt9n+t7/9Teecc47q6uoUCoU0bNgw/ehHP2r3edd1tWjRIo0ZM0bRaFS9evXS6NGjdfvttyudTn9Ul4EDhIAEAACAQ8pPf/pTzZo1S0899ZTeeuutyvb169erf//+uv/++7Vx40Z9+9vf1jXXXKOFCxe2+fz06dNVX1+vM888U48//rg2bNig6667To888ohWrFjxUV8Oupi/uwsAAAAAPiqpVEq//OUvtW7dOjU0NGjx4sW6/vrrJUkXXHBBm7ZHHXWUnn76af3qV7/S5ZdfLkn65S9/qSVLlujhhx/WmWeeWWl75JFHasqUKWpqavroLgYHBAEJAAAAneK6rtxMplvObYRCMgxjn9s/+OCDGjp0qIYOHaqvfe1rmjVrlq677ro9HiORSKhPnz6V9SVLlmjo0KFtwlGlFsNQPB7v+EXgoEJAAgAAQKe4mYxeOWFUt5x76HPrZYTD+9z+nnvu0de+9jVJ0umnn65kMqk//vGPOvXUU9u1ffrpp/XLX/5Sv/3tbyvbXnvtNQ0dOrTzheOgxTNIAAAAOCS88sorWrt2rb761a9Kkvx+v84++2z99Kc/bdd248aNOvPMM3X99ddr4sSJle2u63aoxwofP/QgAQAAoFOMUEhDn1vfbefeV/fcc4+KxaIOO+ywyjbXdWVZlhobG9W7d29J0ksvvaQvfOELmjlzpr7zne+0OcYnP/lJbdq0qWuKx0GJgAQAAIBOMQyjQ7e5dYdisaif//znuvXWWzVp0qQ2+77yla9oyZIluvzyy7Vx40Z94Qtf0Pnnn6/vf//77Y4zbdo0ffWrX9UjjzzS7jkk13XV1NTEc0gfcwQkAAAA9Hi/+c1v1NjYqAsvvLBdgPn3f/933XPPPTr55JN18skna9KkSZozZ44aGhokSaZpqn///pKks846S8uWLdM555yj6667ThMnTlT//v31wgsvaMGCBZo1a5amTp36UV8eupDhuq7b3UUcCC3pPZFIqKqqqrvLAQAA6DGy2aw2b96swYMHKxgMdnc5++SMM86Q4zhtBlxo8dxzz2nUqFE644wz9Oijj7bbf8QRR+jNN9+srDuOo0WLFumnP/2pNm7cKL/fryFDhui8887TzJkzFerAbX/oOnv7d9mRbEBAAgAAQId8HAMSer6uCkiMYgcAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAD2i+M43V0CUNFV/x6ZKBYAAAAdEggE5PP5tHXrVvXv31+BQECGYXR3WThEua6rfD6vd999Vz6fT4FAoFPHIyABAACgQ3w+nwYPHqxt27Zp69at3V0OIEkKh8MaNGiQfL7O3STXqYA0f/58XXvttZo9e7Zuv/12SeUE9x//8R9atGiRGhsbNWbMGP33f/+3PvWpT1U+l8vldNVVV+kXv/iFMpmMTjnlFN155506/PDDK20aGxt1xRVX6Ne//rUkacqUKbrjjjvUq1evzpQMAACALhAIBDRo0CAVi0WVSqXuLgeHONM05ff7u6Qnc78D0rp167Ro0SIde+yxbbbfcsstuu2227R48WJ98pOf1I033qiJEyfqlVdeUSwWkyTV19fr0Ucf1dKlS9W3b19deeWVmjx5stavXy/TNCVJ06ZN09tvv63ly5dLki666CJNnz5djz766P6WDAAAgC5kGIYsy5JlWd1dCtBlDNd13Y5+KJlM6oQTTtCdd96pG2+8Uccff7xuv/12ua6r2tpa1dfXa+7cuZLKvUXV1dW6+eabdfHFFyuRSKh///667777dPbZZ0uStm7dqrq6Oj322GM67bTTtGnTJg0fPlxr1qzRmDFjJElr1qzR2LFj9fLLL2vo0KHtasrlcsrlcpX1pqYm1dXVKZFIqKqqar/+OAAAAAA+/pqamhSPx/cpG+zXDXqXXXaZ/vVf/1Wnnnpqm+2bN29WQ0ODJk2aVNlm27bGjx+v1atXS5LWr1+vQqHQpk1tba1GjBhRafP0008rHo9XwpEknXjiiYrH45U2u5o/f77i8Xhlqaur259LAwAAAHAI63BAWrp0qZ577jnNnz+/3b6GhgZJUnV1dZvt1dXVlX0NDQ0KBALq3bv3XtsMGDCg3fEHDBhQabOra665RolEorJs2bKlo5cGAAAA4BDXoWeQtmzZotmzZ2vFihUKBoN7bLfrw1Gu637oA1O7ttld+70dx7Zt2ba913MAAAAAwN50qAdp/fr12r59u0aNGiW/3y+/369Vq1bpv/7rv+T3+ys9R7v28mzfvr2yr6amRvl8Xo2NjXtt884777Q7/7vvvtuudwoAAAAAukqHAtIpp5yiF154QRs2bKgso0eP1rnnnqsNGzboqKOOUk1NjVauXFn5TD6f16pVqzRu3DhJ0qhRo2RZVps227Zt04svvlhpM3bsWCUSCa1du7bS5plnnlEikai0AQAAAICu1qFb7GKxmEaMGNFmWyQSUd++fSvb6+vrNW/ePA0ZMkRDhgzRvHnzFA6HNW3aNElSPB7XhRdeqCuvvFJ9+/ZVnz59dNVVV2nkyJGVQR+GDRum008/XTNnztTdd98tqTzM9+TJk3c7gh0AAAAAdIVOTRS7O1dffbUymYwuvfTSykSxK1asqMyBJEkLFiyQ3+/XWWedVZkodvHixZU5kCRpyZIluuKKKyqj3U2ZMkULFy7s6nIBAAAAoGK/5kH6OOjIWOcAAAAAeq4DPg8SAAAAAPREBCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAAA8BCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAAA8BCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAAA8BCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAAA8BCQAAAAA8BCQAAAAAMBDQAIAAAAADwEJAAAAADwEJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPB0KSHfddZeOPfZYVVVVqaqqSmPHjtXvfve7yn7XdXXDDTeotrZWoVBIEyZM0MaNG9scI5fLadasWerXr58ikYimTJmit99+u02bxsZGTZ8+XfF4XPF4XNOnT9eOHTv2/yoBAAAAYB90KCAdfvjhuummm/Tss8/q2Wef1Re+8AWdeeaZlRB0yy236LbbbtPChQu1bt061dTUaOLEiWpubq4co76+XsuWLdPSpUv11FNPKZlMavLkySqVSpU206ZN04YNG7R8+XItX75cGzZs0PTp07vokgEAAABg9wzXdd3OHKBPnz76wQ9+oAsuuEC1tbWqr6/X3LlzJZV7i6qrq3XzzTfr4osvViKRUP/+/XXffffp7LPPliRt3bpVdXV1euyxx3Taaadp06ZNGj58uNasWaMxY8ZIktasWaOxY8fq5Zdf1tChQ3dbRy6XUy6Xq6w3NTWprq5OiURCVVVVnblEAAAAAB9jTU1Nisfj+5QN9vsZpFKppKVLlyqVSmns2LHavHmzGhoaNGnSpEob27Y1fvx4rV69WpK0fv16FQqFNm1qa2s1YsSISpunn35a8Xi8Eo4k6cQTT1Q8Hq+02Z358+dXbsmLx+Oqq6vb30sDAAAAcIjqcEB64YUXFI1GZdu2LrnkEi1btkzDhw9XQ0ODJKm6urpN++rq6sq+hoYGBQIB9e7de69tBgwY0O68AwYMqLTZnWuuuUaJRKKybNmypaOXBgAAAOAQ5+/oB4YOHaoNGzZox44deuihh3T++edr1apVlf2GYbRp77puu2272rXN7tp/2HFs25Zt2/t6GQAAAADQTod7kAKBgI4++miNHj1a8+fP13HHHacf/ehHqqmpkaR2vTzbt2+v9CrV1NQon8+rsbFxr23eeeeddud999132/VOAQAAAEBX6vQ8SK7rKpfLafDgwaqpqdHKlSsr+/L5vFatWqVx48ZJkkaNGiXLstq02bZtm1588cVKm7FjxyqRSGjt2rWVNs8884wSiUSlDQAAAAAcCB26xe7aa6/VF7/4RdXV1am5uVlLly7VE088oeXLl8swDNXX12vevHkaMmSIhgwZonnz5ikcDmvatGmSpHg8rgsvvFBXXnml+vbtqz59+uiqq67SyJEjdeqpp0qShg0bptNPP10zZ87U3XffLUm66KKLNHny5D2OYAcAAAAAXaFDAemdd97R9OnTtW3bNsXjcR177LFavny5Jk6cKEm6+uqrlclkdOmll6qxsVFjxozRihUrFIvFKsdYsGCB/H6/zjrrLGUyGZ1yyilavHixTNOstFmyZImuuOKKymh3U6ZM0cKFC7viegEAAABgjzo9D9LBqiNjnQMAAADouT6SeZAAAAAAoKchIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHg6FJDmz5+vf/mXf1EsFtOAAQM0depUvfLKK23auK6rG264QbW1tQqFQpowYYI2btzYpk0ul9OsWbPUr18/RSIRTZkyRW+//XabNo2NjZo+fbri8bji8bimT5+uHTt27N9VAgAAAMA+6FBAWrVqlS677DKtWbNGK1euVLFY1KRJk5RKpSptbrnlFt12221auHCh1q1bp5qaGk2cOFHNzc2VNvX19Vq2bJmWLl2qp556SslkUpMnT1apVKq0mTZtmjZs2KDly5dr+fLl2rBhg6ZPn94FlwwAAAAAu2e4ruvu74ffffddDRgwQKtWrdJJJ50k13VVW1ur+vp6zZ07V1K5t6i6ulo333yzLr74YiUSCfXv31/33Xefzj77bEnS1q1bVVdXp8cee0ynnXaaNm3apOHDh2vNmjUaM2aMJGnNmjUaO3asXn75ZQ0dOvRDa2tqalI8HlcikVBVVdX+XiIAAACAj7mOZINOPYOUSCQkSX369JEkbd68WQ0NDZo0aVKljW3bGj9+vFavXi1JWr9+vQqFQps2tbW1GjFiRKXN008/rXg8XglHknTiiScqHo9X2uwql8upqampzQIAAAAAHbHfAcl1Xc2ZM0ef+9znNGLECElSQ0ODJKm6urpN2+rq6sq+hoYGBQIB9e7de69tBgwY0O6cAwYMqLTZ1fz58yvPK8XjcdXV1e3vpQEAAAA4RO13QLr88sv1/PPP6xe/+EW7fYZhtFl3Xbfdtl3t2mZ37fd2nGuuuUaJRKKybNmyZV8uAwAAAAAq9isgzZo1S7/+9a/1+OOP6/DDD69sr6mpkaR2vTzbt2+v9CrV1NQon8+rsbFxr23eeeeddud999132/VOtbBtW1VVVW0WAAAAAOiIDgUk13V1+eWX61e/+pX+9Kc/afDgwW32Dx48WDU1NVq5cmVlWz6f16pVqzRu3DhJ0qhRo2RZVps227Zt04svvlhpM3bsWCUSCa1du7bS5plnnlEikai0AQAAAICu5u9I48suu0wPPPCAHnnkEcVisUpPUTweVygUkmEYqq+v17x58zRkyBANGTJE8+bNUzgc1rRp0yptL7zwQl155ZXq27ev+vTpo6uuukojR47UqaeeKkkaNmyYTj/9dM2cOVN33323JOmiiy7S5MmT92kEOwAAAADYHx0KSHfddZckacKECW2233vvvZoxY4Yk6eqrr1Ymk9Gll16qxsZGjRkzRitWrFAsFqu0X7Bggfx+v8466yxlMhmdcsopWrx4sUzTrLRZsmSJrrjiispod1OmTNHChQv35xoBAAAAYJ90ah6kgxnzIAEAAACQPsJ5kAAAAACgJyEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAODpcEB68skndcYZZ6i2tlaGYejhhx9us991Xd1www2qra1VKBTShAkTtHHjxjZtcrmcZs2apX79+ikSiWjKlCl6++2327RpbGzU9OnTFY/HFY/HNX36dO3YsaPDFwgAAAAA+6rDASmVSum4447TwoULd7v/lltu0W233aaFCxdq3bp1qqmp0cSJE9Xc3FxpU19fr2XLlmnp0qV66qmnlEwmNXnyZJVKpUqbadOmacOGDVq+fLmWL1+uDRs2aPr06ftxiQAAAACwbwzXdd39/rBhaNmyZZo6daqkcu9RbW2t6uvrNXfuXEnl3qLq6mrdfPPNuvjii5VIJNS/f3/dd999OvvssyVJW7duVV1dnR577DGddtpp2rRpk4YPH641a9ZozJgxkqQ1a9Zo7NixevnllzV06NAPra2pqUnxeFyJREJVVVX7e4kAAAAAPuY6kg269BmkzZs3q6GhQZMmTapss21b48eP1+rVqyVJ69evV6FQaNOmtrZWI0aMqLR5+umnFY/HK+FIkk488UTF4/FKm13lcjk1NTW1WQAAAACgI7o0IDU0NEiSqqur22yvrq6u7GtoaFAgEFDv3r332mbAgAHtjj9gwIBKm13Nnz+/8rxSPB5XXV1dp68HAAAAwKHlgIxiZxhGm3XXddtt29WubXbXfm/Hueaaa5RIJCrLli1b9qNyAAAAAIeyLg1INTU1ktSul2f79u2VXqWamhrl83k1Njbutc0777zT7vjvvvtuu96pFrZtq6qqqs0CAAAAAB3RpQFp8ODBqqmp0cqVKyvb8vm8Vq1apXHjxkmSRo0aJcuy2rTZtm2bXnzxxUqbsWPHKpFIaO3atZU2zzzzjBKJRKUNAAAAAHQ1f0c/kEwm9frrr1fWN2/erA0bNqhPnz4aNGiQ6uvrNW/ePA0ZMkRDhgzRvHnzFA6HNW3aNElSPB7XhRdeqCuvvFJ9+/ZVnz59dNVVV2nkyJE69dRTJUnDhg3T6aefrpkzZ+ruu++WJF100UWaPHnyPo1gBwAAAAD7o8MB6dlnn9XJJ59cWZ8zZ44k6fzzz9fixYt19dVXK5PJ6NJLL1VjY6PGjBmjFStWKBaLVT6zYMEC+f1+nXXWWcpkMjrllFO0ePFimaZZabNkyRJdccUVldHupkyZsse5lwAAAACgK3RqHqSDGfMgAQAAAJC6cR4kAAAAAPg4IyABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAICHgAQAAAAAHgISAAAAAHgISAAAAADgISABAAAAgIeABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4PF3dwEAAADAgeQ6jpxUSk5zs0rNSTnJZpWam+VU3iflNDfLSSVlWAH5B9bIqhkoa2CN/DUD5e/fT4aPfoVDBQEJAAAABy23WJSTTKqUTHoBp1lOMrXHkFNK7i74pDpXhN8va8AA+QcOlDWwJTjVlN/X1Mg/cKDMXr1kGEbXXDR2r1SQCmkpny6/7vq+kJHyqcq6m0/LyadVyiWV3bFjn09DQAIAAMAB4RYKbYPN3sJMMll+39y88zPJpNx0usvqMSxLvlhMvlhUZjRWfh+NVN6bsaicbE7Fhm0qbGtQoaFBxe3bpWJRha1bVdi6VZk9HTsY9MJS696nXUJUNNpl13LQcV2plG8TWtx8SsVsSoVcSsVsUsVcWqVsUk4uJSeflpNLyfVCjVFIyyhkZBTT8hUzMksZmcWs/KWMLCcjv5OV3y12qCRDkuktwZy7z58jIAEAAKAdN59XqblZpaYmOcnWweXDe2xaAo6by3VZPUYwWA42kWglzPiibcNO221RLwBFZca8MGTbHf87FIsqvveeClu3tQ1Ord6X3ntPbjar/JtvKv/mm3s8li8W202IKr9aAwfKX1OzXzXusXbXVaHkKlcsKZfPK59Nq5BJqpBLq5BNqZgrh5RSLi0nn5KbS8stpMu9MMWMfIW0jGJGvmJaphda/KWsrFJGlpOV5WRlu1nZTla2cjLltDm/Icnylq5Ucg2lFVRGtjJuQGnZyspW2rWVUUAZ2Uq7wcr7jGvrg4Ih6Z59Or7huu6+x6mPkaamJsXjcSUSCVVVVXV3OQAAAB8pJ5eT09TkhZYmlZqaK6+l5iY5La/NyVbrzd5nmuVms11WixEOVwJLJbjsGmx2F3y8YGNGIjICgS6rp6s5+byKDQ0qbGsdnLzXbdtU2LZNbnPzPh2rFI2qGK9SsSqqYiysYtRWMWKrGPGrGPLJDUk+Jy9fKSuzlJW/lJXfycpycrLcnAJuTrabU8DNy1ZeQeUUVF4Bo3SA/wo7FVyzHFK8AJNROaxkFVTOZytvBJX3BVXwBVUwQyr5giqaIZWssBwzKMcflqywXCskBcIyrIiMQFg+OyyfHZVl2bIts7z4fd5iyrZavff7vPXy+1w6qV69eu1TNqAHCQAA4CDjuq7cXK7ce9PSi9Pc3CbkOM1tw8+uIcfN57ukFt/ugs2ewkzU29b6fSQiw3/w/OQslhyl8iWlckWl80UlcyWlc0Ulc0Wl8yVlc1mVculyr0ohIyeflpvPlG8FK2RkFDNSIStfMS2jlCvfClbKyizlyreBOTkFnKwsN69AdVZ2dUGh4/OyC1IwU5A/U5KZLklpV07ap2LaVCHtUyFtyi35ZCaTMpNJ2f/cwwUYrvxBR1a4JH+4JMtbWr83g4729jhUVgHlFFDesJUzgsr5gioYtgpmSAVfSEUzqJIZUskfkuMPyfWXw4prhVsFlpB8dlSmHZFph2XaUVnBsPyhqOxAsBJQ+ngBJWD65PN13zNa+Q48H3bw/GsFAADoIVzXlZvJtOmRaRt2dt9rU2nb3CwVCp0vxDC8IBOTr6rKe43JjFXJrIrJF6vyAk2r9davkYgM0+x8HfvJdV3lio5SuaJSuZJS+aJSrcJMMptXPp1UIdOkYqZZpWyznFxSbi5Zfq4ln5SvkJK/lJK/mFaglJbtZhRVVhFlFDFyiiijfkZOUWUUVrbreloMb2lhe0uv9k0dGeXAUrCVyQRVyARUzPhVTPvkpA25KVduqiQli5IjFTOmihlTen8P5/ab8vXpLXNAP1k11bIG1sg+rE6Bww+XddggWQMHyo7HGVRiDwhIAAAAu3ByuVbP3ZRHTNs5kpr3vM2ut6q1DjvJpFTs2APlu+Xz7RJuWoWc6M6w46uKyWzXpkq+cPgjHZ665LhK59uGmVSu3FuTyheVzmRVSDepkGlWMdukUjYpN9csN7czzJiFlPyltKxSSoFSRmFlFFZOUaMcYPooq0FGVmFlFVZOPqMDT4t04E/hyFDBF1TRZ6voC6pk2iqZQe8WsJAcf1CuPyT5QzKsoBQIyWeFZQRCMgNhmXZY/kBYph0p96wEQvLZEckflKzQzsUfks9vK2QYCkmK76Um13FUev9977a9ts9BFbdtazWoREnO9vfkbH9PhRdf3u2xjFBIVk2NYqd8QQOuumrf/zCHAAISAADoMSqjpqVSbQcW8JbyHDje+6Q3XHRzs0qpluBTXtyu6L2RJL9/t7025VvSdu21KYecSo9PrEq+SPiA/L/8juMqUyiVbynzXtP5ojL58vtMvqhsLqd8NqV8Lq1iJqlSphxolE9KuaSMghdoimlZxZSsUkZBN62wsoooq4hRfu2trCJGRhHlZBsd/LvuY+eVI5/yvpAK/oiKZlglKyLHCkuBqGTHZAQiMkNV5dvAwlWyQjFZoSopEJHsaPk1ECu/t0KSFZbPDMg2DHXdkAmdZ/h88vfvL3///gode+xu27iFgorbt6vQ7pmoBhW2bVVxW4NKjY1yMxnlN29W8f0PPuKrOPgRkAAAQLerTOSZTLaZ56ZNr02qdcBpCT5tA05XDiwgSb5IpO1Q0NHozlHRWvfe7HrLmteLY4RC+xVwWm4tS6dySmdSymdSymYyymXTyntLMZdWMZ9RMZdRKZ+RW8jKyWfkFLJSsbwYxax8pZz3rExOppOV383LcvKyjYL3EH/5tWqXdbMjPTNSh3pnCkag/LyLGVHJXw40rtUSVmIyg1H5gjFZoaj8oSoFQjH5grFy4AlEWwWbmBSIyGeFFDQMBTtWcY9kWJasww6Tddhhe2zjZLPlQSUaGmTG99ZndWgiIAEAgP3mlkpyMtlyuEkldx9wWkJN64Cza69NZyfy3IURCpVDTSTaPuC0DAEdibYdDjoS9QYd8NZb357mulIx12pCyqwKuZRymYxyuZTSmbTyuXdU3LFZhXfKgcXJp1UqZOXmM3IKOamYkVHMScWsfKVycCmHlrxMbwQyyy2URyBTQbYK6mMU1KdL/zLaOTlMB+R8YRXMkIr+cqBxrKjcQEQKRGXYUfmC5SDjD0YVCMflD0Zl2DEvyMR2CTVRWabV5UM/Y9/5gkEFjjxSgSOP7O5SDkoEJAAAeji3UJCTyZSXdFpu5X1GTmYP6+mMSum0iumkiumUSulU5RhuJiNlcjKyORn5LroVrYVllQNLS5DZW8Bp6c1peR8MyAyaMixXxWJOuUyzCpmUCpmk8pmkCrmUN+dLUk5+u9z8m1JzSmosz/fiK6bl8yam9HvzvAS8eV4Cbvs5Xlrmd+nyqT/30OFUkk95BZQ3AioYAe/ZGFuOL+A9G2PL9dtyzWD5mRgrKJ8VlM8KyRcIyR8IyW+XX61gWAE7LMsu75M/2GqxvWdjbMkfksyAbJ/voLrVDDiQCEgAAHQz13Xl5vP7HF5K6bQKqaQK6aSKqaRK6ZRKmbSctBdestmdASaXl6/ofHgR+2jXgblaOIbki0ZkxeKV4NIm4EQiMiMhGUFLru2X4/epaEoly1DRKKnkK6lolOQ6ORXyKTn5lJQv99YYhSb5ig3eZJVZ+d/PyNqekeUNp2y6WVm7TFIZ8JYDIe+aysouD5XsWsoZlvKGraIXXEo+W45pq2SWX13TCx3+oAyr/EC/LxCSaQVl2iH57XCb0GIHQ7JDEdnBsIKhiPx2+UF+0/QrJCl0gK4LQBkBCQCAD9FyG5mby5Zfs5mdr9lsuVclW95XyqSVTzUrl25SoSW8pNNyMmmv9yUrZbLl8JLNy5fLy8wWZXRy3vZ9uWuqZEi5gJS1pJy3lN8bygVar3vvA0blfSlgqhTwy7V8cixTjt+Q6zdk+A3JlEzT0dnJqA4rFGWVGuRzsrK83pegm5WdzstMd11Q25uc61dGdnlxbWWNoPKVySnLc7wUzWD5VjEzJMebkNKwwuXnWQKRcoAJRry5XaKyQlEFQhEFQlGFbFvhgF8hy1SvgKmA/6MbJQ7AgUdAAgB8bLmOIzeXk5PNlntadgkrLUHGyZaDiZNtCTW53ezLqJhOl3tiMpny9mxORi4no9C5eVFM7fsjHwVzl6ASaBViWocaL9AUA6ZKtl+lgCUnYMqxTLkBU47fJ9fvqwQYwydZhiPbKSlYKipUKirkFBQuFRQt5dTPySvm5lTlFhR0XYUcV0G3vNiuu7PXqOQtndA6wGRVnqgy7wuq4CsHmJIZVNGbpNL1lyendK2wDCssw/YCjN0yfHJUVigifzAmOxSVHY4qHLQVtEz1tUxZpsFcLwA6hIAEADhgXMeRk07vnAQzld5tr8uuPTPtAk3Ley8EVV5zuQNW+55uJcv5y8Ekb+363ii/ekvRb6hkWyoFLTm2JSfgl2P75VrlIONaptyWEGMaMnyufKZkuSXZxZLsUkGhYkGhUl6RUk69SnlFS1lVOTnFnax6uTnZrts+eDmSumAgt4JrKq2gGhVSzrCV9YWUN0LKm2EVzZCK/pAcf0ROICxZEckKywhEvABTDi/+YFRWMFLufQlGy70vkZiCQVsRy1Qvk54XAAcfAhIAYI9cx9k54lhzs0pNTeX3Tc1ympvavFYmykw275wws7lZcj6a26rypnYGFH+r95ah/C6hZufrzl6ZljaFgE8+OygzFJQZsGUGAuXF75flMxV0DNklV6FSSaFCSaFiQZFCXtFiXjWFrOLFrHqVsqoqleeDCWmXEFeSlPGWLlByDaUUVEZBZY2QckZQOV9IeTOkkhlS0R/2Rh0rhxg3ECmPOmZHvRATkxWOKRCKKhCqUihSJTtSpUg4pJjfVNxH7wuAQwsBCQB6MLdU2jnsctMuQaa5SU5zstV6886enpbXZLI8vHEnlUxD2ZCprO0r3yLmd5QxHeX8bptwsvO9sfteGsuoBJxdP+P6DEXNkCKmrZARUNiwFHJ9Cro+hUpSyHEVKpYULpUULxYUKRQUK+ZVVcqqVzGrXqWM+pUyirlFGVl1SS9Ma45rKC1bGQWVMYLebWU7e2QKZkiOFZHjL99OVh4+uRxm/HZUpjcnTCAclR2ukh2OKRiJKxIOK2r5VUWQAYAuQUACgIOYWyxWemIqvTW7ru+lF8dJJrukjoLfUDpoKGW7Stqu0rahVFBKB6WULaWChtK2lPLW07ZR3uetF/zy7ldr3Zu08/aqkC+giM9SWJbCMhV2fQo55VDTt+QoXCoqUiwqVswrVsqrqphT70xGfZI5RR1HUcdR2HU7Mk/lh8q4ASW9npmMEVLOF1LOF1bRDKvgj8ixynPBKBCRYcfKPTJeb4wVKgeYQLhKwUiV7EhMkXBM4YBfUYIMABzUCEgAcAC4xWL52ZtUaufSar2USslNp1VKJtvflub13pSamuSm011ST85fDis7Q4xRCTfpoCqBp2U91SoApe1yQNqVZZgK+wIKyVJIPoVdn4KOVOU4qik53sP/BUXT5UATd7KKlwqKOm451LiOIo6jiON2+n+MSq6hpMJKKaiUG1TKu90sb4aU90XKt5m19M4EyhNV+oJR+YIx+YMxBVpCTTSuUKRKkWhckZCtmO1XP7+Ph/wB4BBCQAIAeRNp7ibQlHYbcNI79yeby/PQJJPlOWzSabmpdJdPnpm11CbApG1jZ5jZJfCkWgWetF1eil7AsQy/Qj5bIcNS0PUr6PoUdKVQqTxqWZ9iSXWloqKlfPn2s0xOvZMZ9S5lFXMcRdxyoIk4TqfmmMm6llIKK+EGtVVBpRRSyg2WBwLwhVX0e700lUDj9dIEW241iykQqlIgXKVQNK5wOKJI0FIs6NdAuzz8so+eGgDAfiAgAfhYcvP5nb0wewgwxVSz8s1NKiabVPCCjJNKyU2l5HoTahrpnHyZrHydHMa5tdY/y4s+KROQMnY55GQDUiZgKOutZwJewGl1i1rau2WtJQAVgwH5raCCRkC265ftmrIdQ0FHCnqDBYRLJfUvFjS4VFC8lFfcyap3Nqv+qYx6Ka+o4yrsOLI6eW1511SzItrqhpVUSCkjrIwRUdaMKGdGVbCiKvqjKlkxOXaVZEelYFy+YJXMcFx2OC47HFMkHFLU9itq+1UV9KvW9isSMOVnVDMAQDcjIAH4yFSGfPZGRCs2Nymz431lE+8rm/hA+cQOFZoSclJJL/xkJG8xMjn5MjmZ2YL82YLM4v6NjPZhP7/zZjnElINMq0DTar1lW+v1bMBQKWirGAyoGLRVsm0VLUuG6ZffMWQ5hvyOFCi5skqOAqXyXDTBUlHRYkEDS3lVlXLq7eTVz82ofz6rAbm0ogmny/6LOuUG9YERVtoIK+uLKGtGlTcjyvujKloxOYGoF2qqZASrZAar5Av3khWukh3pJTvSW6FwWBHbUl/bVF3AL5NeGgBAD0NAArBPXMdRKZVSese7Su94T+kd7ym7433lEh+o0JRQoSlRGfXMTaZkpDLypTIy0zlZ6YKsTEGBXEm+vQyI5pNkd7CuvL91kGkbaHZuM1QM+lUMBlQKBspBxrZVDNoqBkMqBoLK2yHl/bZk+GWWJLPoyF8sySyUZBWLChSLsgt52cW8wsWcepVyijk59Xay6qOsertZxbI7FMumFVVGptH5kd9aFGUqbUSU8UWU8wJNwR9VyYqqFIjJDcSkYDnU+IJx+cNxWZFeCoTjCsZ6yY72KT9TY1mKdFlVAAD0TAQkoAdzXVe5Uk7JXLPSifeV2vGu12PzgQpNjSo0NanYXA42bjIlJdPlYJPOyp/OlUNNpig7W1Iw236EMENS0Fs6oujb+WxMy/M0+aBfhbClYiigYrgcYlqWoh30lrAKdkgFK6S8FVbOCqmgoEoFn1QoyZcvyswX5M/nZOVzsgo5BfNZ2YWM4m45uESVUbSQUVWhWdHU9vK64W1XVr6OBhtjl9dWHPmU9YWVMyMq+KMq+iMqWVE5gZhcOybDjpV7akJeqAnHFYj0VjDWS/5QXLKrpGCV/P6gqgxDVR38OwMAgI4jIAEHGdd1lS6m1ZxvVjKfVDLbpHTT+8ok3lcu0ah80w4VmhPe0M7NUjIlpdLypbIy0zn503lZmYLsbFHBrKNwTgrmdt5aFvKW/VUwy8EmE/QpZ5vKhUzlgwHlQwHlgwEVQkEVgiHlgyHl7bDywYhygaiygYiy/pjSVkxZhVUsWlLekT9flFHIy8qnZBZTMotp2aVUObS4GUWzGfXNZhRVk2JGOeTEWgJN5fVDJqwxO3aNjkzl/FEVvEBTsqJy7SrJCzW+UJX8obj84SoFwr3kD5X3yW55Lffo+Kywwoah8P7/uQEAwEeMgAR0Edd1VchllEq8p2Tze0olPigHm+ZG5ZIJ5ZubVEg1q5hqLg8qkE5LmayMTFZGNi8zk5c/V5SVcxQsuArmpWBesovl2856d0GNBVPK2D5lg6aytl/ZoKWcbSlr28ratjKBoDKBkNJWSCkrrKQZVpMvrCZfRM0KKeP65XN9iqikqHKKGFlFlVFYWUWNbJvX3mpWNP+uwvmd2yLKKmpkFFZOkT311pjqcKBpUTIsFayYnEovTVSGXSUjGPN6acrP1RgtQSbYKtC0Cjc+f1Ahw+hUkAQAAB9PBCQcklzHkZvJlAcM8JZcc0Kp5g+UaW5UtnmHcs07VEg2K59qUimVUintDRrghRpfNi9/tiB/rqRArqRA3pV/l3EDOttb01rBNJS2TWVsvzIBv9KBgFKWpZRlK+m31WwGy8HGH1bSH1bOH1LJDEj+gAzTlGlJtr+oiBdUIkb5lrKwUV7vpawOM5oV1bsKG9nyPmUV8faHjHwXXUlbrgw5VkSOFdk5nHOwSr5glXzBWDnM7CHI7LrN9Nv7m60AAAAkEZDwMVAe+SzTdn6aliGdvWGdc6kmZZM7lG9OKJ9qUjGZVDGdlJsqD+WsTEZGJi8z29JLs/chnX3qXLjJ+6WsZShr+ZSxfMpapjJ+v7KWpaxpKesPKOsPKG8GVDADKpqWimZAjmnJ9QVkmJYM0yef35Dhd+W3SgqaBUWUUcTIea9Z1SiriJoVMd6rbGsJQJbRdcNWt+b6rPLQzYGIjEBMCkS8dW/x9mmv+6LlYBOIyLDCMg2DYAMAAA4KBCQcEC1z1LQLNa2WUjIpJ5lSPplQvjmhQrJZpWT59rOWoZ196ax8uYI68tx8yx1a+zIamqNWwzR7c9TkLJ9yfp9ylk95y1TB71PBb6rkN1Xy++SapuT3yWca8pk+WaZkm1LQ5yjsk2K+oiK+kmyjoN7Kq0YF2coqaORlq1BejIJM7d8w1R3mD3U4tMjrySmvt34fkeHv6DhzAAAAHx8EJEjaXS9NcvehpuV9stymkGxWIdmkUrJl8s20jHRWRnH/ei982vM8NY7hTbi5y9wzLcEma0lFy1DRb8ixJNdvyPBLPr8r03QV8DuyTUdhs6iIWVCVWVAvX0kx11Gt4yjiOoo4bvf0ZPiDkt8uhxm/XV63gju3W+E9hJZWQaey3ioEWRHJ5D/mAAAA+4pfTh9jlUk3m5pUak7uDDXJZPtAk0rJSaXb7C+mmsvBJp0u99h0kqH2Ix3n/VK6ZT4ae+ecNK3nrckEpFzAkGO5kuXKsFz5/SX5/eVQE/A7CpqOIj5HUddR1HEUc11VO+X3UcdV1HEUct3djbS8hz+epOIu23yWZLcKKP7WAeXDtu8h2OzLdr8tGUy2CQAAcDAgIHUjJ5/3wk15uOY2r03l282cpmY5yeZyAGpqUrG5WaXmhJzm8mSccrtuMkqpfS9N2t5NoGm1rRxuJMNyyj01fld+vyPL7yjodxRRObzEnJZw42pgJdh42x1XwT2EG9e15RpRGVaVjJYH8lt6S6zw/ocSK9g+7Ph4CgYAAOBQR0DaT67jlHtjmprKz9K09OI0N6nY3KTcjg/K89UkEuWJOJuay6GmOSmlMjLTGZmFrnmIvuiTUsGd4aV1L83OdSnTLugYyluuDMuR6ZdsvyPb66WJteqZaQk3NY7rbd+5P+Y4O8ONIykvOW5YMmKSv5d8dnRnqLFjO28Jax12Wm4L23V/ICrDH9j3XiEAAACgkw7ZgFTKZpVNfKBM47tK73hfucT7yiV2KJ/4QLlEQoVEkwpNTXKbUzJSafmSafkzOVnpvOxsXoFcSb79GDhgd9J2eUl5r+mgsXM9KKVsw9ve0s5Q3nZVslwp4MryuQrJVaQSXnYGm5jjaKC7M8y0DjdRx1Eo60o5U473HIthx2UEq2S0CS67hJw2YWeX/YGIfPTEAAAA4GOqxwekZdPGq1fJlZ0tKZhzFMw6CuWkwG46b0x1fGjngtk62Ehp21AquDP0FAJSwXZVCrhyAq7cgCs34Mi0XBkBV5bpKGS4CjmuQq6jsOMq6rrq7z1TE3ZdhVreO65sw1JQtvyloOQLySgEZQRC8lkhGS0P8LcOLrvrrdk17FghmTwDAwAAABz8AenOO+/UD37wA23btk2f+tSndPvtt+vzn//8Pn9++CspRc0992i0BJmstxQCrgq2q2JAcrxQo0B54ABfwJHpd+QPlJ+x8QcMWX5TQVkKG5Z6G7aCpq2gGSwvgbBMKyxfICwzEJLfDssfCMkXCHnPwez6Giw/J9PmNdi2DUEGAAAAOGAO6oD04IMPqr6+Xnfeeac++9nP6u6779YXv/hFvfTSSxo0aNA+HeMfYwMKx2z57IB8QVtmKKhAOKpANKpwJK64HdOAYFhmICwrGFbADisQDCsQisgMhHYTWFoFF24lAwAAAHoUw3W7eBi0LjRmzBidcMIJuuuuuyrbhg0bpqlTp2r+/Pl7/WxTU5Pi8bgSiYSqqqoOdKkAAAAADlIdyQZ7mpOz2+Xzea1fv16TJk1qs33SpElavXp1u/a5XE5NTU1tFgAAAADoiIM2IL333nsqlUqqrq5us726uloNDQ3t2s+fP1/xeLyy1NXVfVSlAgAAAOghDtqA1MLYZVAC13XbbZOka665RolEorJs2bLloyoRAAAAQA9x0A7S0K9fP5mm2a63aPv27e16lSTJtm3Ztv1RlQcAAACgBzpoe5ACgYBGjRqllStXttm+cuVKjRs3rpuqAgAAANCTHbQ9SJI0Z84cTZ8+XaNHj9bYsWO1aNEivfXWW7rkkku6uzQAAAAAPdBBHZDOPvtsvf/++/rP//xPbdu2TSNGjNBjjz2mI444ortLAwAAANADHdTzIHUG8yABAAAAkHrIPEgAAAAA8FEjIAEAAACAh4AEAAAAAB4CEgAAAAB4CEgAAAAA4CEgAQAAAIDnoJ4HqTNaRi9vamrq5koAAAAAdKeWTLAvMxz12ID0/vvvS5Lq6uq6uRIAAAAAB4Pm5mbF4/G9tumxAalPnz6SpLfeeutD/wj4eGlqalJdXZ22bNnCJMA9EN9vz8V323Px3fZcfLc926H0/bquq+bmZtXW1n5o2x4bkHy+8uNV8Xi8x3/hh6qqqiq+2x6M77fn4rvtufhuey6+257tUPl+97XThEEaAAAAAMBDQAIAAAAAT48NSLZt67vf/a5s2+7uUtDF+G57Nr7fnovvtufiu+25+G57Nr7f3TPcfRnrDgAAAAAOAT22BwkAAAAAOoqABAAAAAAeAhIAAAAAeAhIAAAAAOAhIAEAAACAp8cGpDvvvFODBw9WMBjUqFGj9Oc//7m7S0InzZ8/X//yL/+iWCymAQMGaOrUqXrllVe6uywcAPPnz5dhGKqvr+/uUtAF/vnPf+prX/ua+vbtq3A4rOOPP17r16/v7rLQBYrFor7zne9o8ODBCoVCOuqoo/Sf//mfchynu0tDBz355JM644wzVFtbK8Mw9PDDD7fZ77qubrjhBtXW1ioUCmnChAnauHFj9xSLDtnbd1soFDR37lyNHDlSkUhEtbW1Ou+887R169buK/gg0CMD0oMPPqj6+np9+9vf1l//+ld9/vOf1xe/+EW99dZb3V0aOmHVqlW67LLLtGbNGq1cuVLFYlGTJk1SKpXq7tLQhdatW6dFixbp2GOP7e5S0AUaGxv12c9+VpZl6Xe/+51eeukl3XrrrerVq1d3l4YucPPNN+vHP/6xFi5cqE2bNumWW27RD37wA91xxx3dXRo6KJVK6bjjjtPChQt3u/+WW27RbbfdpoULF2rdunWqqanRxIkT1dzc/BFXio7a23ebTqf13HPP6brrrtNzzz2nX/3qV3r11Vc1ZcqUbqj04NEj50EaM2aMTjjhBN11112VbcOGDdPUqVM1f/78bqwMXendd9/VgAEDtGrVKp100kndXQ66QDKZ1AknnKA777xTN954o44//njdfvvt3V0WOuFb3/qW/vKXv9CL30NNnjxZ1dXVuueeeyrbvvKVrygcDuu+++7rxsrQGYZhaNmyZZo6daqkcu9RbW2t6uvrNXfuXElSLpdTdXW1br75Zl188cXdWC06YtfvdnfWrVunz3zmM/rHP/6hQYMGfXTFHUR6XA9SPp/X+vXrNWnSpDbbJ02apNWrV3dTVTgQEomEJKlPnz7dXAm6ymWXXaZ//dd/1amnntrdpaCL/PrXv9bo0aP1f/7P/9GAAQP06U9/Wj/5yU+6uyx0kc997nP64x//qFdffVWS9Le//U1PPfWUvvSlL3VzZehKmzdvVkNDQ5vfVrZta/z48fy26oESiYQMwzike/r93V1AV3vvvfdUKpVUXV3dZnt1dbUaGhq6qSp0Ndd1NWfOHH3uc5/TiBEjurscdIGlS5fqueee07p167q7FHShN954Q3fddZfmzJmja6+9VmvXrtUVV1wh27Z13nnndXd56KS5c+cqkUjomGOOkWmaKpVK+v73v69zzjmnu0tDF2r5/bS731b/+Mc/uqMkHCDZbFbf+ta3NG3aNFVVVXV3Od2mxwWkFoZhtFl3XbfdNnx8XX755Xr++ef11FNPdXcp6AJbtmzR7NmztWLFCgWDwe4uB13IcRyNHj1a8+bNkyR9+tOf1saNG3XXXXcRkHqABx98UPfff78eeOABfepTn9KGDRtUX1+v2tpanX/++d1dHroYv616tkKhoK9+9atyHEd33nlnd5fTrXpcQOrXr59M02zXW7R9+/Z2/88HPp5mzZqlX//613ryySd1+OGHd3c56ALr16/X9u3bNWrUqMq2UqmkJ598UgsXLlQul5Npmt1YIfbXwIEDNXz48Dbbhg0bpoceeqibKkJX+uY3v6lvfetb+upXvypJGjlypP7xj39o/vz5BKQepKamRlK5J2ngwIGV7fy26jkKhYLOOussbd68WX/6058O6d4jqQc+gxQIBDRq1CitXLmyzfaVK1dq3Lhx3VQVuoLrurr88sv1q1/9Sn/60580ePDg7i4JXeSUU07RCy+8oA0bNlSW0aNH69xzz9WGDRsIRx9jn/3sZ9sNx//qq6/qiCOO6KaK0JXS6bR8vrY/JUzTZJjvHmbw4MGqqalp89sqn89r1apV/LbqAVrC0WuvvaY//OEP6tu3b3eX1O16XA+SJM2ZM0fTp0/X6NGjNXbsWC1atEhvvfWWLrnkku4uDZ1w2WWX6YEHHtAjjzyiWCxW6SWMx+MKhULdXB06IxaLtXuWLBKJqG/fvjxj9jH3jW98Q+PGjdO8efN01llnae3atVq0aJEWLVrU3aWhC5xxxhn6/ve/r0GDBulTn/qU/vrXv+q2227TBRdc0N2loYOSyaRef/31yvrmzZu1YcMG9enTR4MGDVJ9fb3mzZunIUOGaMiQIZo3b57C4bCmTZvWjVVjX+ztu62trdW///u/67nnntNvfvMblUqlyu+rPn36KBAIdFfZ3cvtof77v//bPeKII9xAIOCecMIJ7qpVq7q7JHSSpN0u9957b3eXhgNg/Pjx7uzZs7u7DHSBRx991B0xYoRr27Z7zDHHuIsWLeruktBFmpqa3NmzZ7uDBg1yg8Gge9RRR7nf/va33Vwu192loYMef/zx3f5v7Pnnn++6rus6juN+97vfdWtqalzbtt2TTjrJfeGFF7q3aOyTvX23mzdv3uPvq8cff7y7S+82PXIeJAAAAADYHz3uGSQAAAAA2F8EJAAAAADwEJAAAAAAwENAAgAAAAAPAQkAAAAAPAQkAAAAAPAQkAAAAADAQ0ACAAAAAA8BCQAAAAA8BCQAAAAA8BCQAAAAAMDz/wGC30dVwZaKZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#clear the plots\n",
    "plt.close(\"all\")\n",
    "#plot the rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rewards, label=\"baseline\")\n",
    "plt.plot(wrapped_env_rewards, label=\"modified_reward\")\n",
    "plt.plot(PPO_rewards, label=\"PPO\")\n",
    "plt.plot(A2C_rewards, label=\"A2C\")\n",
    "#limit the range of the x-axis to the number of steps of A2C\n",
    "plt.xlim(0, max(len(PPO_rewards), len(A2C_rewards)))\n",
    "#scale the y-axis to the range of the rewards\n",
    "# plt.ylim(-4, 50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the observation space\n",
    "from gymnasium import ObservationWrapper\n",
    "import numpy as np\n",
    "\n",
    "class FlattenObservation(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).flatten()\n",
    "    \n",
    "base_env = gym.make('BinPack3D-v1',\n",
    "                container_size = (9, 11, 13),\n",
    "                    boxSeqGenerator='CUT-2', \n",
    "                    enabled_rotations = [Rotate.NOOP],\n",
    "                    n_foreseeable_box = 3,\n",
    "                    minSideLen = 2,\n",
    "                    maxSideLen = 5,\n",
    "                )\n",
    "wrapped_env = FlattenObservation(base_env)\n",
    "\n",
    "#we want to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a random agent to test the environment\n",
    "from gymnasium import Wrapper\n",
    "from gymnasium.spaces import MultiDiscrete\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class RandomAgent(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.Prob = self.calculate_Prob()\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        return obs, reward, done, truncated, info\n",
    "    \n",
    "    def act(self, obs):\n",
    "        #choose a random position from the action space. action space is a multi-discrete space\n",
    "        (x, y) = self.env.action_space.sample()\n",
    "        print(self.env.action_space, x, y, self.env.container_size)\n",
    "        pos = x\n",
    "        rot = random.choice(self.env.enabled_rotations)\n",
    "        return (pos, rot)\n",
    "    \n",
    "    def create_agent(self, **kwargs):\n",
    "        agent = ValueIterationAgent(env = self.env, gamma=0.9, theta=0.0001, max_iter=1000)\n",
    "        agent.initialize()\n",
    "\n",
    "        return agent\n",
    "    \n",
    "    def calculate_Prob(self):\n",
    "        #calculate the transition probabilities\n",
    "        Prob = np.zeros((self.env.observation_space.nvec[0], self.env.action_space.n, self.env.observation_space.nvec[0]))\n",
    "        for s in range(self.env.observation_space.nvec[0]):\n",
    "            for a in range(self.env.action_space.n):\n",
    "                for s_prime in range(self.env.observation_space.nvec[0]):\n",
    "                    Prob[s, a, s_prime] = self.env.calculate_prob(s, a, s_prime)\n",
    "                    \n",
    "        return Prob\n",
    "\n",
    "class ValueIterationAgent(object):\n",
    "    def __init__(self, env=None, gamma=0.99, theta=0.001, max_iter=1000):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        self.disc_actions = self.env.action_space.nvec\n",
    "        self.disc_states = self.env.observation_space.nvec\n",
    "        self.Prob = self.env.Prob\n",
    "\n",
    "    def initialize(self):\n",
    "        self.value_policy, self.policy_function = self.value_iteration()\n",
    "\n",
    "    def value_iteration(self):\n",
    "        value_policy = np.zeros(self.disc_states)\n",
    "        policy_function = np.zeros(self.disc_states)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            delta = 0\n",
    "            for s in range(self.disc_states):\n",
    "                v = value_policy[s]\n",
    "                value_policy[s] = self.calculate_value(s, value_policy)\n",
    "                delta = max(delta, abs(v - value_policy[s]))\n",
    "\n",
    "            if delta < self.theta:\n",
    "                print('Converged at iteration', i)\n",
    "                break\n",
    "\n",
    "        for s in range(self.disc_states):\n",
    "            policy_function[s] = self.calculate_policy(s, value_policy)\n",
    "\n",
    "        return value_policy, policy_function\n",
    "    \n",
    "    def calculate_value(self, s, value_policy):\n",
    "        max_val = float('-inf')\n",
    "        for a in range(self.env.action_space.n):\n",
    "            val = 0\n",
    "            for s_prime in range(self.disc_states):\n",
    "                val += self.Prob[s, a, s_prime] * (self.env.R[s, a, s_prime] + self.gamma * value_policy[s_prime])\n",
    "            max_val = max(max_val, val)\n",
    "        return max_val\n",
    "    \n",
    "    def calculate_policy(self, s, value_policy):\n",
    "        max_val = float('-inf')\n",
    "        max_action = 0\n",
    "        for a in range(self.env.action_space.n):\n",
    "            val = 0\n",
    "            for s_prime in range(self.disc_states):\n",
    "                val += self.Prob[s, a, s_prime] * (self.env.R[s, a, s_prime] + self.gamma * value_policy[s_prime])\n",
    "            if val > max_val:\n",
    "                max_val = val\n",
    "                max_action = a\n",
    "        return max_action\n",
    "\n",
    "base_env = gym.make('BinPack3D-v1', \n",
    "                    container_size = (9, 11, 13),\n",
    "                    boxSeqGenerator='CUT-2', \n",
    "                    enabled_rotations = [Rotate.NOOP],\n",
    "                    n_foreseeable_box = 3,\n",
    "                    minSideLen = 2,\n",
    "                    maxSideLen = 5,\n",
    "                    )\n",
    "wrapped_env = RandomAgent(base_env)\n",
    "\n",
    "frames = []\n",
    "obs = wrapped_env.reset()\n",
    "frame = wrapped_env.render()\n",
    "rewards = []\n",
    "for i in range(100):\n",
    "    frames.append(frame)\n",
    "    action = wrapped_env.act(obs)\n",
    "    obs, reward, done,_, info = wrapped_env.step(action)\n",
    "    frame = wrapped_env.render()\n",
    "    print(reward,done,info)\n",
    "    rewards.append(reward)\n",
    "    \n",
    "\n",
    "wrapped_env.render()\n",
    "\n",
    "imageio.mimsave(DATA_DIR+\"/random.gif\", frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5446_proj] *",
   "language": "python",
   "name": "conda-env-cs5446_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
